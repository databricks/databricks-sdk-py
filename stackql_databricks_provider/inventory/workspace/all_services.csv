filename,path,operationId,verb,response_object,tags,params,summary,description,stackql_resource_name,stackql_method_name,stackql_verb,stackql_object_key
agentbricks.json,/api/2.0/custom-llms/{id}/optimize/cancel,agent_bricks_cancel_optimize,post,,"agentbricks, agent_bricks",id,Cancel a Custom LLM Optimization Run.,Cancel a Custom LLM Optimization Run.  :param id: str,custom_llms,cancel_optimize,exec,
agentbricks.json,/api/2.0/custom-llms,agent_bricks_create_custom_llm,post,CustomLlm,"agentbricks, agent_bricks","name, instructions, agent_artifact_path, datasets, guidelines",Create a Custom LLM.,"Create a Custom LLM.  :param name: str   Name of the custom LLM. Only alphanumeric characters and dashes allowed. :param instructions: str   Instructions for the custom LLM to follow :param agent_artifact_path: str (optional)   This will soon be deprecated!! Optional: UC path for agent artifacts. If you are using a dataset   that you only have read permissions, please provide a destination path where you have write   permissions. Please provide this in catalog.schema format. :param datasets: List[:class:`Dataset`] (optional)   Datasets used for training and evaluating the model, not for inference. Currently, only 1 dataset is   accepted. :param guidelines: List[str] (optional)   Guidelines for the custom LLM to adhere to  :returns: :class:`CustomLlm`",custom_llms,create,insert,
agentbricks.json,/api/2.0/custom-llms/{id},agent_bricks_delete_custom_llm,delete,,"agentbricks, agent_bricks",id,Delete a Custom LLM.,Delete a Custom LLM.  :param id: str   The id of the custom llm,custom_llms,delete,delete,
agentbricks.json,/api/2.0/custom-llms/{id},agent_bricks_get_custom_llm,get,CustomLlm,"agentbricks, agent_bricks",id,Get a Custom LLM.,Get a Custom LLM.  :param id: str   The id of the custom llm  :returns: :class:`CustomLlm`,custom_llms,get,select,
agentbricks.json,/api/2.0/custom-llms/{id},agent_bricks_update_custom_llm,patch,CustomLlm,"agentbricks, agent_bricks","id, custom_llm, update_mask",Update a Custom LLM.,"Update a Custom LLM.  :param id: str   The id of the custom llm :param custom_llm: :class:`CustomLlm`   The CustomLlm containing the fields which should be updated. :param update_mask: str   The list of the CustomLlm fields to update. These should correspond to the values (or lack thereof)   present in `custom_llm`.    The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`CustomLlm`",custom_llms,update,update,
agentbricks.json,/api/2.0/custom-llms/{id}/optimize,agent_bricks_start_optimize,post,CustomLlm,"agentbricks, agent_bricks",id,Start a Custom LLM Optimization Run.,Start a Custom LLM Optimization Run.  :param id: str   The Id of the tile.  :returns: :class:`CustomLlm`,custom_llms,start_optimize,exec,
apps.json,/api/2.0/apps/{app_name}/deployments,apps_deploy,post,AppDeployment,apps,"app_name, app_deployment",Creates an app deployment for the app with the supplied name.,Creates an app deployment for the app with the supplied name.  :param app_name: str   The name of the app. :param app_deployment: :class:`AppDeployment`   The app deployment configuration.  :returns:   Long-running operation waiter for :class:`AppDeployment`.   See :method:wait_get_deployment_app_succeeded for more details.,app_deployments,create,insert,
apps.json,/api/2.0/apps/{app_name}/deployments,apps_list_deployments,get,ListAppDeploymentsResponse,apps,"app_name, page_size, page_token",Lists all app deployments for the app with the supplied name.,Lists all app deployments for the app with the supplied name.  :param app_name: str   The name of the app. :param page_size: int (optional)   Upper bound for items returned. :param page_token: str (optional)   Pagination token to go to the next page of apps. Requests first page if absent.  :returns: Iterator over :class:`AppDeployment`,app_deployments,list,select,$.app_deployments
apps.json,/api/2.0/apps/{app_name}/deployments/{deployment_id},apps_get_deployment,get,AppDeployment,apps,"app_name, deployment_id",Retrieves information for the app deployment with the supplied name and deployment id.,Retrieves information for the app deployment with the supplied name and deployment id.  :param app_name: str   The name of the app. :param deployment_id: str   The unique id of the deployment.  :returns: :class:`AppDeployment`,app_deployments,get,select,
apps.json,/api/2.0/permissions/apps/{app_name}/permissionLevels,apps_get_permission_levels,get,GetAppPermissionLevelsResponse,apps,app_name,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param app_name: str   The app for which to get or manage permissions.  :returns: :class:`GetAppPermissionLevelsResponse`,app_permission_levels,get,select,
apps.json,/api/2.0/permissions/apps/{app_name},apps_get_permissions,get,AppPermissions,apps,app_name,Gets the permissions of an app. Apps can inherit permissions from their root object.,Gets the permissions of an app. Apps can inherit permissions from their root object.  :param app_name: str   The app for which to get or manage permissions.  :returns: :class:`AppPermissions`,app_permissions,get,select,
apps.json,/api/2.0/permissions/apps/{app_name},apps_set_permissions,put,AppPermissions,apps,"app_name, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param app_name: str   The app for which to get or manage permissions. :param access_control_list: List[:class:`AppAccessControlRequest`] (optional)  :returns: :class:`AppPermissions`",app_permissions,set,replace,
apps.json,/api/2.0/permissions/apps/{app_name},apps_update_permissions,patch,AppPermissions,apps,"app_name, access_control_list",Updates the permissions on an app. Apps can inherit permissions from their root object.,Updates the permissions on an app. Apps can inherit permissions from their root object.  :param app_name: str   The app for which to get or manage permissions. :param access_control_list: List[:class:`AppAccessControlRequest`] (optional)  :returns: :class:`AppPermissions`,app_permissions,update,update,
apps.json,/api/2.0/apps/{app_name}/update,apps_create_update,post,AppUpdate,apps,"app_name, update_mask, app",Creates an app update and starts the update process. The update process is asynchronous and the status,"Creates an app update and starts the update process. The update process is asynchronous and the status of the update can be checked with the GetAppUpdate method.  :param app_name: str :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future. :param app: :class:`App` (optional)  :returns:   Long-running operation waiter for :class:`AppUpdate`.   See :method:wait_get_update_app_succeeded for more details.",app_updates,create,insert,
apps.json,/api/2.0/apps/{app_name}/update,apps_get_update,get,AppUpdate,apps,app_name,Gets the status of an app update.,Gets the status of an app update.  :param app_name: str   The name of the app.  :returns: :class:`AppUpdate`,app_updates,get,select,
apps.json,/api/2.0/apps,apps_create,post,App,apps,"no_compute, app",Creates a new app.,"Creates a new app.  :param app: :class:`App` :param no_compute: bool (optional)   If true, the app will not be started after creation.  :returns:   Long-running operation waiter for :class:`App`.   See :method:wait_get_app_active for more details.",apps,create,insert,
apps.json,/api/2.0/apps,apps_list,get,ListAppsResponse,apps,"page_size, page_token",Lists all apps in the workspace.,Lists all apps in the workspace.  :param page_size: int (optional)   Upper bound for items returned. :param page_token: str (optional)   Pagination token to go to the next page of apps. Requests first page if absent.  :returns: Iterator over :class:`App`,apps,list,select,$.apps
apps.json,/api/2.0/apps/{name},apps_delete,delete,App,apps,name,Deletes an app.,Deletes an app.  :param name: str   The name of the app.  :returns: :class:`App`,apps,delete,delete,
apps.json,/api/2.0/apps/{name},apps_get,get,App,apps,name,Retrieves information for the app with the supplied name.,Retrieves information for the app with the supplied name.  :param name: str   The name of the app.  :returns: :class:`App`,apps,get,select,
apps.json,/api/2.0/apps/{name},apps_update,patch,App,apps,"name, app",Updates the app with the supplied name.,Updates the app with the supplied name.  :param name: str   The name of the app. The name must contain only lowercase alphanumeric characters and hyphens. It   must be unique within the workspace. :param app: :class:`App`  :returns: :class:`App`,apps,update,update,
apps.json,/api/2.0/apps/{name}/start,apps_start,post,App,apps,name,Start the last active deployment of the app in the workspace.,Start the last active deployment of the app in the workspace.  :param name: str   The name of the app.  :returns:   Long-running operation waiter for :class:`App`.   See :method:wait_get_app_active for more details.,apps,start,exec,
apps.json,/api/2.0/apps/{name}/stop,apps_stop,post,App,apps,name,Stops the active deployment of the app in the workspace.,Stops the active deployment of the app in the workspace.  :param name: str   The name of the app.  :returns:   Long-running operation waiter for :class:`App`.   See :method:wait_get_app_stopped for more details.,apps,stop,exec,
apps.json,/api/2.0/apps-settings/templates,apps_settings_create_custom_template,post,CustomTemplate,"apps, apps_settings",template,Creates a custom template.,Creates a custom template.  :param template: :class:`CustomTemplate`  :returns: :class:`CustomTemplate`,apps_settings,create,insert,
apps.json,/api/2.0/apps-settings/templates,apps_settings_list_custom_templates,get,ListCustomTemplatesResponse,"apps, apps_settings","page_size, page_token",Lists all custom templates in the workspace.,Lists all custom templates in the workspace.  :param page_size: int (optional)   Upper bound for items returned. :param page_token: str (optional)   Pagination token to go to the next page of custom templates. Requests first page if absent.  :returns: Iterator over :class:`CustomTemplate`,apps_settings,list,select,$.templates
apps.json,/api/2.0/apps-settings/templates/{name},apps_settings_delete_custom_template,delete,CustomTemplate,"apps, apps_settings",name,Deletes the custom template with the specified name.,Deletes the custom template with the specified name.  :param name: str   The name of the custom template.  :returns: :class:`CustomTemplate`,apps_settings,delete,delete,
apps.json,/api/2.0/apps-settings/templates/{name},apps_settings_get_custom_template,get,CustomTemplate,"apps, apps_settings",name,Gets the custom template with the specified name.,Gets the custom template with the specified name.  :param name: str   The name of the custom template.  :returns: :class:`CustomTemplate`,apps_settings,get,select,
apps.json,/api/2.0/apps-settings/templates/{name},apps_settings_update_custom_template,put,CustomTemplate,"apps, apps_settings","name, template",Updates the custom template with the specified name. Note that the template name cannot be updated.,"Updates the custom template with the specified name. Note that the template name cannot be updated.  :param name: str   The name of the template. It must contain only alphanumeric characters, hyphens, underscores, and   whitespaces. It must be unique within the workspace. :param template: :class:`CustomTemplate`  :returns: :class:`CustomTemplate`",apps_settings,replace,replace,
catalog.json,/api/2.1/unity-catalog/artifact-allowlists/{artifact_type.value},artifact_allowlists_get,get,ArtifactAllowlistInfo,"catalog, artifact_allowlists","artifact_type.value, artifact_type",Get the artifact allowlist of a certain artifact type. The caller must be a metastore admin or have,Get the artifact allowlist of a certain artifact type. The caller must be a metastore admin or have the **MANAGE ALLOWLIST** privilege on the metastore.  :param artifact_type: :class:`ArtifactType`   The artifact type of the allowlist.  :returns: :class:`ArtifactAllowlistInfo`,artifact_allowlists,get,select,
catalog.json,/api/2.1/unity-catalog/artifact-allowlists/{artifact_type.value},artifact_allowlists_update,put,ArtifactAllowlistInfo,"catalog, artifact_allowlists","artifact_type.value, artifact_type, artifact_matchers, created_at, created_by, metastore_id",Set the artifact allowlist of a certain artifact type. The whole artifact allowlist is replaced with,"Set the artifact allowlist of a certain artifact type. The whole artifact allowlist is replaced with the new allowlist. The caller must be a metastore admin or have the **MANAGE ALLOWLIST** privilege on the metastore.  :param artifact_type: :class:`ArtifactType`   The artifact type of the allowlist. :param artifact_matchers: List[:class:`ArtifactMatcher`]   A list of allowed artifact match patterns. :param created_at: int (optional)   Time at which this artifact allowlist was set, in epoch milliseconds. :param created_by: str (optional)   Username of the user who set the artifact allowlist. :param metastore_id: str (optional)   Unique identifier of parent metastore.  :returns: :class:`ArtifactAllowlistInfo`",artifact_allowlists,replace,replace,
catalog.json,/api/2.1/unity-catalog/catalogs,catalogs_create,post,CatalogInfo,"catalog, catalogs","name, comment, connection_name, options, properties, provider_name, share_name, storage_root",Creates a new catalog instance in the parent metastore if the caller is a metastore admin or has the,"Creates a new catalog instance in the parent metastore if the caller is a metastore admin or has the **CREATE_CATALOG** privilege.  :param name: str   Name of catalog. :param comment: str (optional)   User-provided free-form text description. :param connection_name: str (optional)   The name of the connection to an external data source. :param options: Dict[str,str] (optional)   A map of key-value properties attached to the securable. :param properties: Dict[str,str] (optional)   A map of key-value properties attached to the securable. :param provider_name: str (optional)   The name of delta sharing provider.    A Delta Sharing catalog is a catalog that is based on a Delta share on a remote sharing server. :param share_name: str (optional)   The name of the share under the share provider. :param storage_root: str (optional)   Storage root URL for managed tables within catalog.  :returns: :class:`CatalogInfo`",catalogs,create,insert,
catalog.json,/api/2.1/unity-catalog/catalogs,catalogs_list,get,ListCatalogsResponse,"catalog, catalogs","include_browse, include_unbound, max_results, page_token","Gets an array of catalogs in the metastore. If the caller is the metastore admin, all catalogs will be","Gets an array of catalogs in the metastore. If the caller is the metastore admin, all catalogs will be retrieved. Otherwise, only catalogs owned by the caller (or for which the caller has the **USE_CATALOG** privilege) will be retrieved. There is no guarantee of a specific ordering of the elements in the array.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param include_browse: bool (optional)   Whether to include catalogs in the response for which the principal can only access selective   metadata for :param include_unbound: bool (optional)   Whether to include catalogs not bound to the workspace. Effective only if the user has permission to   update the catalog–workspace binding. :param max_results: int (optional)   Maximum number of catalogs to return. - when set to 0, the page length is set to a server configured   value (recommended); - when set to a value greater than 0, the page length is the minimum of this   value and a server configured value; - when set to a value less than 0, an invalid parameter error   is returned; - If not set, all valid catalogs are returned (not recommended). - Note: The number of   returned catalogs might be less than the specified max_results size, even zero. The only definitive   indication that no further catalogs can be fetched is when the next_page_token is unset from the   response. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`CatalogInfo`",catalogs,list,select,$.catalogs
catalog.json,/api/2.1/unity-catalog/catalogs/{name},catalogs_delete,delete,,"catalog, catalogs","name, force",Deletes the catalog that matches the supplied name. The caller must be a metastore admin or the owner,Deletes the catalog that matches the supplied name. The caller must be a metastore admin or the owner of the catalog.  :param name: str   The name of the catalog. :param force: bool (optional)   Force deletion even if the catalog is not empty.,catalogs,delete,delete,
catalog.json,/api/2.1/unity-catalog/catalogs/{name},catalogs_get,get,CatalogInfo,"catalog, catalogs","name, include_browse","Gets the specified catalog in a metastore. The caller must be a metastore admin, the owner of the","Gets the specified catalog in a metastore. The caller must be a metastore admin, the owner of the catalog, or a user that has the **USE_CATALOG** privilege set for their account.  :param name: str   The name of the catalog. :param include_browse: bool (optional)   Whether to include catalogs in the response for which the principal can only access selective   metadata for  :returns: :class:`CatalogInfo`",catalogs,get,select,
catalog.json,/api/2.1/unity-catalog/catalogs/{name},catalogs_update,patch,CatalogInfo,"catalog, catalogs","name, comment, enable_predictive_optimization, isolation_mode, new_name, options, owner, properties",Updates the catalog that matches the supplied name. The caller must be either the owner of the,"Updates the catalog that matches the supplied name. The caller must be either the owner of the catalog, or a metastore admin (when changing the owner field of the catalog).  :param name: str   The name of the catalog. :param comment: str (optional)   User-provided free-form text description. :param enable_predictive_optimization: :class:`EnablePredictiveOptimization` (optional)   Whether predictive optimization should be enabled for this object and objects under it. :param isolation_mode: :class:`CatalogIsolationMode` (optional)   Whether the current securable is accessible from all workspaces or a specific set of workspaces. :param new_name: str (optional)   New name for the catalog. :param options: Dict[str,str] (optional)   A map of key-value properties attached to the securable. :param owner: str (optional)   Username of current owner of catalog. :param properties: Dict[str,str] (optional)   A map of key-value properties attached to the securable.  :returns: :class:`CatalogInfo`",catalogs,update,update,
catalog.json,/api/2.1/unity-catalog/connections,connections_create,post,ConnectionInfo,"catalog, connections","name, connection_type, options, comment, properties, read_only",Creates a new connection,"Creates a new connection  Creates a new connection to an external data source. It allows users to specify connection details and configurations for interaction with the external server.  :param name: str   Name of the connection. :param connection_type: :class:`ConnectionType`   The type of connection. :param options: Dict[str,str]   A map of key-value properties attached to the securable. :param comment: str (optional)   User-provided free-form text description. :param properties: Dict[str,str] (optional)   A map of key-value properties attached to the securable. :param read_only: bool (optional)   If the connection is read only.  :returns: :class:`ConnectionInfo`",connections,create,insert,
catalog.json,/api/2.1/unity-catalog/connections,connections_list,get,ListConnectionsResponse,"catalog, connections","max_results, page_token",List all connections.,"List all connections.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param max_results: int (optional)   Maximum number of connections to return. - If not set, all connections are returned (not   recommended). - when set to a value greater than 0, the page length is the minimum of this value and   a server configured value; - when set to 0, the page length is set to a server configured value   (recommended); - when set to a value less than 0, an invalid parameter error is returned; :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`ConnectionInfo`",connections,list,select,$.connections
catalog.json,/api/2.1/unity-catalog/connections/{name},connections_delete,delete,,"catalog, connections",name,Deletes the connection that matches the supplied name.,Deletes the connection that matches the supplied name.  :param name: str   The name of the connection to be deleted.,connections,delete,delete,
catalog.json,/api/2.1/unity-catalog/connections/{name},connections_get,get,ConnectionInfo,"catalog, connections",name,Gets a connection from it's name.,Gets a connection from it's name.  :param name: str   Name of the connection.  :returns: :class:`ConnectionInfo`,connections,get,select,
catalog.json,/api/2.1/unity-catalog/connections/{name},connections_update,patch,ConnectionInfo,"catalog, connections","name, options, new_name, owner",Updates the connection that matches the supplied name.,"Updates the connection that matches the supplied name.  :param name: str   Name of the connection. :param options: Dict[str,str]   A map of key-value properties attached to the securable. :param new_name: str (optional)   New name for the connection. :param owner: str (optional)   Username of current owner of the connection.  :returns: :class:`ConnectionInfo`",connections,update,update,
catalog.json,/api/2.1/unity-catalog/entity-tag-assignments,entity_tag_assignments_create,post,EntityTagAssignment,"catalog, entity_tag_assignments",tag_assignment,Creates a tag assignment for an Unity Catalog entity.,"Creates a tag assignment for an Unity Catalog entity.  To add tags to Unity Catalog entities, you must own the entity or have the following privileges: - **APPLY TAG** on the entity - **USE SCHEMA** on the entity's parent schema - **USE CATALOG** on the entity's parent catalog  To add a governed tag to Unity Catalog entities, you must also have the **ASSIGN** or **MANAGE** permission on the tag policy. See [Manage tag policy permissions].  [Manage tag policy permissions]: https://docs.databricks.com/aws/en/admin/tag-policies/manage-permissions  :param tag_assignment: :class:`EntityTagAssignment`  :returns: :class:`EntityTagAssignment`",entity_tag_assignments,create,insert,
catalog.json,/api/2.1/unity-catalog/entity-tag-assignments/{entity_type}/{entity_name}/tags/{tag_key},entity_tag_assignments_delete,delete,,"catalog, entity_tag_assignments","entity_type, entity_name, tag_key",Deletes a tag assignment for an Unity Catalog entity by its key.,"Deletes a tag assignment for an Unity Catalog entity by its key.  To delete tags from Unity Catalog entities, you must own the entity or have the following privileges: - **APPLY TAG** on the entity - **USE_SCHEMA** on the entity's parent schema - **USE_CATALOG** on the entity's parent catalog  To delete a governed tag from Unity Catalog entities, you must also have the **ASSIGN** or **MANAGE** permission on the tag policy. See [Manage tag policy permissions].  [Manage tag policy permissions]: https://docs.databricks.com/aws/en/admin/tag-policies/manage-permissions  :param entity_type: str   The type of the entity to which the tag is assigned. Allowed values are: catalogs, schemas, tables,   columns, volumes. :param entity_name: str   The fully qualified name of the entity to which the tag is assigned :param tag_key: str   Required. The key of the tag to delete",entity_tag_assignments,delete,delete,
catalog.json,/api/2.1/unity-catalog/entity-tag-assignments/{entity_type}/{entity_name}/tags/{tag_key},entity_tag_assignments_get,get,EntityTagAssignment,"catalog, entity_tag_assignments","entity_type, entity_name, tag_key",Gets a tag assignment for an Unity Catalog entity by tag key.,"Gets a tag assignment for an Unity Catalog entity by tag key.  :param entity_type: str   The type of the entity to which the tag is assigned. Allowed values are: catalogs, schemas, tables,   columns, volumes. :param entity_name: str   The fully qualified name of the entity to which the tag is assigned :param tag_key: str   Required. The key of the tag  :returns: :class:`EntityTagAssignment`",entity_tag_assignments,get,select,
catalog.json,/api/2.1/unity-catalog/entity-tag-assignments/{entity_type}/{entity_name}/tags/{tag_key},entity_tag_assignments_update,patch,EntityTagAssignment,"catalog, entity_tag_assignments","entity_type, entity_name, tag_key, update_mask, tag_assignment",Updates an existing tag assignment for an Unity Catalog entity.,"Updates an existing tag assignment for an Unity Catalog entity.  To update tags to Unity Catalog entities, you must own the entity or have the following privileges: - **APPLY TAG** on the entity - **USE SCHEMA** on the entity's parent schema - **USE CATALOG** on the entity's parent catalog  To update a governed tag to Unity Catalog entities, you must also have the **ASSIGN** or **MANAGE** permission on the tag policy. See [Manage tag policy permissions].  [Manage tag policy permissions]: https://docs.databricks.com/aws/en/admin/tag-policies/manage-permissions  :param entity_type: str   The type of the entity to which the tag is assigned. Allowed values are: catalogs, schemas, tables,   columns, volumes. :param entity_name: str   The fully qualified name of the entity to which the tag is assigned :param tag_key: str   The key of the tag :param tag_assignment: :class:`EntityTagAssignment` :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`EntityTagAssignment`",entity_tag_assignments,update,update,
catalog.json,/api/2.1/unity-catalog/entity-tag-assignments/{entity_type}/{entity_name}/tags,entity_tag_assignments_list,get,ListEntityTagAssignmentsResponse,"catalog, entity_tag_assignments","entity_type, entity_name, max_results, page_token",List tag assignments for an Unity Catalog entity,"List tag assignments for an Unity Catalog entity  PAGINATION BEHAVIOR: The API is by default paginated, a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param entity_type: str   The type of the entity to which the tag is assigned. Allowed values are: catalogs, schemas, tables,   columns, volumes. :param entity_name: str   The fully qualified name of the entity to which the tag is assigned :param max_results: int (optional)   Optional. Maximum number of tag assignments to return in a single page :param page_token: str (optional)   Optional. Pagination token to retrieve the next page of results  :returns: Iterator over :class:`EntityTagAssignment`",entity_tag_assignments,list,select,$.tag_assignments
catalog.json,/api/2.0/lineage-tracking/external-lineage,external_lineage_create_external_lineage_relationship,post,ExternalLineageRelationship,"catalog, external_lineage",external_lineage_relationship,Creates an external lineage relationship between a Databricks or external metadata object and another,Creates an external lineage relationship between a Databricks or external metadata object and another external metadata object.  :param external_lineage_relationship: :class:`CreateRequestExternalLineage`  :returns: :class:`ExternalLineageRelationship`,external_lineage,create,insert,
catalog.json,/api/2.0/lineage-tracking/external-lineage,external_lineage_delete_external_lineage_relationship,delete,,"catalog, external_lineage",external_lineage_relationship,Deletes an external lineage relationship between a Databricks or external metadata object and another,Deletes an external lineage relationship between a Databricks or external metadata object and another external metadata object.  :param external_lineage_relationship: :class:`DeleteRequestExternalLineage`,external_lineage,delete,delete,
catalog.json,/api/2.0/lineage-tracking/external-lineage,external_lineage_list_external_lineage_relationships,get,ListExternalLineageRelationshipsResponse,"catalog, external_lineage","object_info, lineage_direction, page_size, page_token",Lists external lineage relationships of a Databricks object or external metadata given a supplied,"Lists external lineage relationships of a Databricks object or external metadata given a supplied direction.  :param object_info: :class:`ExternalLineageObject`   The object to query external lineage relationships for. Since this field is a query parameter,   please flatten the nested fields. For example, if the object is a table, the query parameter should   look like: `object_info.table.name=main.sales.customers` :param lineage_direction: :class:`LineageDirection`   The lineage direction to filter on. :param page_size: int (optional)   Specifies the maximum number of external lineage relationships to return in a single response. The   value must be less than or equal to 1000. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`ExternalLineageInfo`",external_lineage,list,select,$.external_lineage_relationships
catalog.json,/api/2.0/lineage-tracking/external-lineage,external_lineage_update_external_lineage_relationship,patch,ExternalLineageRelationship,"catalog, external_lineage","update_mask, external_lineage_relationship",Updates an external lineage relationship between a Databricks or external metadata object and another,"Updates an external lineage relationship between a Databricks or external metadata object and another external metadata object.  :param external_lineage_relationship: :class:`UpdateRequestExternalLineage` :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`ExternalLineageRelationship`",external_lineage,update,update,
catalog.json,/api/2.1/unity-catalog/external-locations,external_locations_create,post,ExternalLocationInfo,"catalog, external_locations","name, url, credential_name, comment, enable_file_events, encryption_details, fallback, file_event_queue, read_only, skip_validation",Creates a new external location entry in the metastore. The caller must be a metastore admin or have,"Creates a new external location entry in the metastore. The caller must be a metastore admin or have the **CREATE_EXTERNAL_LOCATION** privilege on both the metastore and the associated storage credential.  :param name: str   Name of the external location. :param url: str   Path URL of the external location. :param credential_name: str   Name of the storage credential used with this location. :param comment: str (optional)   User-provided free-form text description. :param enable_file_events: bool (optional)   Whether to enable file events on this external location. Default to `true`. Set to `false` to   disable file events. :param encryption_details: :class:`EncryptionDetails` (optional) :param fallback: bool (optional)   Indicates whether fallback mode is enabled for this external location. When fallback mode is   enabled, the access to the location falls back to cluster credentials if UC credentials are not   sufficient. :param file_event_queue: :class:`FileEventQueue` (optional)   File event queue settings. If `enable_file_events` is not `false`, must be defined and have exactly   one of the documented properties. :param read_only: bool (optional)   Indicates whether the external location is read-only. :param skip_validation: bool (optional)   Skips validation of the storage credential associated with the external location.  :returns: :class:`ExternalLocationInfo`",external_locations,create,insert,
catalog.json,/api/2.1/unity-catalog/external-locations,external_locations_list,get,ListExternalLocationsResponse,"catalog, external_locations","include_browse, include_unbound, max_results, page_token",Gets an array of external locations (__ExternalLocationInfo__ objects) from the metastore. The caller,"Gets an array of external locations (__ExternalLocationInfo__ objects) from the metastore. The caller must be a metastore admin, the owner of the external location, or a user that has some privilege on the external location. There is no guarantee of a specific ordering of the elements in the array.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param include_browse: bool (optional)   Whether to include external locations in the response for which the principal can only access   selective metadata for :param include_unbound: bool (optional)   Whether to include external locations not bound to the workspace. Effective only if the user has   permission to update the location–workspace binding. :param max_results: int (optional)   Maximum number of external locations to return. If not set, all the external locations are returned   (not recommended). - when set to a value greater than 0, the page length is the minimum of this   value and a server configured value; - when set to 0, the page length is set to a server configured   value (recommended); - when set to a value less than 0, an invalid parameter error is returned; :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`ExternalLocationInfo`",external_locations,list,select,$.external_locations
catalog.json,/api/2.1/unity-catalog/external-locations/{name},external_locations_delete,delete,,"catalog, external_locations","name, force",Deletes the specified external location from the metastore. The caller must be the owner of the,Deletes the specified external location from the metastore. The caller must be the owner of the external location.  :param name: str   Name of the external location. :param force: bool (optional)   Force deletion even if there are dependent external tables or mounts.,external_locations,delete,delete,
catalog.json,/api/2.1/unity-catalog/external-locations/{name},external_locations_get,get,ExternalLocationInfo,"catalog, external_locations","name, include_browse","Gets an external location from the metastore. The caller must be either a metastore admin, the owner","Gets an external location from the metastore. The caller must be either a metastore admin, the owner of the external location, or a user that has some privilege on the external location.  :param name: str   Name of the external location. :param include_browse: bool (optional)   Whether to include external locations in the response for which the principal can only access   selective metadata for  :returns: :class:`ExternalLocationInfo`",external_locations,get,select,
catalog.json,/api/2.1/unity-catalog/external-locations/{name},external_locations_update,patch,ExternalLocationInfo,"catalog, external_locations","name, comment, credential_name, enable_file_events, encryption_details, fallback, file_event_queue, force, isolation_mode, new_name, owner, read_only, skip_validation, url","Updates an external location in the metastore. The caller must be the owner of the external location,","Updates an external location in the metastore. The caller must be the owner of the external location, or be a metastore admin. In the second case, the admin can only update the name of the external location.  :param name: str   Name of the external location. :param comment: str (optional)   User-provided free-form text description. :param credential_name: str (optional)   Name of the storage credential used with this location. :param enable_file_events: bool (optional)   Whether to enable file events on this external location. Default to `true`. Set to `false` to   disable file events. :param encryption_details: :class:`EncryptionDetails` (optional) :param fallback: bool (optional)   Indicates whether fallback mode is enabled for this external location. When fallback mode is   enabled, the access to the location falls back to cluster credentials if UC credentials are not   sufficient. :param file_event_queue: :class:`FileEventQueue` (optional)   File event queue settings. If `enable_file_events` is not `false`, must be defined and have exactly   one of the documented properties. :param force: bool (optional)   Force update even if changing url invalidates dependent external tables or mounts. :param isolation_mode: :class:`IsolationMode` (optional) :param new_name: str (optional)   New name for the external location. :param owner: str (optional)   The owner of the external location. :param read_only: bool (optional)   Indicates whether the external location is read-only. :param skip_validation: bool (optional)   Skips validation of the storage credential associated with the external location. :param url: str (optional)   Path URL of the external location.  :returns: :class:`ExternalLocationInfo`",external_locations,update,update,
catalog.json,/api/2.0/lineage-tracking/external-metadata,external_metadata_create_external_metadata,post,ExternalMetadata,"catalog, external_metadata",external_metadata,Creates a new external metadata object in the parent metastore if the caller is a metastore admin or,Creates a new external metadata object in the parent metastore if the caller is a metastore admin or has the **CREATE_EXTERNAL_METADATA** privilege. Grants **BROWSE** to all account users upon creation by default.  :param external_metadata: :class:`ExternalMetadata`  :returns: :class:`ExternalMetadata`,external_metadata,create,insert,
catalog.json,/api/2.0/lineage-tracking/external-metadata,external_metadata_list_external_metadata,get,ListExternalMetadataResponse,"catalog, external_metadata","page_size, page_token","Gets an array of external metadata objects in the metastore. If the caller is the metastore admin, all","Gets an array of external metadata objects in the metastore. If the caller is the metastore admin, all external metadata objects will be retrieved. Otherwise, only external metadata objects that the caller has **BROWSE** on will be retrieved. There is no guarantee of a specific ordering of the elements in the array.  :param page_size: int (optional)   Specifies the maximum number of external metadata objects to return in a single response. The value   must be less than or equal to 1000. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`ExternalMetadata`",external_metadata,list,select,$.external_metadata
catalog.json,/api/2.0/lineage-tracking/external-metadata/{name},external_metadata_delete_external_metadata,delete,,"catalog, external_metadata",name,Deletes the external metadata object that matches the supplied name. The caller must be a metastore,"Deletes the external metadata object that matches the supplied name. The caller must be a metastore admin, the owner of the external metadata object, or a user that has the **MANAGE** privilege.  :param name: str",external_metadata,delete,delete,
catalog.json,/api/2.0/lineage-tracking/external-metadata/{name},external_metadata_get_external_metadata,get,ExternalMetadata,"catalog, external_metadata",name,"Gets the specified external metadata object in a metastore. The caller must be a metastore admin, the","Gets the specified external metadata object in a metastore. The caller must be a metastore admin, the owner of the external metadata object, or a user that has the **BROWSE** privilege.  :param name: str  :returns: :class:`ExternalMetadata`",external_metadata,get,select,
catalog.json,/api/2.0/lineage-tracking/external-metadata/{name},external_metadata_update_external_metadata,patch,ExternalMetadata,"catalog, external_metadata","name, update_mask, external_metadata",Updates the external metadata object that matches the supplied name. The caller can only update either,"Updates the external metadata object that matches the supplied name. The caller can only update either the owner or other metadata fields in one request. The caller must be a metastore admin, the owner of the external metadata object, or a user that has the **MODIFY** privilege. If the caller is updating the owner, they must also have the **MANAGE** privilege.  :param name: str   Name of the external metadata object. :param external_metadata: :class:`ExternalMetadata` :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`ExternalMetadata`",external_metadata,update,update,
catalog.json,/api/2.1/unity-catalog/functions,functions_create,post,FunctionInfo,"catalog, functions",function_info,**WARNING: This API is experimental and will change in future versions**,**WARNING: This API is experimental and will change in future versions**  Creates a new function  The user must have the following permissions in order for the function to be created: - **USE_CATALOG** on the function's parent catalog - **USE_SCHEMA** and **CREATE_FUNCTION** on the function's parent schema  :param function_info: :class:`CreateFunction`   Partial __FunctionInfo__ specifying the function to be created.  :returns: :class:`FunctionInfo`,functions,create,insert,
catalog.json,/api/2.1/unity-catalog/functions,functions_list,get,ListFunctionsResponse,"catalog, functions","catalog_name, schema_name, include_browse, max_results, page_token","List functions within the specified parent catalog and schema. If the user is a metastore admin, all","List functions within the specified parent catalog and schema. If the user is a metastore admin, all functions are returned in the output list. Otherwise, the user must have the **USE_CATALOG** privilege on the catalog and the **USE_SCHEMA** privilege on the schema, and the output list contains only functions for which either the user has the **EXECUTE** privilege or the user is the owner. There is no guarantee of a specific ordering of the elements in the array.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param catalog_name: str   Name of parent catalog for functions of interest. :param schema_name: str   Parent schema of functions. :param include_browse: bool (optional)   Whether to include functions in the response for which the principal can only access selective   metadata for :param max_results: int (optional)   Maximum number of functions to return. If not set, all the functions are returned (not recommended).   - when set to a value greater than 0, the page length is the minimum of this value and a server   configured value; - when set to 0, the page length is set to a server configured value   (recommended); - when set to a value less than 0, an invalid parameter error is returned; :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`FunctionInfo`",functions,list,select,$.functions
catalog.json,/api/2.1/unity-catalog/functions/{name},functions_delete,delete,,"catalog, functions","name, force","Deletes the function that matches the supplied name. For the deletion to succeed, the user must","Deletes the function that matches the supplied name. For the deletion to succeed, the user must satisfy one of the following conditions: - Is the owner of the function's parent catalog - Is the owner of the function's parent schema and have the **USE_CATALOG** privilege on its parent catalog - Is the owner of the function itself and have both the **USE_CATALOG** privilege on its parent catalog and the **USE_SCHEMA** privilege on its parent schema  :param name: str   The fully-qualified name of the function (of the form   __catalog_name__.__schema_name__.__function__name__) . :param force: bool (optional)   Force deletion even if the function is notempty.",functions,delete,delete,
catalog.json,/api/2.1/unity-catalog/functions/{name},functions_get,get,FunctionInfo,"catalog, functions","name, include_browse","Gets a function from within a parent catalog and schema. For the fetch to succeed, the user must","Gets a function from within a parent catalog and schema. For the fetch to succeed, the user must satisfy one of the following requirements: - Is a metastore admin - Is an owner of the function's parent catalog - Have the **USE_CATALOG** privilege on the function's parent catalog and be the owner of the function - Have the **USE_CATALOG** privilege on the function's parent catalog, the **USE_SCHEMA** privilege on the function's parent schema, and the **EXECUTE** privilege on the function itself  :param name: str   The fully-qualified name of the function (of the form   __catalog_name__.__schema_name__.__function__name__). :param include_browse: bool (optional)   Whether to include functions in the response for which the principal can only access selective   metadata for  :returns: :class:`FunctionInfo`",functions,get,select,
catalog.json,/api/2.1/unity-catalog/functions/{name},functions_update,patch,FunctionInfo,"catalog, functions","name, owner",Updates the function that matches the supplied name. Only the owner of the function can be updated. If,"Updates the function that matches the supplied name. Only the owner of the function can be updated. If the user is not a metastore admin, the user must be a member of the group that is the new function owner. - Is a metastore admin - Is the owner of the function's parent catalog - Is the owner of the function's parent schema and has the **USE_CATALOG** privilege on its parent catalog - Is the owner of the function itself and has the **USE_CATALOG** privilege on its parent catalog as well as the **USE_SCHEMA** privilege on the function's parent schema.  :param name: str   The fully-qualified name of the function (of the form   __catalog_name__.__schema_name__.__function__name__). :param owner: str (optional)   Username of current owner of the function.  :returns: :class:`FunctionInfo`",functions,update,update,
catalog.json,/api/2.1/unity-catalog/permissions/{securable_type}/{full_name},grants_get,get,GetPermissionsResponse,"catalog, grants","securable_type, full_name, max_results, page_token, principal",Gets the permissions for a securable. Does not include inherited permissions.,"Gets the permissions for a securable. Does not include inherited permissions.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param securable_type: str   Type of securable. :param full_name: str   Full name of securable. :param max_results: int (optional)   Specifies the maximum number of privileges to return (page length). Every PrivilegeAssignment   present in a single page response is guaranteed to contain all the privileges granted on the   requested Securable for the respective principal.    If not set, all the permissions are returned. If set to - lesser than 0: invalid parameter error -   0: page length is set to a server configured value - lesser than 150 but greater than 0: invalid   parameter error (this is to ensure that server is able to return at least one complete   PrivilegeAssignment in a single page response) - greater than (or equal to) 150: page length is the   minimum of this value and a server configured value :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query. :param principal: str (optional)   If provided, only the permissions for the specified principal (user or group) are returned.  :returns: :class:`GetPermissionsResponse`",grants,get,select,
catalog.json,/api/2.1/unity-catalog/permissions/{securable_type}/{full_name},grants_update,patch,UpdatePermissionsResponse,"catalog, grants","securable_type, full_name, changes",Updates the permissions for a securable.,Updates the permissions for a securable.  :param securable_type: str   Type of securable. :param full_name: str   Full name of securable. :param changes: List[:class:`PermissionsChange`] (optional)   Array of permissions change objects.  :returns: :class:`UpdatePermissionsResponse`,grants,update,update,
catalog.json,/api/2.1/unity-catalog/effective-permissions/{securable_type}/{full_name},grants_get_effective,get,EffectivePermissionsList,"catalog, grants","securable_type, full_name, max_results, page_token, principal",Gets the effective permissions for a securable. Includes inherited permissions from any parent,"Gets the effective permissions for a securable. Includes inherited permissions from any parent securables.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param securable_type: str   Type of securable. :param full_name: str   Full name of securable. :param max_results: int (optional)   Specifies the maximum number of privileges to return (page length). Every   EffectivePrivilegeAssignment present in a single page response is guaranteed to contain all the   effective privileges granted on (or inherited by) the requested Securable for the respective   principal.    If not set, all the effective permissions are returned. If set to - lesser than 0: invalid parameter   error - 0: page length is set to a server configured value - lesser than 150 but greater than 0:   invalid parameter error (this is to ensure that server is able to return at least one complete   EffectivePrivilegeAssignment in a single page response) - greater than (or equal to) 150: page   length is the minimum of this value and a server configured value :param page_token: str (optional)   Opaque token for the next page of results (pagination). :param principal: str (optional)   If provided, only the effective permissions for the specified principal (user or group) are   returned.  :returns: :class:`EffectivePermissionsList`",effective_grants,get,select,
catalog.json,/api/2.1/unity-catalog/workspaces/{workspace_id}/metastore,metastores_assign,put,,"catalog, metastores","workspace_id, metastore_id, default_catalog_name","Creates a new metastore assignment. If an assignment for the same __workspace_id__ exists, it will be","Creates a new metastore assignment. If an assignment for the same __workspace_id__ exists, it will be overwritten by the new __metastore_id__ and __default_catalog_name__. The caller must be an account admin.  :param workspace_id: int   A workspace ID. :param metastore_id: str   The unique ID of the metastore. :param default_catalog_name: str   The name of the default catalog in the metastore. This field is deprecated. Please use ""Default   Namespace API"" to configure the default catalog for a Databricks workspace.",metastores,assign,replace,
catalog.json,/api/2.1/unity-catalog/workspaces/{workspace_id}/metastore,metastores_unassign,delete,,"catalog, metastores","workspace_id, metastore_id",Deletes a metastore assignment. The caller must be an account administrator.,Deletes a metastore assignment. The caller must be an account administrator.  :param workspace_id: int   A workspace ID. :param metastore_id: str   Query for the ID of the metastore to delete.,metastores,unassign,delete,
catalog.json,/api/2.1/unity-catalog/workspaces/{workspace_id}/metastore,metastores_update_assignment,patch,,"catalog, metastores","workspace_id, default_catalog_name, metastore_id",Updates a metastore assignment. This operation can be used to update __metastore_id__ or,"Updates a metastore assignment. This operation can be used to update __metastore_id__ or __default_catalog_name__ for a specified Workspace, if the Workspace is already assigned a metastore. The caller must be an account admin to update __metastore_id__; otherwise, the caller can be a Workspace admin.  :param workspace_id: int   A workspace ID. :param default_catalog_name: str (optional)   The name of the default catalog in the metastore. This field is deprecated. Please use ""Default   Namespace API"" to configure the default catalog for a Databricks workspace. :param metastore_id: str (optional)   The unique ID of the metastore.",metastores,update_assignment,update,
catalog.json,/api/2.1/unity-catalog/metastores,metastores_create,post,MetastoreInfo,"catalog, metastores","name, external_access_enabled, region, storage_root",Creates a new metastore based on a provided name and optional storage root path. By default (if the,"Creates a new metastore based on a provided name and optional storage root path. By default (if the __owner__ field is not set), the owner of the new metastore is the user calling the __createMetastore__ API. If the __owner__ field is set to the empty string (**""""**), the ownership is assigned to the System User instead.  :param name: str   The user-specified name of the metastore. :param external_access_enabled: bool (optional)   Whether to allow non-DBR clients to directly access entities under the metastore. :param region: str (optional)   Cloud region which the metastore serves (e.g., `us-west-2`, `westus`). :param storage_root: str (optional)   The storage root URL for metastore  :returns: :class:`MetastoreInfo`",metastores,create,insert,
catalog.json,/api/2.1/unity-catalog/metastores,metastores_list,get,AccountsListMetastoresResponse,"catalog, metastores","max_results, page_token",Gets an array of the available metastores (as __MetastoreInfo__ objects). The caller must be an admin,"Gets an array of the available metastores (as __MetastoreInfo__ objects). The caller must be an admin to retrieve this info. There is no guarantee of a specific ordering of the elements in the array.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param max_results: int (optional)   Maximum number of metastores to return. - when set to a value greater than 0, the page length is the   minimum of this value and a server configured value; - when set to 0, the page length is set to a   server configured value (recommended); - when set to a value less than 0, an invalid parameter error   is returned; - If not set, all the metastores are returned (not recommended). - Note: The number of   returned metastores might be less than the specified max_results size, even zero. The only   definitive indication that no further metastores can be fetched is when the next_page_token is unset   from the response. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`MetastoreInfo`",metastores,list,select,$.metastores
catalog.json,/api/2.1/unity-catalog/current-metastore-assignment,metastores_current,get,MetastoreAssignment,"catalog, metastores",,Gets the metastore assignment for the workspace being accessed.,Gets the metastore assignment for the workspace being accessed.   :returns: :class:`MetastoreAssignment`,current_metastore_assignment,get,select,
catalog.json,/api/2.1/unity-catalog/metastores/{id},metastores_delete,delete,,"catalog, metastores","id, force",Deletes a metastore. The caller must be a metastore admin.,Deletes a metastore. The caller must be a metastore admin.  :param id: str   Unique ID of the metastore. :param force: bool (optional)   Force deletion even if the metastore is not empty. Default is false.,metastores,delete,delete,
catalog.json,/api/2.1/unity-catalog/metastores/{id},metastores_get,get,MetastoreInfo,"catalog, metastores",id,Gets a metastore that matches the supplied ID. The caller must be a metastore admin to retrieve this,Gets a metastore that matches the supplied ID. The caller must be a metastore admin to retrieve this info.  :param id: str   Unique ID of the metastore.  :returns: :class:`MetastoreInfo`,metastores,get,select,
catalog.json,/api/2.1/unity-catalog/metastores/{id},metastores_update,patch,MetastoreInfo,"catalog, metastores","id, delta_sharing_organization_name, delta_sharing_recipient_token_lifetime_in_seconds, delta_sharing_scope, external_access_enabled, new_name, owner, privilege_model_version, storage_root_credential_id",Updates information for a specific metastore. The caller must be a metastore admin. If the __owner__,"Updates information for a specific metastore. The caller must be a metastore admin. If the __owner__ field is set to the empty string (**""""**), the ownership is updated to the System User.  :param id: str   Unique ID of the metastore. :param delta_sharing_organization_name: str (optional)   The organization name of a Delta Sharing entity, to be used in Databricks-to-Databricks Delta   Sharing as the official name. :param delta_sharing_recipient_token_lifetime_in_seconds: int (optional)   The lifetime of delta sharing recipient token in seconds. :param delta_sharing_scope: :class:`DeltaSharingScopeEnum` (optional)   The scope of Delta Sharing enabled for the metastore. :param external_access_enabled: bool (optional)   Whether to allow non-DBR clients to directly access entities under the metastore. :param new_name: str (optional)   New name for the metastore. :param owner: str (optional)   The owner of the metastore. :param privilege_model_version: str (optional)   Privilege model version of the metastore, of the form `major.minor` (e.g., `1.0`). :param storage_root_credential_id: str (optional)   UUID of storage credential to access the metastore storage_root.  :returns: :class:`MetastoreInfo`",metastores,update,update,
catalog.json,/api/2.1/unity-catalog/metastore_summary,metastores_summary,get,GetMetastoreSummaryResponse,"catalog, metastores",,"Gets information about a metastore. This summary includes the storage credential, the cloud vendor,","Gets information about a metastore. This summary includes the storage credential, the cloud vendor, the cloud region, and the global metastore ID.   :returns: :class:`GetMetastoreSummaryResponse`",metastore_summary,get,select,
catalog.json,/api/2.1/unity-catalog/models/{full_name}/versions/{version},model_versions_delete,delete,,"catalog, model_versions","full_name, version",Deletes a model version from the specified registered model. Any aliases assigned to the model version,"Deletes a model version from the specified registered model. Any aliases assigned to the model version will also be deleted.  The caller must be a metastore admin or an owner of the parent registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   The three-level (fully qualified) name of the model version :param version: int   The integer version number of the model version",model_versions,delete,delete,
catalog.json,/api/2.1/unity-catalog/models/{full_name}/versions/{version},model_versions_get,get,ModelVersionInfo,"catalog, model_versions","full_name, version, include_aliases, include_browse",Get a model version.,"Get a model version.  The caller must be a metastore admin or an owner of (or have the **EXECUTE** privilege on) the parent registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   The three-level (fully qualified) name of the model version :param version: int   The integer version number of the model version :param include_aliases: bool (optional)   Whether to include aliases associated with the model version in the response :param include_browse: bool (optional)   Whether to include model versions in the response for which the principal can only access selective   metadata for  :returns: :class:`ModelVersionInfo`",model_versions,get,select,
catalog.json,/api/2.1/unity-catalog/models/{full_name}/versions/{version},model_versions_update,patch,ModelVersionInfo,"catalog, model_versions","full_name, version, aliases, catalog_name, comment, created_at, created_by, id, metastore_id, model_name, model_version_dependencies, run_id, run_workspace_id, schema_name, source, status, storage_location, updated_at, updated_by",Updates the specified model version.,"Updates the specified model version.  The caller must be a metastore admin or an owner of the parent registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  Currently only the comment of the model version can be updated.  :param full_name: str   The three-level (fully qualified) name of the model version :param version: int   The integer version number of the model version :param aliases: List[:class:`RegisteredModelAlias`] (optional)   List of aliases associated with the model version :param catalog_name: str (optional)   The name of the catalog containing the model version :param comment: str (optional)   The comment attached to the model version :param created_at: int (optional) :param created_by: str (optional)   The identifier of the user who created the model version :param id: str (optional)   The unique identifier of the model version :param metastore_id: str (optional)   The unique identifier of the metastore containing the model version :param model_name: str (optional)   The name of the parent registered model of the model version, relative to parent schema :param model_version_dependencies: :class:`DependencyList` (optional)   Model version dependencies, for feature-store packaged models :param run_id: str (optional)   MLflow run ID used when creating the model version, if ``source`` was generated by an experiment run   stored in an MLflow tracking server :param run_workspace_id: int (optional)   ID of the Databricks workspace containing the MLflow run that generated this model version, if   applicable :param schema_name: str (optional)   The name of the schema containing the model version, relative to parent catalog :param source: str (optional)   URI indicating the location of the source artifacts (files) for the model version :param status: :class:`ModelVersionInfoStatus` (optional)   Current status of the model version. Newly created model versions start in PENDING_REGISTRATION   status, then move to READY status once the model version files are uploaded and the model version is   finalized. Only model versions in READY status can be loaded for inference or served. :param storage_location: str (optional)   The storage location on the cloud under which model version data files are stored :param updated_at: int (optional) :param updated_by: str (optional)   The identifier of the user who updated the model version last time  :returns: :class:`ModelVersionInfo`",model_versions,update,update,
catalog.json,/api/2.1/unity-catalog/models/{full_name}/aliases/{alias},model_versions_get_by_alias,get,ModelVersionInfo,"catalog, model_versions","full_name, alias, include_aliases",Get a model version by alias.,"Get a model version by alias.  The caller must be a metastore admin or an owner of (or have the **EXECUTE** privilege on) the registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   The three-level (fully qualified) name of the registered model :param alias: str   The name of the alias :param include_aliases: bool (optional)   Whether to include aliases associated with the model version in the response  :returns: :class:`ModelVersionInfo`",model_versions,get_by_alias,select,
catalog.json,/api/2.1/unity-catalog/models/{full_name}/aliases/{alias},registered_models_delete_alias,delete,,"catalog, registered_models","full_name, alias",Deletes a registered model alias.,"Deletes a registered model alias.  The caller must be a metastore admin or an owner of the registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   The three-level (fully qualified) name of the registered model :param alias: str   The name of the alias",registered_models,delete_alias,delete,
catalog.json,/api/2.1/unity-catalog/models/{full_name}/aliases/{alias},registered_models_set_alias,put,RegisteredModelAlias,"catalog, registered_models","full_name, alias, version_num",Set an alias on the specified registered model.,"Set an alias on the specified registered model.  The caller must be a metastore admin or an owner of the registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   The three-level (fully qualified) name of the registered model :param alias: str   The name of the alias :param version_num: int   The version number of the model version to which the alias points  :returns: :class:`RegisteredModelAlias`",registered_models,set_alias,replace,
catalog.json,/api/2.1/unity-catalog/models/{full_name}/versions,model_versions_list,get,ListModelVersionsResponse,"catalog, model_versions","full_name, include_browse, max_results, page_token","List model versions. You can list model versions under a particular schema, or list all model versions","List model versions. You can list model versions under a particular schema, or list all model versions in the current metastore.  The returned models are filtered based on the privileges of the calling user. For example, the metastore admin is able to list all the model versions. A regular user needs to be the owner or have the **EXECUTE** privilege on the parent registered model to recieve the model versions in the response. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  There is no guarantee of a specific ordering of the elements in the response. The elements in the response will not contain any aliases or tags.  PAGINATION BEHAVIOR: The API is by default paginated, a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param full_name: str   The full three-level name of the registered model under which to list model versions :param include_browse: bool (optional)   Whether to include model versions in the response for which the principal can only access selective   metadata for :param max_results: int (optional)   Maximum number of model versions to return. If not set, the page length is set to a server   configured value (100, as of 1/3/2024). - when set to a value greater than 0, the page length is the   minimum of this value and a server configured value(1000, as of 1/3/2024); - when set to 0, the page   length is set to a server configured value (100, as of 1/3/2024) (recommended); - when set to a   value less than 0, an invalid parameter error is returned; :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`ModelVersionInfo`",model_versions,list,select,$.model_versions
catalog.json,/api/2.0/online-tables,online_tables_create,post,OnlineTable,"catalog, online_tables",table,Create a new Online Table.,Create a new Online Table.  :param table: :class:`OnlineTable`   Specification of the online table to be created.  :returns:   Long-running operation waiter for :class:`OnlineTable`.   See :method:wait_get_online_table_active for more details.,online_tables,create,insert,
catalog.json,/api/2.0/online-tables/{name},online_tables_delete,delete,,"catalog, online_tables",name,Delete an online table. Warning: This will delete all the data in the online table. If the source,"Delete an online table. Warning: This will delete all the data in the online table. If the source Delta table was deleted or modified since this Online Table was created, this will lose the data forever!  :param name: str   Full three-part (catalog, schema, table) name of the table.",online_tables,delete,delete,
catalog.json,/api/2.0/online-tables/{name},online_tables_get,get,OnlineTable,"catalog, online_tables",name,Get information about an existing online table and its status.,"Get information about an existing online table and its status.  :param name: str   Full three-part (catalog, schema, table) name of the table.  :returns: :class:`OnlineTable`",online_tables,get,select,
catalog.json,/api/2.1/unity-catalog/policies,policies_create_policy,post,PolicyInfo,"catalog, policies",policy_info,Creates a new policy on a securable. The new policy applies to the securable and all its descendants.,Creates a new policy on a securable. The new policy applies to the securable and all its descendants.  :param policy_info: :class:`PolicyInfo`   Required. The policy to create.  :returns: :class:`PolicyInfo`,policies,create,insert,
catalog.json,/api/2.1/unity-catalog/policies/{on_securable_type}/{on_securable_fullname}/{name},policies_delete_policy,delete,DeletePolicyResponse,"catalog, policies","on_securable_type, on_securable_fullname, name",Delete an ABAC policy defined on a securable.,Delete an ABAC policy defined on a securable.  :param on_securable_type: str   Required. The type of the securable to delete the policy from. :param on_securable_fullname: str   Required. The fully qualified name of the securable to delete the policy from. :param name: str   Required. The name of the policy to delete  :returns: :class:`DeletePolicyResponse`,policies,delete,delete,
catalog.json,/api/2.1/unity-catalog/policies/{on_securable_type}/{on_securable_fullname}/{name},policies_get_policy,get,PolicyInfo,"catalog, policies","on_securable_type, on_securable_fullname, name",Get the policy definition on a securable,Get the policy definition on a securable  :param on_securable_type: str   Required. The type of the securable to retrieve the policy for. :param on_securable_fullname: str   Required. The fully qualified name of securable to retrieve policy for. :param name: str   Required. The name of the policy to retrieve.  :returns: :class:`PolicyInfo`,policies,get,select,
catalog.json,/api/2.1/unity-catalog/policies/{on_securable_type}/{on_securable_fullname}/{name},policies_update_policy,patch,PolicyInfo,"catalog, policies","on_securable_type, on_securable_fullname, name, update_mask, policy_info",Update an ABAC policy on a securable.,"Update an ABAC policy on a securable.  :param on_securable_type: str   Required. The type of the securable to update the policy for. :param on_securable_fullname: str   Required. The fully qualified name of the securable to update the policy for. :param name: str   Required. The name of the policy to update. :param policy_info: :class:`PolicyInfo`   Optional fields to update. This is the request body for updating a policy. Use `update_mask` field   to specify which fields in the request is to be updated. - If `update_mask` is empty or ""*"", all   specified fields will be updated. - If `update_mask` is specified, only the fields specified in the   `update_mask` will be updated. If a field is specified in `update_mask` and not set in the request,   the field will be cleared. Users can use the update mask to explicitly unset optional fields such as   `exception_principals` and `when_condition`. :param update_mask: str (optional)   Optional. The update mask field for specifying user intentions on which fields to update in the   request.  :returns: :class:`PolicyInfo`",policies,update,update,
catalog.json,/api/2.1/unity-catalog/policies/{on_securable_type}/{on_securable_fullname},policies_list_policies,get,ListPoliciesResponse,"catalog, policies","on_securable_type, on_securable_fullname, include_inherited, max_results, page_token","List all policies defined on a securable. Optionally, the list can include inherited policies defined","List all policies defined on a securable. Optionally, the list can include inherited policies defined on the securable's parent schema or catalog.  PAGINATION BEHAVIOR: The API is by default paginated, a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param on_securable_type: str   Required. The type of the securable to list policies for. :param on_securable_fullname: str   Required. The fully qualified name of securable to list policies for. :param include_inherited: bool (optional)   Optional. Whether to include policies defined on parent securables. By default, the inherited   policies are not included. :param max_results: int (optional)   Optional. Maximum number of policies to return on a single page (page length). - When not set or set   to 0, the page length is set to a server configured value (recommended); - When set to a value   greater than 0, the page length is the minimum of this value and a server configured value; :param page_token: str (optional)   Optional. Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`PolicyInfo`",policies,list,select,$.policies
catalog.json,/api/2.1/unity-catalog/tables/{table_name}/monitor/refreshes/{refresh_id}/cancel,quality_monitors_cancel_refresh,post,,"catalog, quality_monitors","table_name, refresh_id",[DEPRECATED] Cancels an already-initiated refresh job. Use Data Quality Monitors API instead,[DEPRECATED] Cancels an already-initiated refresh job. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors).  :param table_name: str   UC table name in format `catalog.schema.table_name`. table_name is case insensitive and spaces are   disallowed. :param refresh_id: int,quality_monitors,cancel_refresh,exec,
catalog.json,/api/2.1/unity-catalog/tables/{table_name}/monitor,quality_monitors_create,post,MonitorInfo,"catalog, quality_monitors","table_name, output_schema_name, assets_dir, baseline_table_name, custom_metrics, data_classification_config, inference_log, latest_monitor_failure_msg, notifications, schedule, skip_builtin_dashboard, slicing_exprs, snapshot, time_series, warehouse_id",[DEPRECATED] Creates a new monitor for the specified table. Use Data Quality Monitors API instead,"[DEPRECATED] Creates a new monitor for the specified table. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors).  The caller must either: 1. be an owner of the table's parent catalog, have **USE_SCHEMA** on the table's parent schema, and have **SELECT** access on the table 2. have **USE_CATALOG** on the table's parent catalog, be an owner of the table's parent schema, and have **SELECT** access on the table. 3. have the following permissions: - **USE_CATALOG** on the table's parent catalog - **USE_SCHEMA** on the table's parent schema - be an owner of the table.  Workspace assets, such as the dashboard, will be created in the workspace where this call was made.  :param table_name: str   UC table name in format `catalog.schema.table_name`. This field corresponds to the   {full_table_name_arg} arg in the endpoint path. :param output_schema_name: str   [Create:REQ Update:REQ] Schema where output tables are created. Needs to be in 2-level format   {catalog}.{schema} :param assets_dir: str   [Create:REQ Update:IGN] Field for specifying the absolute path to a custom directory to store   data-monitoring assets. Normally prepopulated to a default user location via UI and Python APIs. :param baseline_table_name: str (optional)   [Create:OPT Update:OPT] Baseline table name. Baseline data is used to compute drift from the data in   the monitored `table_name`. The baseline table and the monitored table shall have the same schema. :param custom_metrics: List[:class:`MonitorMetric`] (optional)   [Create:OPT Update:OPT] Custom metrics. :param data_classification_config: :class:`MonitorDataClassificationConfig` (optional)   [Create:OPT Update:OPT] Data classification related config. :param inference_log: :class:`MonitorInferenceLog` (optional) :param latest_monitor_failure_msg: str (optional)   [Create:ERR Update:IGN] The latest error message for a monitor failure. :param notifications: :class:`MonitorNotifications` (optional)   [Create:OPT Update:OPT] Field for specifying notification settings. :param schedule: :class:`MonitorCronSchedule` (optional)   [Create:OPT Update:OPT] The monitor schedule. :param skip_builtin_dashboard: bool (optional)   Whether to skip creating a default dashboard summarizing data quality metrics. :param slicing_exprs: List[str] (optional)   [Create:OPT Update:OPT] List of column expressions to slice data with for targeted analysis. The   data is grouped by each expression independently, resulting in a separate slice for each predicate   and its complements. For example `slicing_exprs=[“col_1”, “col_2 > 10”]` will generate the   following slices: two slices for `col_2 > 10` (True and False), and one slice per unique value in   `col1`. For high-cardinality columns, only the top 100 unique values by frequency will generate   slices. :param snapshot: :class:`MonitorSnapshot` (optional)   Configuration for monitoring snapshot tables. :param time_series: :class:`MonitorTimeSeries` (optional)   Configuration for monitoring time series tables. :param warehouse_id: str (optional)   Optional argument to specify the warehouse for dashboard creation. If not specified, the first   running warehouse will be used.  :returns: :class:`MonitorInfo`",quality_monitors,create,insert,
catalog.json,/api/2.1/unity-catalog/tables/{table_name}/monitor,quality_monitors_delete,delete,DeleteMonitorResponse,"catalog, quality_monitors",table_name,[DEPRECATED] Deletes a monitor for the specified table. Use Data Quality Monitors API instead,"[DEPRECATED] Deletes a monitor for the specified table. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors).  The caller must either: 1. be an owner of the table's parent catalog 2. have **USE_CATALOG** on the table's parent catalog and be an owner of the table's parent schema 3. have the following permissions: - **USE_CATALOG** on the table's parent catalog - **USE_SCHEMA** on the table's parent schema - be an owner of the table.  Additionally, the call must be made from the workspace where the monitor was created.  Note that the metric tables and dashboard will not be deleted as part of this call; those assets must be manually cleaned up (if desired).  :param table_name: str   UC table name in format `catalog.schema.table_name`. This field corresponds to the   {full_table_name_arg} arg in the endpoint path.  :returns: :class:`DeleteMonitorResponse`",quality_monitors,delete,delete,
catalog.json,/api/2.1/unity-catalog/tables/{table_name}/monitor,quality_monitors_get,get,MonitorInfo,"catalog, quality_monitors",table_name,[DEPRECATED] Gets a monitor for the specified table. Use Data Quality Monitors API instead,"[DEPRECATED] Gets a monitor for the specified table. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors).  The caller must either: 1. be an owner of the table's parent catalog 2. have **USE_CATALOG** on the table's parent catalog and be an owner of the table's parent schema. 3. have the following permissions: - **USE_CATALOG** on the table's parent catalog - **USE_SCHEMA** on the table's parent schema - **SELECT** privilege on the table.  The returned information includes configuration values, as well as information on assets created by the monitor. Some information (e.g., dashboard) may be filtered out if the caller is in a different workspace than where the monitor was created.  :param table_name: str   UC table name in format `catalog.schema.table_name`. This field corresponds to the   {full_table_name_arg} arg in the endpoint path.  :returns: :class:`MonitorInfo`",quality_monitors,get,select,
catalog.json,/api/2.1/unity-catalog/tables/{table_name}/monitor,quality_monitors_update,put,MonitorInfo,"catalog, quality_monitors","table_name, output_schema_name, baseline_table_name, custom_metrics, dashboard_id, data_classification_config, inference_log, latest_monitor_failure_msg, notifications, schedule, slicing_exprs, snapshot, time_series",[DEPRECATED] Updates a monitor for the specified table. Use Data Quality Monitors API instead,"[DEPRECATED] Updates a monitor for the specified table. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors).  The caller must either: 1. be an owner of the table's parent catalog 2. have **USE_CATALOG** on the table's parent catalog and be an owner of the table's parent schema 3. have the following permissions: - **USE_CATALOG** on the table's parent catalog - **USE_SCHEMA** on the table's parent schema - be an owner of the table.  Additionally, the call must be made from the workspace where the monitor was created, and the caller must be the original creator of the monitor.  Certain configuration fields, such as output asset identifiers, cannot be updated.  :param table_name: str   UC table name in format `catalog.schema.table_name`. This field corresponds to the   {full_table_name_arg} arg in the endpoint path. :param output_schema_name: str   [Create:REQ Update:REQ] Schema where output tables are created. Needs to be in 2-level format   {catalog}.{schema} :param baseline_table_name: str (optional)   [Create:OPT Update:OPT] Baseline table name. Baseline data is used to compute drift from the data in   the monitored `table_name`. The baseline table and the monitored table shall have the same schema. :param custom_metrics: List[:class:`MonitorMetric`] (optional)   [Create:OPT Update:OPT] Custom metrics. :param dashboard_id: str (optional)   [Create:ERR Update:OPT] Id of dashboard that visualizes the computed metrics. This can be empty if   the monitor is in PENDING state. :param data_classification_config: :class:`MonitorDataClassificationConfig` (optional)   [Create:OPT Update:OPT] Data classification related config. :param inference_log: :class:`MonitorInferenceLog` (optional) :param latest_monitor_failure_msg: str (optional)   [Create:ERR Update:IGN] The latest error message for a monitor failure. :param notifications: :class:`MonitorNotifications` (optional)   [Create:OPT Update:OPT] Field for specifying notification settings. :param schedule: :class:`MonitorCronSchedule` (optional)   [Create:OPT Update:OPT] The monitor schedule. :param slicing_exprs: List[str] (optional)   [Create:OPT Update:OPT] List of column expressions to slice data with for targeted analysis. The   data is grouped by each expression independently, resulting in a separate slice for each predicate   and its complements. For example `slicing_exprs=[“col_1”, “col_2 > 10”]` will generate the   following slices: two slices for `col_2 > 10` (True and False), and one slice per unique value in   `col1`. For high-cardinality columns, only the top 100 unique values by frequency will generate   slices. :param snapshot: :class:`MonitorSnapshot` (optional)   Configuration for monitoring snapshot tables. :param time_series: :class:`MonitorTimeSeries` (optional)   Configuration for monitoring time series tables.  :returns: :class:`MonitorInfo`",quality_monitors,update,replace,
catalog.json,/api/2.1/unity-catalog/tables/{table_name}/monitor/refreshes/{refresh_id},quality_monitors_get_refresh,get,MonitorRefreshInfo,"catalog, quality_monitors","table_name, refresh_id",[DEPRECATED] Gets info about a specific monitor refresh using the given refresh ID. Use Data Quality,"[DEPRECATED] Gets info about a specific monitor refresh using the given refresh ID. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors).  The caller must either: 1. be an owner of the table's parent catalog 2. have **USE_CATALOG** on the table's parent catalog and be an owner of the table's parent schema 3. have the following permissions: - **USE_CATALOG** on the table's parent catalog - **USE_SCHEMA** on the table's parent schema - **SELECT** privilege on the table.  Additionally, the call must be made from the workspace where the monitor was created.  :param table_name: str   Full name of the table. :param refresh_id: int   ID of the refresh.  :returns: :class:`MonitorRefreshInfo`",quality_monitor_refreshes,get,select,
catalog.json,/api/2.1/unity-catalog/tables/{table_name}/monitor/refreshes,quality_monitors_list_refreshes,get,MonitorRefreshListResponse,"catalog, quality_monitors",table_name,[DEPRECATED] Gets an array containing the history of the most recent refreshes (up to 25) for this,"[DEPRECATED] Gets an array containing the history of the most recent refreshes (up to 25) for this table. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors).  The caller must either: 1. be an owner of the table's parent catalog 2. have **USE_CATALOG** on the table's parent catalog and be an owner of the table's parent schema 3. have the following permissions: - **USE_CATALOG** on the table's parent catalog - **USE_SCHEMA** on the table's parent schema - **SELECT** privilege on the table.  Additionally, the call must be made from the workspace where the monitor was created.  :param table_name: str   UC table name in format `catalog.schema.table_name`. table_name is case insensitive and spaces are   disallowed.  :returns: :class:`MonitorRefreshListResponse`",quality_monitor_refreshes,list,select,
catalog.json,/api/2.1/unity-catalog/tables/{table_name}/monitor/refreshes,quality_monitors_run_refresh,post,MonitorRefreshInfo,"catalog, quality_monitors",table_name,[DEPRECATED] Queues a metric refresh on the monitor for the specified table. Use Data Quality Monitors,"[DEPRECATED] Queues a metric refresh on the monitor for the specified table. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors). The refresh will execute in the background.  The caller must either: 1. be an owner of the table's parent catalog 2. have **USE_CATALOG** on the table's parent catalog and be an owner of the table's parent schema 3. have the following permissions: - **USE_CATALOG** on the table's parent catalog - **USE_SCHEMA** on the table's parent schema - be an owner of the table  Additionally, the call must be made from the workspace where the monitor was created.  :param table_name: str   UC table name in format `catalog.schema.table_name`. table_name is case insensitive and spaces are   disallowed.  :returns: :class:`MonitorRefreshInfo`",quality_monitor_refreshes,run,exec,
catalog.json,/api/2.1/quality-monitoring/tables/{table_name}/monitor/dashboard,quality_monitors_regenerate_dashboard,post,RegenerateDashboardResponse,"catalog, quality_monitors","table_name, warehouse_id",[DEPRECATED] Regenerates the monitoring dashboard for the specified table. Use Data Quality Monitors,"[DEPRECATED] Regenerates the monitoring dashboard for the specified table. Use Data Quality Monitors API instead (/api/data-quality/v1/monitors).  The caller must either: 1. be an owner of the table's parent catalog 2. have **USE_CATALOG** on the table's parent catalog and be an owner of the table's parent schema 3. have the following permissions: - **USE_CATALOG** on the table's parent catalog - **USE_SCHEMA** on the table's parent schema - be an owner of the table  The call must be made from the workspace where the monitor was created. The dashboard will be regenerated in the assets directory that was specified when the monitor was created.  :param table_name: str   UC table name in format `catalog.schema.table_name`. This field corresponds to the   {full_table_name_arg} arg in the endpoint path. :param warehouse_id: str (optional)   Optional argument to specify the warehouse for dashboard regeneration. If not specified, the first   running warehouse will be used.  :returns: :class:`RegenerateDashboardResponse`",quality_monitors,regenerate_dashboard,exec,
catalog.json,/api/2.1/unity-catalog/models,registered_models_create,post,RegisteredModelInfo,"catalog, registered_models","aliases, browse_only, catalog_name, comment, created_at, created_by, full_name, metastore_id, name, owner, schema_name, storage_location, updated_at, updated_by",Creates a new registered model in Unity Catalog.,"Creates a new registered model in Unity Catalog.  File storage for model versions in the registered model will be located in the default location which is specified by the parent schema, or the parent catalog, or the Metastore.  For registered model creation to succeed, the user must satisfy the following conditions: - The caller must be a metastore admin, or be the owner of the parent catalog and schema, or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema. - The caller must have the **CREATE MODEL** or **CREATE FUNCTION** privilege on the parent schema.  :param aliases: List[:class:`RegisteredModelAlias`] (optional)   List of aliases associated with the registered model :param browse_only: bool (optional)   Indicates whether the principal is limited to retrieving metadata for the associated object through   the BROWSE privilege when include_browse is enabled in the request. :param catalog_name: str (optional)   The name of the catalog where the schema and the registered model reside :param comment: str (optional)   The comment attached to the registered model :param created_at: int (optional)   Creation timestamp of the registered model in milliseconds since the Unix epoch :param created_by: str (optional)   The identifier of the user who created the registered model :param full_name: str (optional)   The three-level (fully qualified) name of the registered model :param metastore_id: str (optional)   The unique identifier of the metastore :param name: str (optional)   The name of the registered model :param owner: str (optional)   The identifier of the user who owns the registered model :param schema_name: str (optional)   The name of the schema where the registered model resides :param storage_location: str (optional)   The storage location on the cloud under which model version data files are stored :param updated_at: int (optional)   Last-update timestamp of the registered model in milliseconds since the Unix epoch :param updated_by: str (optional)   The identifier of the user who updated the registered model last time  :returns: :class:`RegisteredModelInfo`",registered_models,create,insert,
catalog.json,/api/2.1/unity-catalog/models,registered_models_list,get,ListRegisteredModelsResponse,"catalog, registered_models","catalog_name, include_browse, max_results, page_token, schema_name","List registered models. You can list registered models under a particular schema, or list all","List registered models. You can list registered models under a particular schema, or list all registered models in the current metastore.  The returned models are filtered based on the privileges of the calling user. For example, the metastore admin is able to list all the registered models. A regular user needs to be the owner or have the **EXECUTE** privilege on the registered model to recieve the registered models in the response. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  There is no guarantee of a specific ordering of the elements in the response.  PAGINATION BEHAVIOR: The API is by default paginated, a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param catalog_name: str (optional)   The identifier of the catalog under which to list registered models. If specified, schema_name must   be specified. :param include_browse: bool (optional)   Whether to include registered models in the response for which the principal can only access   selective metadata for :param max_results: int (optional)   Max number of registered models to return.    If both catalog and schema are specified: - when max_results is not specified, the page length is   set to a server configured value (10000, as of 4/2/2024). - when set to a value greater than 0, the   page length is the minimum of this value and a server configured value (10000, as of 4/2/2024); -   when set to 0, the page length is set to a server configured value (10000, as of 4/2/2024); - when   set to a value less than 0, an invalid parameter error is returned;    If neither schema nor catalog is specified: - when max_results is not specified, the page length is   set to a server configured value (100, as of 4/2/2024). - when set to a value greater than 0, the   page length is the minimum of this value and a server configured value (1000, as of 4/2/2024); -   when set to 0, the page length is set to a server configured value (100, as of 4/2/2024); - when set   to a value less than 0, an invalid parameter error is returned; :param page_token: str (optional)   Opaque token to send for the next page of results (pagination). :param schema_name: str (optional)   The identifier of the schema under which to list registered models. If specified, catalog_name must   be specified.  :returns: Iterator over :class:`RegisteredModelInfo`",registered_models,list,select,$.registered_models
catalog.json,/api/2.1/unity-catalog/models/{full_name},registered_models_delete,delete,,"catalog, registered_models",full_name,Deletes a registered model and all its model versions from the specified parent catalog and schema.,"Deletes a registered model and all its model versions from the specified parent catalog and schema.  The caller must be a metastore admin or an owner of the registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   The three-level (fully qualified) name of the registered model",registered_models,delete,delete,
catalog.json,/api/2.1/unity-catalog/models/{full_name},registered_models_get,get,RegisteredModelInfo,"catalog, registered_models","full_name, include_aliases, include_browse",Get a registered model.,"Get a registered model.  The caller must be a metastore admin or an owner of (or have the **EXECUTE** privilege on) the registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   The three-level (fully qualified) name of the registered model :param include_aliases: bool (optional)   Whether to include registered model aliases in the response :param include_browse: bool (optional)   Whether to include registered models in the response for which the principal can only access   selective metadata for  :returns: :class:`RegisteredModelInfo`",registered_models,get,select,
catalog.json,/api/2.1/unity-catalog/models/{full_name},registered_models_update,patch,RegisteredModelInfo,"catalog, registered_models","full_name, aliases, browse_only, catalog_name, comment, created_at, created_by, metastore_id, name, new_name, owner, schema_name, storage_location, updated_at, updated_by",Updates the specified registered model.,"Updates the specified registered model.  The caller must be a metastore admin or an owner of the registered model. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  Currently only the name, the owner or the comment of the registered model can be updated.  :param full_name: str   The three-level (fully qualified) name of the registered model :param aliases: List[:class:`RegisteredModelAlias`] (optional)   List of aliases associated with the registered model :param browse_only: bool (optional)   Indicates whether the principal is limited to retrieving metadata for the associated object through   the BROWSE privilege when include_browse is enabled in the request. :param catalog_name: str (optional)   The name of the catalog where the schema and the registered model reside :param comment: str (optional)   The comment attached to the registered model :param created_at: int (optional)   Creation timestamp of the registered model in milliseconds since the Unix epoch :param created_by: str (optional)   The identifier of the user who created the registered model :param metastore_id: str (optional)   The unique identifier of the metastore :param name: str (optional)   The name of the registered model :param new_name: str (optional)   New name for the registered model. :param owner: str (optional)   The identifier of the user who owns the registered model :param schema_name: str (optional)   The name of the schema where the registered model resides :param storage_location: str (optional)   The storage location on the cloud under which model version data files are stored :param updated_at: int (optional)   Last-update timestamp of the registered model in milliseconds since the Unix epoch :param updated_by: str (optional)   The identifier of the user who updated the registered model last time  :returns: :class:`RegisteredModelInfo`",registered_models,update,update,
catalog.json,/api/2.1/unity-catalog/resource-quotas/{parent_securable_type}/{parent_full_name}/{quota_name},resource_quotas_get_quota,get,GetQuotaResponse,"catalog, resource_quotas","parent_securable_type, parent_full_name, quota_name","The GetQuota API returns usage information for a single resource quota, defined as a child-parent","The GetQuota API returns usage information for a single resource quota, defined as a child-parent pair. This API also refreshes the quota count if it is out of date. Refreshes are triggered asynchronously. The updated count might not be returned in the first call.  :param parent_securable_type: str   Securable type of the quota parent. :param parent_full_name: str   Full name of the parent resource. Provide the metastore ID if the parent is a metastore. :param quota_name: str   Name of the quota. Follows the pattern of the quota type, with ""-quota"" added as a suffix.  :returns: :class:`GetQuotaResponse`",resource_quotas,get,select,
catalog.json,/api/2.1/unity-catalog/resource-quotas/all-resource-quotas,resource_quotas_list_quotas,get,ListQuotasResponse,"catalog, resource_quotas","max_results, page_token",ListQuotas returns all quota values under the metastore. There are no SLAs on the freshness of the,"ListQuotas returns all quota values under the metastore. There are no SLAs on the freshness of the counts returned. This API does not trigger a refresh of quota counts.  PAGINATION BEHAVIOR: The API is by default paginated, a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param max_results: int (optional)   The number of quotas to return. :param page_token: str (optional)   Opaque token for the next page of results.  :returns: Iterator over :class:`QuotaInfo`",resource_quotas,list,select,$.quotas
catalog.json,/api/3.0/rfa/requests,rfa_batch_create_access_requests,post,BatchCreateAccessRequestsResponse,"catalog, rfa",requests,Creates access requests for Unity Catalog permissions for a specified principal on a securable object.,"Creates access requests for Unity Catalog permissions for a specified principal on a securable object. This Batch API can take in multiple principals, securable objects, and permissions as the input and returns the access request destinations for each. Principals must be unique across the API call.  The supported securable types are: ""metastore"", ""catalog"", ""schema"", ""table"", ""external_location"", ""connection"", ""credential"", ""function"", ""registered_model"", and ""volume"".  :param requests: List[:class:`CreateAccessRequest`] (optional)   A list of individual access requests, where each request corresponds to a set of permissions being   requested on a list of securables for a specified principal.    At most 30 requests per API call.  :returns: :class:`BatchCreateAccessRequestsResponse`",rfa,batch_create,insert,
catalog.json,/api/3.0/rfa/destinations/{securable_type}/{full_name},rfa_get_access_request_destinations,get,AccessRequestDestinations,"catalog, rfa","securable_type, full_name",Gets an array of access request destinations for the specified securable. Any caller can see URL,"Gets an array of access request destinations for the specified securable. Any caller can see URL destinations or the destinations on the metastore. Otherwise, only those with **BROWSE** permissions on the securable can see destinations.  The supported securable types are: ""metastore"", ""catalog"", ""schema"", ""table"", ""external_location"", ""connection"", ""credential"", ""function"", ""registered_model"", and ""volume"".  :param securable_type: str   The type of the securable. :param full_name: str   The full name of the securable.  :returns: :class:`AccessRequestDestinations`",rfa,get_destinations,select,
catalog.json,/api/3.0/rfa/destinations,rfa_update_access_request_destinations,patch,AccessRequestDestinations,"catalog, rfa","update_mask, access_request_destinations","Updates the access request destinations for the given securable. The caller must be a metastore admin,","Updates the access request destinations for the given securable. The caller must be a metastore admin, the owner of the securable, or a user that has the **MANAGE** privilege on the securable in order to assign destinations. Destinations cannot be updated for securables underneath schemas (tables, volumes, functions, and models). For these securable types, destinations are inherited from the parent securable. A maximum of 5 emails and 5 external notification destinations (Slack, Microsoft Teams, and Generic Webhook destinations) can be assigned to a securable. If a URL destination is assigned, no other destinations can be set.  The supported securable types are: ""metastore"", ""catalog"", ""schema"", ""table"", ""external_location"", ""connection"", ""credential"", ""function"", ""registered_model"", and ""volume"".  :param access_request_destinations: :class:`AccessRequestDestinations`   The access request destinations to assign to the securable. For each destination, a   **destination_id** and **destination_type** must be defined. :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`AccessRequestDestinations`",rfa,update_destinations,update,
catalog.json,/api/2.1/unity-catalog/schemas,schemas_create,post,SchemaInfo,"catalog, schemas","name, catalog_name, comment, properties, storage_root","Creates a new schema for catalog in the Metastore. The caller must be a metastore admin, or have the","Creates a new schema for catalog in the Metastore. The caller must be a metastore admin, or have the **CREATE_SCHEMA** privilege in the parent catalog.  :param name: str   Name of schema, relative to parent catalog. :param catalog_name: str   Name of parent catalog. :param comment: str (optional)   User-provided free-form text description. :param properties: Dict[str,str] (optional)   A map of key-value properties attached to the securable. :param storage_root: str (optional)   Storage root URL for managed tables within schema.  :returns: :class:`SchemaInfo`",schemas,create,insert,
catalog.json,/api/2.1/unity-catalog/schemas,schemas_list,get,ListSchemasResponse,"catalog, schemas","catalog_name, include_browse, max_results, page_token",Gets an array of schemas for a catalog in the metastore. If the caller is the metastore admin or the,"Gets an array of schemas for a catalog in the metastore. If the caller is the metastore admin or the owner of the parent catalog, all schemas for the catalog will be retrieved. Otherwise, only schemas owned by the caller (or for which the caller has the **USE_SCHEMA** privilege) will be retrieved. There is no guarantee of a specific ordering of the elements in the array.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param catalog_name: str   Parent catalog for schemas of interest. :param include_browse: bool (optional)   Whether to include schemas in the response for which the principal can only access selective   metadata for :param max_results: int (optional)   Maximum number of schemas to return. If not set, all the schemas are returned (not recommended). -   when set to a value greater than 0, the page length is the minimum of this value and a server   configured value; - when set to 0, the page length is set to a server configured value   (recommended); - when set to a value less than 0, an invalid parameter error is returned; :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`SchemaInfo`",schemas,list,select,$.schemas
catalog.json,/api/2.1/unity-catalog/schemas/{full_name},schemas_delete,delete,,"catalog, schemas","full_name, force",Deletes the specified schema from the parent catalog. The caller must be the owner of the schema or an,Deletes the specified schema from the parent catalog. The caller must be the owner of the schema or an owner of the parent catalog.  :param full_name: str   Full name of the schema. :param force: bool (optional)   Force deletion even if the schema is not empty.,schemas,delete,delete,
catalog.json,/api/2.1/unity-catalog/schemas/{full_name},schemas_get,get,SchemaInfo,"catalog, schemas","full_name, include_browse","Gets the specified schema within the metastore. The caller must be a metastore admin, the owner of the","Gets the specified schema within the metastore. The caller must be a metastore admin, the owner of the schema, or a user that has the **USE_SCHEMA** privilege on the schema.  :param full_name: str   Full name of the schema. :param include_browse: bool (optional)   Whether to include schemas in the response for which the principal can only access selective   metadata for  :returns: :class:`SchemaInfo`",schemas,get,select,
catalog.json,/api/2.1/unity-catalog/schemas/{full_name},schemas_update,patch,SchemaInfo,"catalog, schemas","full_name, comment, enable_predictive_optimization, new_name, owner, properties",Updates a schema for a catalog. The caller must be the owner of the schema or a metastore admin. If,"Updates a schema for a catalog. The caller must be the owner of the schema or a metastore admin. If the caller is a metastore admin, only the __owner__ field can be changed in the update. If the __name__ field must be updated, the caller must be a metastore admin or have the **CREATE_SCHEMA** privilege on the parent catalog.  :param full_name: str   Full name of the schema. :param comment: str (optional)   User-provided free-form text description. :param enable_predictive_optimization: :class:`EnablePredictiveOptimization` (optional)   Whether predictive optimization should be enabled for this object and objects under it. :param new_name: str (optional)   New name for the schema. :param owner: str (optional)   Username of current owner of schema. :param properties: Dict[str,str] (optional)   A map of key-value properties attached to the securable.  :returns: :class:`SchemaInfo`",schemas,update,update,
catalog.json,/api/2.1/unity-catalog/storage-credentials,storage_credentials_create,post,StorageCredentialInfo,"catalog, storage_credentials","name, aws_iam_role, azure_managed_identity, azure_service_principal, cloudflare_api_token, comment, databricks_gcp_service_account, read_only, skip_validation",Creates a new storage credential.,Creates a new storage credential.  The caller must be a metastore admin or have the **CREATE_STORAGE_CREDENTIAL** privilege on the metastore.  :param name: str   The credential name. The name must be unique among storage and service credentials within the   metastore. :param aws_iam_role: :class:`AwsIamRoleRequest` (optional)   The AWS IAM role configuration. :param azure_managed_identity: :class:`AzureManagedIdentityRequest` (optional)   The Azure managed identity configuration. :param azure_service_principal: :class:`AzureServicePrincipal` (optional)   The Azure service principal configuration. :param cloudflare_api_token: :class:`CloudflareApiToken` (optional)   The Cloudflare API token configuration. :param comment: str (optional)   Comment associated with the credential. :param databricks_gcp_service_account: :class:`DatabricksGcpServiceAccountRequest` (optional)   The Databricks managed GCP service account configuration. :param read_only: bool (optional)   Whether the credential is usable only for read operations. Only applicable when purpose is   **STORAGE**. :param skip_validation: bool (optional)   Supplying true to this argument skips validation of the created credential.  :returns: :class:`StorageCredentialInfo`,storage_credentials,create,insert,
catalog.json,/api/2.1/unity-catalog/storage-credentials,storage_credentials_list,get,ListAccountStorageCredentialsResponse,"catalog, storage_credentials","include_unbound, max_results, page_token",Gets an array of storage credentials (as __StorageCredentialInfo__ objects). The array is limited to,"Gets an array of storage credentials (as __StorageCredentialInfo__ objects). The array is limited to only those storage credentials the caller has permission to access. If the caller is a metastore admin, retrieval of credentials is unrestricted. There is no guarantee of a specific ordering of the elements in the array.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param include_unbound: bool (optional)   Whether to include credentials not bound to the workspace. Effective only if the user has permission   to update the credential–workspace binding. :param max_results: int (optional)   Maximum number of storage credentials to return. If not set, all the storage credentials are   returned (not recommended). - when set to a value greater than 0, the page length is the minimum of   this value and a server configured value; - when set to 0, the page length is set to a server   configured value (recommended); - when set to a value less than 0, an invalid parameter error is   returned; :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`StorageCredentialInfo`",storage_credentials,list,select,$.storage_credentials
catalog.json,/api/2.1/unity-catalog/storage-credentials/{name},storage_credentials_delete,delete,,"catalog, storage_credentials","name, force",Deletes a storage credential from the metastore. The caller must be an owner of the storage,Deletes a storage credential from the metastore. The caller must be an owner of the storage credential.  :param name: str   Name of the storage credential. :param force: bool (optional)   Force an update even if there are dependent external locations or external tables (when purpose is   **STORAGE**) or dependent services (when purpose is **SERVICE**).,storage_credentials,delete,delete,
catalog.json,/api/2.1/unity-catalog/storage-credentials/{name},storage_credentials_get,get,StorageCredentialInfo,"catalog, storage_credentials",name,"Gets a storage credential from the metastore. The caller must be a metastore admin, the owner of the","Gets a storage credential from the metastore. The caller must be a metastore admin, the owner of the storage credential, or have some permission on the storage credential.  :param name: str   Name of the storage credential.  :returns: :class:`StorageCredentialInfo`",storage_credentials,get,select,
catalog.json,/api/2.1/unity-catalog/storage-credentials/{name},storage_credentials_update,patch,StorageCredentialInfo,"catalog, storage_credentials","name, aws_iam_role, azure_managed_identity, azure_service_principal, cloudflare_api_token, comment, databricks_gcp_service_account, force, isolation_mode, new_name, owner, read_only, skip_validation",Updates a storage credential on the metastore.,"Updates a storage credential on the metastore.  The caller must be the owner of the storage credential or a metastore admin. If the caller is a metastore admin, only the **owner** field can be changed.  :param name: str   Name of the storage credential. :param aws_iam_role: :class:`AwsIamRoleRequest` (optional)   The AWS IAM role configuration. :param azure_managed_identity: :class:`AzureManagedIdentityResponse` (optional)   The Azure managed identity configuration. :param azure_service_principal: :class:`AzureServicePrincipal` (optional)   The Azure service principal configuration. :param cloudflare_api_token: :class:`CloudflareApiToken` (optional)   The Cloudflare API token configuration. :param comment: str (optional)   Comment associated with the credential. :param databricks_gcp_service_account: :class:`DatabricksGcpServiceAccountRequest` (optional)   The Databricks managed GCP service account configuration. :param force: bool (optional)   Force update even if there are dependent external locations or external tables. :param isolation_mode: :class:`IsolationMode` (optional)   Whether the current securable is accessible from all workspaces or a specific set of workspaces. :param new_name: str (optional)   New name for the storage credential. :param owner: str (optional)   Username of current owner of credential. :param read_only: bool (optional)   Whether the credential is usable only for read operations. Only applicable when purpose is   **STORAGE**. :param skip_validation: bool (optional)   Supplying true to this argument skips validation of the updated credential.  :returns: :class:`StorageCredentialInfo`",storage_credentials,update,update,
catalog.json,/api/2.1/unity-catalog/validate-storage-credentials,storage_credentials_validate,post,ValidateStorageCredentialResponse,"catalog, storage_credentials","aws_iam_role, azure_managed_identity, azure_service_principal, cloudflare_api_token, databricks_gcp_service_account, external_location_name, read_only, storage_credential_name, url",Validates a storage credential. At least one of __external_location_name__ and __url__ need to be,"Validates a storage credential. At least one of __external_location_name__ and __url__ need to be provided. If only one of them is provided, it will be used for validation. And if both are provided, the __url__ will be used for validation, and __external_location_name__ will be ignored when checking overlapping urls.  Either the __storage_credential_name__ or the cloud-specific credential must be provided.  The caller must be a metastore admin or the storage credential owner or have the **CREATE_EXTERNAL_LOCATION** privilege on the metastore and the storage credential.  :param aws_iam_role: :class:`AwsIamRoleRequest` (optional)   The AWS IAM role configuration. :param azure_managed_identity: :class:`AzureManagedIdentityRequest` (optional)   The Azure managed identity configuration. :param azure_service_principal: :class:`AzureServicePrincipal` (optional)   The Azure service principal configuration. :param cloudflare_api_token: :class:`CloudflareApiToken` (optional)   The Cloudflare API token configuration. :param databricks_gcp_service_account: :class:`DatabricksGcpServiceAccountRequest` (optional)   The Databricks created GCP service account configuration. :param external_location_name: str (optional)   The name of an existing external location to validate. :param read_only: bool (optional)   Whether the storage credential is only usable for read operations. :param storage_credential_name: str (optional)   Required. The name of an existing credential or long-lived cloud credential to validate. :param url: str (optional)   The external location url to validate.  :returns: :class:`ValidateStorageCredentialResponse`",storage_credentials,validate,exec,
catalog.json,/api/2.1/unity-catalog/metastores/{metastore_id}/systemschemas/{schema_name},system_schemas_disable,delete,,"catalog, system_schemas","metastore_id, schema_name",Disables the system schema and removes it from the system catalog. The caller must be an account admin,Disables the system schema and removes it from the system catalog. The caller must be an account admin or a metastore admin.  :param metastore_id: str   The metastore ID under which the system schema lives. :param schema_name: str   Full name of the system schema.,system_schemas,disable,delete,
catalog.json,/api/2.1/unity-catalog/metastores/{metastore_id}/systemschemas/{schema_name},system_schemas_enable,put,,"catalog, system_schemas","metastore_id, schema_name, catalog_name",Enables the system schema and adds it to the system catalog. The caller must be an account admin or a,Enables the system schema and adds it to the system catalog. The caller must be an account admin or a metastore admin.  :param metastore_id: str   The metastore ID under which the system schema lives. :param schema_name: str   Full name of the system schema. :param catalog_name: str (optional)   the catalog for which the system schema is to enabled in,system_schemas,enable,replace,
catalog.json,/api/2.1/unity-catalog/metastores/{metastore_id}/systemschemas,system_schemas_list,get,ListSystemSchemasResponse,"catalog, system_schemas","metastore_id, max_results, page_token",Gets an array of system schemas for a metastore. The caller must be an account admin or a metastore,"Gets an array of system schemas for a metastore. The caller must be an account admin or a metastore admin.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param metastore_id: str   The ID for the metastore in which the system schema resides. :param max_results: int (optional)   Maximum number of schemas to return. - When set to 0, the page length is set to a server configured   value (recommended); - When set to a value greater than 0, the page length is the minimum of this   value and a server configured value; - When set to a value less than 0, an invalid parameter error   is returned; - If not set, all the schemas are returned (not recommended). :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`SystemSchemaInfo`",system_schemas,list,select,$.schemas
catalog.json,/api/2.1/unity-catalog/constraints,table_constraints_create,post,TableConstraint,"catalog, table_constraints","full_name_arg, constraint",Creates a new table constraint.,"Creates a new table constraint.  For the table constraint creation to succeed, the user must satisfy both of these conditions: - the user must have the **USE_CATALOG** privilege on the table's parent catalog, the **USE_SCHEMA** privilege on the table's parent schema, and be the owner of the table. - if the new constraint is a __ForeignKeyConstraint__, the user must have the **USE_CATALOG** privilege on the referenced parent table's catalog, the **USE_SCHEMA** privilege on the referenced parent table's schema, and be the owner of the referenced parent table.  :param full_name_arg: str   The full name of the table referenced by the constraint. :param constraint: :class:`TableConstraint`  :returns: :class:`TableConstraint`",table_constraints,create,insert,
catalog.json,/api/2.1/unity-catalog/constraints/{full_name},table_constraints_delete,delete,,"catalog, table_constraints","full_name, constraint_name, cascade",Deletes a table constraint.,"Deletes a table constraint.  For the table constraint deletion to succeed, the user must satisfy both of these conditions: - the user must have the **USE_CATALOG** privilege on the table's parent catalog, the **USE_SCHEMA** privilege on the table's parent schema, and be the owner of the table. - if __cascade__ argument is **true**, the user must have the following permissions on all of the child tables: the **USE_CATALOG** privilege on the table's catalog, the **USE_SCHEMA** privilege on the table's schema, and be the owner of the table.  :param full_name: str   Full name of the table referenced by the constraint. :param constraint_name: str   The name of the constraint to delete. :param cascade: bool   If true, try deleting all child constraints of the current constraint. If false, reject this   operation if the current constraint has any child constraints.",table_constraints,delete,delete,
catalog.json,/api/2.1/unity-catalog/tables,tables_create,post,TableInfo,"catalog, tables","name, catalog_name, schema_name, table_type, data_source_format, storage_location, columns, properties",Creates a new table in the specified catalog and schema.,"Creates a new table in the specified catalog and schema.  To create an external delta table, the caller must have the **EXTERNAL_USE_SCHEMA** privilege on the parent schema and the **EXTERNAL_USE_LOCATION** privilege on the external location. These privileges must always be granted explicitly, and cannot be inherited through ownership or **ALL_PRIVILEGES**.  Standard UC permissions needed to create tables still apply: **USE_CATALOG** on the parent catalog (or ownership of the parent catalog), **CREATE_TABLE** and **USE_SCHEMA** on the parent schema (or ownership of the parent schema), and **CREATE_EXTERNAL_TABLE** on external location.  The **columns** field needs to be in a Spark compatible format, so we recommend you use Spark to create these tables. The API itself does not validate the correctness of the column spec. If the spec is not Spark compatible, the tables may not be readable by Databricks Runtime.  NOTE: The Create Table API for external clients only supports creating **external delta tables**. The values shown in the respective enums are all values supported by Databricks, however for this specific Create Table API, only **table_type** **EXTERNAL** and **data_source_format** **DELTA** are supported. Additionally, column masks are not supported when creating tables through this API.  :param name: str   Name of table, relative to parent schema. :param catalog_name: str   Name of parent catalog. :param schema_name: str   Name of parent schema relative to its parent catalog. :param table_type: :class:`TableType` :param data_source_format: :class:`DataSourceFormat` :param storage_location: str   Storage root URL for table (for **MANAGED**, **EXTERNAL** tables). :param columns: List[:class:`ColumnInfo`] (optional)   The array of __ColumnInfo__ definitions of the table's columns. :param properties: Dict[str,str] (optional)   A map of key-value properties attached to the securable.  :returns: :class:`TableInfo`",tables,create,insert,
catalog.json,/api/2.1/unity-catalog/tables,tables_list,get,ListTablesResponse,"catalog, tables","catalog_name, schema_name, include_browse, include_manifest_capabilities, max_results, omit_columns, omit_properties, omit_username, page_token",Gets an array of all tables for the current metastore under the parent catalog and schema. The caller,"Gets an array of all tables for the current metastore under the parent catalog and schema. The caller must be a metastore admin or an owner of (or have the **SELECT** privilege on) the table. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema. There is no guarantee of a specific ordering of the elements in the array.  NOTE: **view_dependencies** and **table_constraints** are not returned by ListTables queries.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param catalog_name: str   Name of parent catalog for tables of interest. :param schema_name: str   Parent schema of tables. :param include_browse: bool (optional)   Whether to include tables in the response for which the principal can only access selective metadata   for. :param include_manifest_capabilities: bool (optional)   Whether to include a manifest containing table capabilities in the response. :param max_results: int (optional)   Maximum number of tables to return. If not set, all the tables are returned (not recommended). -   when set to a value greater than 0, the page length is the minimum of this value and a server   configured value; - when set to 0, the page length is set to a server configured value   (recommended); - when set to a value less than 0, an invalid parameter error is returned; :param omit_columns: bool (optional)   Whether to omit the columns of the table from the response or not. :param omit_properties: bool (optional)   Whether to omit the properties of the table from the response or not. :param omit_username: bool (optional)   Whether to omit the username of the table (e.g. owner, updated_by, created_by) from the response or   not. :param page_token: str (optional)   Opaque token to send for the next page of results (pagination).  :returns: Iterator over :class:`TableInfo`",tables,list,select,$.tables
catalog.json,/api/2.1/unity-catalog/tables/{full_name},tables_delete,delete,,"catalog, tables",full_name,Deletes a table from the specified parent catalog and schema. The caller must be the owner of the,"Deletes a table from the specified parent catalog and schema. The caller must be the owner of the parent catalog, have the **USE_CATALOG** privilege on the parent catalog and be the owner of the parent schema, or be the owner of the table and have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   Full name of the table.",tables,delete,delete,
catalog.json,/api/2.1/unity-catalog/tables/{full_name},tables_get,get,TableInfo,"catalog, tables","full_name, include_browse, include_delta_metadata, include_manifest_capabilities",Gets a table from the metastore for a specific catalog and schema. The caller must satisfy one of the,"Gets a table from the metastore for a specific catalog and schema. The caller must satisfy one of the following requirements: * Be a metastore admin * Be the owner of the parent catalog * Be the owner of the parent schema and have the **USE_CATALOG** privilege on the parent catalog * Have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema, and either be the table owner or have the **SELECT** privilege on the table.  :param full_name: str   Full name of the table. :param include_browse: bool (optional)   Whether to include tables in the response for which the principal can only access selective metadata   for. :param include_delta_metadata: bool (optional)   Whether delta metadata should be included in the response. :param include_manifest_capabilities: bool (optional)   Whether to include a manifest containing table capabilities in the response.  :returns: :class:`TableInfo`",tables,get,select,
catalog.json,/api/2.1/unity-catalog/tables/{full_name},tables_update,patch,,"catalog, tables","full_name, owner","Change the owner of the table. The caller must be the owner of the parent catalog, have the","Change the owner of the table. The caller must be the owner of the parent catalog, have the **USE_CATALOG** privilege on the parent catalog and be the owner of the parent schema, or be the owner of the table and have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param full_name: str   Full name of the table. :param owner: str (optional)   Username of current owner of table.",tables,update,update,
catalog.json,/api/2.1/unity-catalog/tables/{full_name}/exists,tables_exists,get,TableExistsResponse,"catalog, tables",full_name,Gets if a table exists in the metastore for a specific catalog and schema. The caller must satisfy one,"Gets if a table exists in the metastore for a specific catalog and schema. The caller must satisfy one of the following requirements: * Be a metastore admin * Be the owner of the parent catalog * Be the owner of the parent schema and have the **USE_CATALOG** privilege on the parent catalog * Have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema, and either be the table owner or have the **SELECT** privilege on the table. * Have **BROWSE** privilege on the parent catalog * Have **BROWSE** privilege on the parent schema  :param full_name: str   Full name of the table.  :returns: :class:`TableExistsResponse`",tables,exists,exec,
catalog.json,/api/2.1/unity-catalog/table-summaries,tables_list_summaries,get,ListTableSummariesResponse,"catalog, tables","catalog_name, include_manifest_capabilities, max_results, page_token, schema_name_pattern, table_name_pattern",Gets an array of summaries for tables for a schema and catalog within the metastore. The table,"Gets an array of summaries for tables for a schema and catalog within the metastore. The table summaries returned are either:  * summaries for tables (within the current metastore and parent catalog and schema), when the user is a metastore admin, or: * summaries for tables and schemas (within the current metastore and parent catalog) for which the user has ownership or the **SELECT** privilege on the table and ownership or **USE_SCHEMA** privilege on the schema, provided that the user also has ownership or the **USE_CATALOG** privilege on the parent catalog.  There is no guarantee of a specific ordering of the elements in the array.  PAGINATION BEHAVIOR: The API is by default paginated, a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param catalog_name: str   Name of parent catalog for tables of interest. :param include_manifest_capabilities: bool (optional)   Whether to include a manifest containing table capabilities in the response. :param max_results: int (optional)   Maximum number of summaries for tables to return. If not set, the page length is set to a server   configured value (10000, as of 1/5/2024). - when set to a value greater than 0, the page length is   the minimum of this value and a server configured value (10000, as of 1/5/2024); - when set to 0,   the page length is set to a server configured value (10000, as of 1/5/2024) (recommended); - when   set to a value less than 0, an invalid parameter error is returned; :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query. :param schema_name_pattern: str (optional)   A sql LIKE pattern (% and _) for schema names. All schemas will be returned if not set or empty. :param table_name_pattern: str (optional)   A sql LIKE pattern (% and _) for table names. All tables will be returned if not set or empty.  :returns: Iterator over :class:`TableSummary`",table_summaries,list,select,$.tables
catalog.json,/api/2.0/unity-catalog/temporary-path-credentials,temporary_path_credentials_generate_temporary_path_credentials,post,GenerateTemporaryPathCredentialResponse,"catalog, temporary_path_credentials","url, operation, dry_run",Get a short-lived credential for directly accessing cloud storage locations registered in Databricks.,"Get a short-lived credential for directly accessing cloud storage locations registered in Databricks. The Generate Temporary Path Credentials API is only supported for external storage paths, specifically external locations and external tables. Managed tables are not supported by this API. The metastore must have **external_access_enabled** flag set to true (default false). The caller must have the **EXTERNAL_USE_LOCATION** privilege on the external location; this privilege can only be granted by external location owners. For requests on existing external tables, the caller must also have the **EXTERNAL_USE_SCHEMA** privilege on the parent schema; this privilege can only be granted by catalog owners.  :param url: str   URL for path-based access. :param operation: :class:`PathOperation`   The operation being performed on the path. :param dry_run: bool (optional)   Optional. When set to true, the service will not validate that the generated credentials can perform   write operations, therefore no new paths will be created and the response will not contain valid   credentials. Defaults to false.  :returns: :class:`GenerateTemporaryPathCredentialResponse`",temporary_path_credentials,generate,insert,
catalog.json,/api/2.0/unity-catalog/temporary-table-credentials,temporary_table_credentials_generate_temporary_table_credentials,post,GenerateTemporaryTableCredentialResponse,"catalog, temporary_table_credentials","operation, table_id",Get a short-lived credential for directly accessing the table data on cloud storage. The metastore,"Get a short-lived credential for directly accessing the table data on cloud storage. The metastore must have **external_access_enabled** flag set to true (default false). The caller must have the **EXTERNAL_USE_SCHEMA** privilege on the parent schema and this privilege can only be granted by catalog owners.  :param operation: :class:`TableOperation` (optional)   The operation performed against the table data, either READ or READ_WRITE. If READ_WRITE is   specified, the credentials returned will have write permissions, otherwise, it will be read only. :param table_id: str (optional)   UUID of the table to read or write.  :returns: :class:`GenerateTemporaryTableCredentialResponse`",temporary_table_credentials,generate,insert,
catalog.json,/api/2.1/unity-catalog/volumes,volumes_create,post,VolumeInfo,"catalog, volumes","catalog_name, schema_name, name, volume_type, comment, storage_location",Creates a new volume.,"Creates a new volume.  The user could create either an external volume or a managed volume. An external volume will be created in the specified external location, while a managed volume will be located in the default location which is specified by the parent schema, or the parent catalog, or the Metastore.  For the volume creation to succeed, the user must satisfy following conditions: - The caller must be a metastore admin, or be the owner of the parent catalog and schema, or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema. - The caller must have **CREATE VOLUME** privilege on the parent schema.  For an external volume, following conditions also need to satisfy - The caller must have **CREATE EXTERNAL VOLUME** privilege on the external location. - There are no other tables, nor volumes existing in the specified storage location. - The specified storage location is not under the location of other tables, nor volumes, or catalogs or schemas.  :param catalog_name: str   The name of the catalog where the schema and the volume are :param schema_name: str   The name of the schema where the volume is :param name: str   The name of the volume :param volume_type: :class:`VolumeType`   The type of the volume. An external volume is located in the specified external location. A managed   volume is located in the default location which is specified by the parent schema, or the parent   catalog, or the Metastore. [Learn more]    [Learn more]: https://docs.databricks.com/aws/en/volumes/managed-vs-external :param comment: str (optional)   The comment attached to the volume :param storage_location: str (optional)   The storage location on the cloud  :returns: :class:`VolumeInfo`",volumes,create,insert,
catalog.json,/api/2.1/unity-catalog/volumes,volumes_list,get,ListVolumesResponseContent,"catalog, volumes","catalog_name, schema_name, include_browse, max_results, page_token",Gets an array of volumes for the current metastore under the parent catalog and schema.,"Gets an array of volumes for the current metastore under the parent catalog and schema.  The returned volumes are filtered based on the privileges of the calling user. For example, the metastore admin is able to list all the volumes. A regular user needs to be the owner or have the **READ VOLUME** privilege on the volume to receive the volumes in the response. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  There is no guarantee of a specific ordering of the elements in the array.  PAGINATION BEHAVIOR: The API is by default paginated, a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param catalog_name: str   The identifier of the catalog :param schema_name: str   The identifier of the schema :param include_browse: bool (optional)   Whether to include volumes in the response for which the principal can only access selective   metadata for :param max_results: int (optional)   Maximum number of volumes to return (page length).    If not set, the page length is set to a server configured value (10000, as of 1/29/2024). - when set   to a value greater than 0, the page length is the minimum of this value and a server configured   value (10000, as of 1/29/2024); - when set to 0, the page length is set to a server configured value   (10000, as of 1/29/2024) (recommended); - when set to a value less than 0, an invalid parameter   error is returned;    Note: this parameter controls only the maximum number of volumes to return. The actual number of   volumes returned in a page may be smaller than this value, including 0, even if there are more   pages. :param page_token: str (optional)   Opaque token returned by a previous request. It must be included in the request to retrieve the next   page of results (pagination).  :returns: Iterator over :class:`VolumeInfo`",volumes,list,select,$.volumes
catalog.json,/api/2.1/unity-catalog/volumes/{name},volumes_delete,delete,,"catalog, volumes",name,Deletes a volume from the specified parent catalog and schema.,"Deletes a volume from the specified parent catalog and schema.  The caller must be a metastore admin or an owner of the volume. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param name: str   The three-level (fully qualified) name of the volume",volumes,delete,delete,
catalog.json,/api/2.1/unity-catalog/volumes/{name},volumes_read,get,VolumeInfo,"catalog, volumes","name, include_browse",Gets a volume from the metastore for a specific catalog and schema.,"Gets a volume from the metastore for a specific catalog and schema.  The caller must be a metastore admin or an owner of (or have the **READ VOLUME** privilege on) the volume. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  :param name: str   The three-level (fully qualified) name of the volume :param include_browse: bool (optional)   Whether to include volumes in the response for which the principal can only access selective   metadata for  :returns: :class:`VolumeInfo`",volumes,read,select,
catalog.json,/api/2.1/unity-catalog/volumes/{name},volumes_update,patch,VolumeInfo,"catalog, volumes","name, comment, new_name, owner",Updates the specified volume under the specified parent catalog and schema.,"Updates the specified volume under the specified parent catalog and schema.  The caller must be a metastore admin or an owner of the volume. For the latter case, the caller must also be the owner or have the **USE_CATALOG** privilege on the parent catalog and the **USE_SCHEMA** privilege on the parent schema.  Currently only the name, the owner or the comment of the volume could be updated.  :param name: str   The three-level (fully qualified) name of the volume :param comment: str (optional)   The comment attached to the volume :param new_name: str (optional)   New name for the volume. :param owner: str (optional)   The identifier of the user who owns the volume  :returns: :class:`VolumeInfo`",volumes,update,update,
catalog.json,/api/2.1/unity-catalog/workspace-bindings/catalogs/{name},workspace_bindings_get,get,GetCatalogWorkspaceBindingsResponse,"catalog, workspace_bindings",name,Gets workspace bindings of the catalog. The caller must be a metastore admin or an owner of the,Gets workspace bindings of the catalog. The caller must be a metastore admin or an owner of the catalog.  :param name: str   The name of the catalog.  :returns: :class:`GetCatalogWorkspaceBindingsResponse`,workspace_bindings,get,select,
catalog.json,/api/2.1/unity-catalog/workspace-bindings/catalogs/{name},workspace_bindings_update,patch,UpdateCatalogWorkspaceBindingsResponse,"catalog, workspace_bindings","name, assign_workspaces, unassign_workspaces",Updates workspace bindings of the catalog. The caller must be a metastore admin or an owner of the,Updates workspace bindings of the catalog. The caller must be a metastore admin or an owner of the catalog.  :param name: str   The name of the catalog. :param assign_workspaces: List[int] (optional)   A list of workspace IDs. :param unassign_workspaces: List[int] (optional)   A list of workspace IDs.  :returns: :class:`UpdateCatalogWorkspaceBindingsResponse`,workspace_bindings,update,update,
catalog.json,/api/2.1/unity-catalog/bindings/{securable_type}/{securable_name},workspace_bindings_get_bindings,get,GetWorkspaceBindingsResponse,"catalog, workspace_bindings","securable_type, securable_name, max_results, page_token",Gets workspace bindings of the securable. The caller must be a metastore admin or an owner of the,"Gets workspace bindings of the securable. The caller must be a metastore admin or an owner of the securable.  NOTE: we recommend using max_results=0 to use the paginated version of this API. Unpaginated calls will be deprecated soon.  PAGINATION BEHAVIOR: When using pagination (max_results >= 0), a page may contain zero results while still providing a next_page_token. Clients must continue reading pages until next_page_token is absent, which is the only indication that the end of results has been reached.  :param securable_type: str   The type of the securable to bind to a workspace (catalog, storage_credential, credential, or   external_location). :param securable_name: str   The name of the securable. :param max_results: int (optional)   Maximum number of workspace bindings to return. - When set to 0, the page length is set to a server   configured value (recommended); - When set to a value greater than 0, the page length is the minimum   of this value and a server configured value; - When set to a value less than 0, an invalid parameter   error is returned; - If not set, all the workspace bindings are returned (not recommended). :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`WorkspaceBinding`",workspace_bindings,get_bindings,select,$.bindings
catalog.json,/api/2.1/unity-catalog/bindings/{securable_type}/{securable_name},workspace_bindings_update_bindings,patch,UpdateWorkspaceBindingsResponse,"catalog, workspace_bindings","securable_type, securable_name, add, remove",Updates workspace bindings of the securable. The caller must be a metastore admin or an owner of the,"Updates workspace bindings of the securable. The caller must be a metastore admin or an owner of the securable.  :param securable_type: str   The type of the securable to bind to a workspace (catalog, storage_credential, credential, or   external_location). :param securable_name: str   The name of the securable. :param add: List[:class:`WorkspaceBinding`] (optional)   List of workspace bindings to add. If a binding for the workspace already exists with a different   binding_type, adding it again with a new binding_type will update the existing binding (e.g., from   READ_WRITE to READ_ONLY). :param remove: List[:class:`WorkspaceBinding`] (optional)   List of workspace bindings to remove.  :returns: :class:`UpdateWorkspaceBindingsResponse`",workspace_bindings,update_bindings,update,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/assets/{asset_type.value}/{name}/revisions/{etag},clean_room_asset_revisions_get,get,CleanRoomAsset,"cleanrooms, clean_room_asset_revisions","clean_room_name, asset_type.value, name, etag, asset_type",Get a specific revision of an asset,"Get a specific revision of an asset  :param clean_room_name: str   Name of the clean room. :param asset_type: :class:`CleanRoomAssetAssetType`   Asset type. Only NOTEBOOK_FILE is supported. :param name: str   Name of the asset. :param etag: str   Revision etag to fetch. If not provided, the latest revision will be returned.  :returns: :class:`CleanRoomAsset`",asset_revisions,get,select,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/assets/{asset_type.value}/{name}/revisions,clean_room_asset_revisions_list,get,ListCleanRoomAssetRevisionsResponse,"cleanrooms, clean_room_asset_revisions","clean_room_name, asset_type.value, name, asset_type, page_size, page_token",List revisions for an asset,List revisions for an asset  :param clean_room_name: str   Name of the clean room. :param asset_type: :class:`CleanRoomAssetAssetType`   Asset type. Only NOTEBOOK_FILE is supported. :param name: str   Name of the asset. :param page_size: int (optional)   Maximum number of asset revisions to return. Defaults to 10. :param page_token: str (optional)   Opaque pagination token to go to next page based on the previous query.  :returns: Iterator over :class:`CleanRoomAsset`,asset_revisions,list,select,$.revisions
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/assets,clean_room_assets_create,post,CleanRoomAsset,"cleanrooms, clean_room_assets","clean_room_name, asset",Create a clean room asset —share an asset like a notebook or table into the clean room. For each UC,"Create a clean room asset —share an asset like a notebook or table into the clean room. For each UC asset that is added through this method, the clean room owner must also have enough privilege on the asset to consume it. The privilege must be maintained indefinitely for the clean room to be able to access the asset. Typically, you should use a group as the clean room owner.  :param clean_room_name: str   The name of the clean room this asset belongs to. This field is required for create operations and   populated by the server for responses. :param asset: :class:`CleanRoomAsset`  :returns: :class:`CleanRoomAsset`",assets,create,insert,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/assets,clean_room_assets_list,get,ListCleanRoomAssetRevisionsResponse,"cleanrooms, clean_room_assets","clean_room_name, page_token",List assets.,List assets.  :param clean_room_name: str   Name of the clean room. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`CleanRoomAsset`,assets,list,select,$.assets
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/assets/{asset_type.value}/{name}/reviews,clean_room_assets_create_clean_room_asset_review,post,CreateCleanRoomAssetReviewResponse,"cleanrooms, clean_room_assets","clean_room_name, asset_type.value, name, asset_type, notebook_review",Submit an asset review,Submit an asset review  :param clean_room_name: str   Name of the clean room :param asset_type: :class:`CleanRoomAssetAssetType`   Asset type. Can either be NOTEBOOK_FILE or JAR_ANALYSIS. :param name: str   Name of the asset :param notebook_review: :class:`NotebookVersionReview` (optional)  :returns: :class:`CreateCleanRoomAssetReviewResponse`,assets,review,exec,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/assets/{asset_type.value}/{name},clean_room_assets_delete,delete,,"cleanrooms, clean_room_assets","clean_room_name, asset_type.value, name, asset_type",Delete a clean room asset - unshare/remove the asset from the clean room,"Delete a clean room asset - unshare/remove the asset from the clean room  :param clean_room_name: str   Name of the clean room. :param asset_type: :class:`CleanRoomAssetAssetType`   The type of the asset. :param name: str   The fully qualified name of the asset, it is same as the name field in CleanRoomAsset.",assets,delete,delete,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/assets/{asset_type.value}/{name},clean_room_assets_get,get,CleanRoomAsset,"cleanrooms, clean_room_assets","clean_room_name, asset_type.value, name, asset_type",Get the details of a clean room asset by its type and full name.,"Get the details of a clean room asset by its type and full name.  :param clean_room_name: str   Name of the clean room. :param asset_type: :class:`CleanRoomAssetAssetType`   The type of the asset. :param name: str   The fully qualified name of the asset, it is same as the name field in CleanRoomAsset.  :returns: :class:`CleanRoomAsset`",assets,get,select,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/assets/{asset_type.value}/{name},clean_room_assets_update,patch,CleanRoomAsset,"cleanrooms, clean_room_assets","clean_room_name, asset_type.value, name, asset_type, asset","Update a clean room asset. For example, updating the content of a notebook; changing the shared","Update a clean room asset. For example, updating the content of a notebook; changing the shared partitions of a table; etc.  :param clean_room_name: str   Name of the clean room. :param asset_type: :class:`CleanRoomAssetAssetType`   The type of the asset. :param name: str   A fully qualified name that uniquely identifies the asset within the clean room. This is also the   name displayed in the clean room UI.    For UC securable assets (tables, volumes, etc.), the format is   *shared_catalog*.*shared_schema*.*asset_name*    For notebooks, the name is the notebook file name. For jar analyses, the name is the jar analysis   name. :param asset: :class:`CleanRoomAsset`   The asset to update. The asset's `name` and `asset_type` fields are used to identify the asset to   update.  :returns: :class:`CleanRoomAsset`",assets,update,update,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/auto-approval-rules,clean_room_auto_approval_rules_create,post,CleanRoomAutoApprovalRule,"cleanrooms, clean_room_auto_approval_rules","clean_room_name, auto_approval_rule",Create an auto-approval rule,Create an auto-approval rule  :param clean_room_name: str   The name of the clean room this auto-approval rule belongs to. :param auto_approval_rule: :class:`CleanRoomAutoApprovalRule`  :returns: :class:`CleanRoomAutoApprovalRule`,auto_approval_rules,create,insert,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/auto-approval-rules,clean_room_auto_approval_rules_list,get,ListCleanRoomAutoApprovalRulesResponse,"cleanrooms, clean_room_auto_approval_rules","clean_room_name, page_size, page_token",List all auto-approval rules for the caller,List all auto-approval rules for the caller  :param clean_room_name: str :param page_size: int (optional)   Maximum number of auto-approval rules to return. Defaults to 100. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`CleanRoomAutoApprovalRule`,auto_approval_rules,list,select,$.rules
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/auto-approval-rules/{rule_id},clean_room_auto_approval_rules_delete,delete,,"cleanrooms, clean_room_auto_approval_rules","clean_room_name, rule_id",Delete a auto-approval rule by rule ID,Delete a auto-approval rule by rule ID  :param clean_room_name: str :param rule_id: str,auto_approval_rules,delete,delete,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/auto-approval-rules/{rule_id},clean_room_auto_approval_rules_get,get,CleanRoomAutoApprovalRule,"cleanrooms, clean_room_auto_approval_rules","clean_room_name, rule_id",Get a auto-approval rule by rule ID,Get a auto-approval rule by rule ID  :param clean_room_name: str :param rule_id: str  :returns: :class:`CleanRoomAutoApprovalRule`,auto_approval_rules,get,select,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/auto-approval-rules/{rule_id},clean_room_auto_approval_rules_update,patch,CleanRoomAutoApprovalRule,"cleanrooms, clean_room_auto_approval_rules","clean_room_name, rule_id, auto_approval_rule",Update a auto-approval rule by rule ID,Update a auto-approval rule by rule ID  :param clean_room_name: str   The name of the clean room this auto-approval rule belongs to. :param rule_id: str   A generated UUID identifying the rule. :param auto_approval_rule: :class:`CleanRoomAutoApprovalRule`   The auto-approval rule to update. The rule_id field is used to identify the rule to update.  :returns: :class:`CleanRoomAutoApprovalRule`,auto_approval_rules,update,update,
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/runs,clean_room_task_runs_list,get,ListCleanRoomNotebookTaskRunsResponse,"cleanrooms, clean_room_task_runs","clean_room_name, notebook_name, page_size, page_token",List all the historical notebook task runs in a clean room.,List all the historical notebook task runs in a clean room.  :param clean_room_name: str   Name of the clean room. :param notebook_name: str (optional)   Notebook name :param page_size: int (optional)   The maximum number of task runs to return. Currently ignored - all runs will be returned. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`CleanRoomNotebookTaskRun`,task_runs,list,select,$.runs
cleanrooms.json,/api/2.0/clean-rooms,clean_rooms_create,post,CleanRoom,"cleanrooms, clean_rooms",clean_room,Create a new clean room with the specified collaborators. This method is asynchronous; the returned,"Create a new clean room with the specified collaborators. This method is asynchronous; the returned name field inside the clean_room field can be used to poll the clean room status, using the :method:cleanrooms/get method. When this method returns, the clean room will be in a PROVISIONING state, with only name, owner, comment, created_at and status populated. The clean room will be usable once it enters an ACTIVE state.  The caller must be a metastore admin or have the **CREATE_CLEAN_ROOM** privilege on the metastore.  :param clean_room: :class:`CleanRoom`  :returns:   Long-running operation waiter for :class:`CleanRoom`.   See :method:wait_get_clean_room_active for more details.",clean_rooms,create,insert,
cleanrooms.json,/api/2.0/clean-rooms,clean_rooms_list,get,ListCleanRoomsResponse,"cleanrooms, clean_rooms","page_size, page_token",Get a list of all clean rooms of the metastore. Only clean rooms the caller has access to are,"Get a list of all clean rooms of the metastore. Only clean rooms the caller has access to are returned.  :param page_size: int (optional)   Maximum number of clean rooms to return (i.e., the page length). Defaults to 100. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`CleanRoom`",clean_rooms,list,select,$.clean_rooms
cleanrooms.json,/api/2.0/clean-rooms/{clean_room_name}/output-catalogs,clean_rooms_create_output_catalog,post,CreateCleanRoomOutputCatalogResponse,"cleanrooms, clean_rooms","clean_room_name, output_catalog",Create the output catalog of the clean room.,Create the output catalog of the clean room.  :param clean_room_name: str   Name of the clean room. :param output_catalog: :class:`CleanRoomOutputCatalog`  :returns: :class:`CreateCleanRoomOutputCatalogResponse`,clean_rooms,create_output_catalog,exec,
cleanrooms.json,/api/2.0/clean-rooms/{name},clean_rooms_delete,delete,,"cleanrooms, clean_rooms",name,"Delete a clean room. After deletion, the clean room will be removed from the metastore. If the other","Delete a clean room. After deletion, the clean room will be removed from the metastore. If the other collaborators have not deleted the clean room, they will still have the clean room in their metastore, but it will be in a DELETED state and no operations other than deletion can be performed on it.  :param name: str   Name of the clean room.",clean_rooms,delete,delete,
cleanrooms.json,/api/2.0/clean-rooms/{name},clean_rooms_get,get,CleanRoom,"cleanrooms, clean_rooms",name,Get the details of a clean room given its name.,Get the details of a clean room given its name.  :param name: str  :returns: :class:`CleanRoom`,clean_rooms,get,select,
cleanrooms.json,/api/2.0/clean-rooms/{name},clean_rooms_update,patch,CleanRoom,"cleanrooms, clean_rooms","name, clean_room","Update a clean room. The caller must be the owner of the clean room, have **MODIFY_CLEAN_ROOM**","Update a clean room. The caller must be the owner of the clean room, have **MODIFY_CLEAN_ROOM** privilege, or be metastore admin.  When the caller is a metastore admin, only the __owner__ field can be updated.  :param name: str   Name of the clean room. :param clean_room: :class:`CleanRoom` (optional)  :returns: :class:`CleanRoom`",clean_rooms,update,update,
compute.json,/api/2.0/libraries/all-cluster-statuses,libraries_all_cluster_statuses,get,ListAllClusterLibraryStatusesResponse,"compute, libraries",,Get the status of all libraries on all clusters. A status is returned for all libraries installed on,Get the status of all libraries on all clusters. A status is returned for all libraries installed on this cluster via the API or the libraries UI.   :returns: Iterator over :class:`ClusterLibraryStatuses`,all_cluster_library_statuses,list,select,$.statuses
compute.json,/api/2.1/clusters/list-node-types,clusters_list_node_types,get,ListNodeTypesResponse,"compute, clusters",,Returns a list of supported Spark node types. These node types can be used to launch a cluster.,Returns a list of supported Spark node types. These node types can be used to launch a cluster.   :returns: :class:`ListNodeTypesResponse`,cluster_node_types,list,select,
compute.json,/api/2.0/permissions/clusters/{cluster_id}/permissionLevels,clusters_get_permission_levels,get,GetClusterPermissionLevelsResponse,"compute, clusters",cluster_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param cluster_id: str   The cluster for which to get or manage permissions.  :returns: :class:`GetClusterPermissionLevelsResponse`,cluster_permission_levels,get,select,
compute.json,/api/2.0/permissions/clusters/{cluster_id},clusters_get_permissions,get,ClusterPermissions,"compute, clusters",cluster_id,Gets the permissions of a cluster. Clusters can inherit permissions from their root object.,Gets the permissions of a cluster. Clusters can inherit permissions from their root object.  :param cluster_id: str   The cluster for which to get or manage permissions.  :returns: :class:`ClusterPermissions`,cluster_permissions,get,select,
compute.json,/api/2.0/permissions/clusters/{cluster_id},clusters_set_permissions,put,ClusterPermissions,"compute, clusters","cluster_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param cluster_id: str   The cluster for which to get or manage permissions. :param access_control_list: List[:class:`ClusterAccessControlRequest`] (optional)  :returns: :class:`ClusterPermissions`",cluster_permissions,set,replace,
compute.json,/api/2.0/permissions/clusters/{cluster_id},clusters_update_permissions,patch,ClusterPermissions,"compute, clusters","cluster_id, access_control_list",Updates the permissions on a cluster. Clusters can inherit permissions from their root object.,Updates the permissions on a cluster. Clusters can inherit permissions from their root object.  :param cluster_id: str   The cluster for which to get or manage permissions. :param access_control_list: List[:class:`ClusterAccessControlRequest`] (optional)  :returns: :class:`ClusterPermissions`,cluster_permissions,update,update,
compute.json,/api/2.0/policies/clusters/create,cluster_policies_create,post,CreatePolicyResponse,"compute, cluster_policies","definition, description, libraries, max_clusters_per_user, name, policy_family_definition_overrides, policy_family_id",Creates a new policy with prescribed settings.,"Creates a new policy with prescribed settings.  :param definition: str (optional)   Policy definition document expressed in [Databricks Cluster Policy Definition Language].    [Databricks Cluster Policy Definition Language]: https://docs.databricks.com/administration-guide/clusters/policy-definition.html :param description: str (optional)   Additional human-readable description of the cluster policy. :param libraries: List[:class:`Library`] (optional)   A list of libraries to be installed on the next cluster restart that uses this policy. The maximum   number of libraries is 500. :param max_clusters_per_user: int (optional)   Max number of clusters per user that can be active using this policy. If not present, there is no   max limit. :param name: str (optional)   Cluster Policy name requested by the user. This has to be unique. Length must be between 1 and 100   characters. :param policy_family_definition_overrides: str (optional)   Policy definition JSON document expressed in [Databricks Policy Definition Language]. The JSON   document must be passed as a string and cannot be embedded in the requests.    You can use this to customize the policy definition inherited from the policy family. Policy rules   specified here are merged into the inherited policy definition.    [Databricks Policy Definition Language]: https://docs.databricks.com/administration-guide/clusters/policy-definition.html :param policy_family_id: str (optional)   ID of the policy family. The cluster policy's policy definition inherits the policy family's policy   definition.    Cannot be used with `definition`. Use `policy_family_definition_overrides` instead to customize the   policy definition.  :returns: :class:`CreatePolicyResponse`",cluster_policies,create,insert,
compute.json,/api/2.0/policies/clusters/delete,cluster_policies_delete,post,,"compute, cluster_policies",policy_id,"Delete a policy for a cluster. Clusters governed by this policy can still run, but cannot be edited.","Delete a policy for a cluster. Clusters governed by this policy can still run, but cannot be edited.  :param policy_id: str   The ID of the policy to delete.",cluster_policies,delete,delete,
compute.json,/api/2.0/policies/clusters/edit,cluster_policies_edit,post,,"compute, cluster_policies","policy_id, definition, description, libraries, max_clusters_per_user, name, policy_family_definition_overrides, policy_family_id",Update an existing policy for cluster. This operation may make some clusters governed by the previous,"Update an existing policy for cluster. This operation may make some clusters governed by the previous policy invalid.  :param policy_id: str   The ID of the policy to update. :param definition: str (optional)   Policy definition document expressed in [Databricks Cluster Policy Definition Language].    [Databricks Cluster Policy Definition Language]: https://docs.databricks.com/administration-guide/clusters/policy-definition.html :param description: str (optional)   Additional human-readable description of the cluster policy. :param libraries: List[:class:`Library`] (optional)   A list of libraries to be installed on the next cluster restart that uses this policy. The maximum   number of libraries is 500. :param max_clusters_per_user: int (optional)   Max number of clusters per user that can be active using this policy. If not present, there is no   max limit. :param name: str (optional)   Cluster Policy name requested by the user. This has to be unique. Length must be between 1 and 100   characters. :param policy_family_definition_overrides: str (optional)   Policy definition JSON document expressed in [Databricks Policy Definition Language]. The JSON   document must be passed as a string and cannot be embedded in the requests.    You can use this to customize the policy definition inherited from the policy family. Policy rules   specified here are merged into the inherited policy definition.    [Databricks Policy Definition Language]: https://docs.databricks.com/administration-guide/clusters/policy-definition.html :param policy_family_id: str (optional)   ID of the policy family. The cluster policy's policy definition inherits the policy family's policy   definition.    Cannot be used with `definition`. Use `policy_family_definition_overrides` instead to customize the   policy definition.",cluster_policies,replace,replace,
compute.json,/api/2.0/policies/clusters/get,cluster_policies_get,get,Policy,"compute, cluster_policies",policy_id,Get a cluster policy entity. Creation and editing is available to admins only.,Get a cluster policy entity. Creation and editing is available to admins only.  :param policy_id: str   Canonical unique identifier for the Cluster Policy.  :returns: :class:`Policy`,cluster_policies,get,select,
compute.json,/api/2.0/policies/clusters/list,cluster_policies_list,get,ListPoliciesResponse,"compute, cluster_policies","sort_column, sort_order",Returns a list of policies accessible by the requesting user.,Returns a list of policies accessible by the requesting user.  :param sort_column: :class:`ListSortColumn` (optional)   The cluster policy attribute to sort by. * `POLICY_CREATION_TIME` - Sort result list by policy   creation time. * `POLICY_NAME` - Sort result list by policy name. :param sort_order: :class:`ListSortOrder` (optional)   The order in which the policies get listed. * `DESC` - Sort result list in descending order. * `ASC`   - Sort result list in ascending order.  :returns: Iterator over :class:`Policy`,cluster_policies,list,select,$.policies
compute.json,/api/2.0/permissions/cluster-policies/{cluster_policy_id}/permissionLevels,cluster_policies_get_permission_levels,get,GetClusterPolicyPermissionLevelsResponse,"compute, cluster_policies",cluster_policy_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param cluster_policy_id: str   The cluster policy for which to get or manage permissions.  :returns: :class:`GetClusterPolicyPermissionLevelsResponse`,cluster_policy_permission_levels,get,select,
compute.json,/api/2.0/permissions/cluster-policies/{cluster_policy_id},cluster_policies_get_permissions,get,ClusterPolicyPermissions,"compute, cluster_policies",cluster_policy_id,Gets the permissions of a cluster policy. Cluster policies can inherit permissions from their root,Gets the permissions of a cluster policy. Cluster policies can inherit permissions from their root object.  :param cluster_policy_id: str   The cluster policy for which to get or manage permissions.  :returns: :class:`ClusterPolicyPermissions`,cluster_policy_permissions,get,select,
compute.json,/api/2.0/permissions/cluster-policies/{cluster_policy_id},cluster_policies_set_permissions,put,ClusterPolicyPermissions,"compute, cluster_policies","cluster_policy_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param cluster_policy_id: str   The cluster policy for which to get or manage permissions. :param access_control_list: List[:class:`ClusterPolicyAccessControlRequest`] (optional)  :returns: :class:`ClusterPolicyPermissions`",cluster_policy_permissions,set,replace,
compute.json,/api/2.0/permissions/cluster-policies/{cluster_policy_id},cluster_policies_update_permissions,patch,ClusterPolicyPermissions,"compute, cluster_policies","cluster_policy_id, access_control_list",Updates the permissions on a cluster policy. Cluster policies can inherit permissions from their root,Updates the permissions on a cluster policy. Cluster policies can inherit permissions from their root object.  :param cluster_policy_id: str   The cluster policy for which to get or manage permissions. :param access_control_list: List[:class:`ClusterPolicyAccessControlRequest`] (optional)  :returns: :class:`ClusterPolicyPermissions`,cluster_policy_permissions,update,update,
compute.json,/api/2.1/clusters/list-zones,clusters_list_zones,get,ListAvailableZonesResponse,"compute, clusters",,"Returns a list of availability zones where clusters can be created in (For example, us-west-2a). These","Returns a list of availability zones where clusters can be created in (For example, us-west-2a). These zones can be used to launch a cluster.   :returns: :class:`ListAvailableZonesResponse`",cluster_zones,list,select,
compute.json,/api/2.1/clusters/change-owner,clusters_change_owner,post,,"compute, clusters","cluster_id, owner_username",Change the owner of the cluster. You must be an admin and the cluster must be terminated to perform,Change the owner of the cluster. You must be an admin and the cluster must be terminated to perform this operation. The service principal application ID can be supplied as an argument to `owner_username`.  :param cluster_id: str :param owner_username: str   New owner of the cluster_id after this RPC.,clusters,change_owner,exec,
compute.json,/api/2.1/clusters/create,clusters_create,post,ClusterDetails,"compute, clusters","spark_version, apply_policy_default_values, autoscale, autotermination_minutes, aws_attributes, azure_attributes, clone_from, cluster_log_conf, cluster_name, custom_tags, data_security_mode, docker_image, driver_instance_pool_id, driver_node_type_flexibility, driver_node_type_id, enable_elastic_disk, enable_local_disk_encryption, gcp_attributes, init_scripts, instance_pool_id, is_single_node, kind, node_type_id, num_workers, policy_id, remote_disk_throughput, runtime_engine, single_user_name, spark_conf, spark_env_vars, ssh_public_keys, total_initial_remote_disk_size, use_ml_runtime, worker_node_type_flexibility, workload_type",Creates a new Spark cluster. This method will acquire new instances from the cloud provider if,"Creates a new Spark cluster. This method will acquire new instances from the cloud provider if necessary. This method is asynchronous; the returned ``cluster_id`` can be used to poll the cluster status. When this method returns, the cluster will be in a ``PENDING`` state. The cluster will be usable once it enters a ``RUNNING`` state. Note: Databricks may not be able to acquire some of the requested nodes, due to cloud provider limitations (account limits, spot price, etc.) or transient network issues.  If Databricks acquires at least 85% of the requested on-demand nodes, cluster creation will succeed. Otherwise the cluster will terminate with an informative error message.  Rather than authoring the cluster's JSON definition from scratch, Databricks recommends filling out the [create compute UI] and then copying the generated JSON definition from the UI.  [create compute UI]: https://docs.databricks.com/compute/configure.html  :param spark_version: str   The Spark version of the cluster, e.g. `3.3.x-scala2.11`. A list of available Spark versions can be   retrieved by using the :method:clusters/sparkVersions API call. :param apply_policy_default_values: bool (optional)   When set to true, fixed and default values from the policy will be used for fields that are omitted.   When set to false, only fixed values from the policy will be applied. :param autoscale: :class:`AutoScale` (optional)   Parameters needed in order to automatically scale clusters up and down based on load. Note:   autoscaling works best with DB runtime versions 3.0 or later. :param autotermination_minutes: int (optional)   Automatically terminates the cluster after it is inactive for this time in minutes. If not set, this   cluster will not be automatically terminated. If specified, the threshold must be between 10 and   10000 minutes. Users can also set this value to 0 to explicitly disable automatic termination. :param aws_attributes: :class:`AwsAttributes` (optional)   Attributes related to clusters running on Amazon Web Services. If not specified at cluster creation,   a set of default values will be used. :param azure_attributes: :class:`AzureAttributes` (optional)   Attributes related to clusters running on Microsoft Azure. If not specified at cluster creation, a   set of default values will be used. :param clone_from: :class:`CloneCluster` (optional)   When specified, this clones libraries from a source cluster during the creation of a new cluster. :param cluster_log_conf: :class:`ClusterLogConf` (optional)   The configuration for delivering spark logs to a long-term storage destination. Three kinds of   destinations (DBFS, S3 and Unity Catalog volumes) are supported. Only one destination can be   specified for one cluster. If the conf is given, the logs will be delivered to the destination every   `5 mins`. The destination of driver logs is `$destination/$clusterId/driver`, while the destination   of executor logs is `$destination/$clusterId/executor`. :param cluster_name: str (optional)   Cluster name requested by the user. This doesn't have to be unique. If not specified at creation,   the cluster name will be an empty string. For job clusters, the cluster name is automatically set   based on the job and job run IDs. :param custom_tags: Dict[str,str] (optional)   Additional tags for cluster resources. Databricks will tag all cluster resources (e.g., AWS   instances and EBS volumes) with these tags in addition to `default_tags`. Notes:    - Currently, Databricks allows at most 45 custom tags    - Clusters can only reuse cloud resources if the resources' tags are a subset of the cluster tags :param data_security_mode: :class:`DataSecurityMode` (optional) :param docker_image: :class:`DockerImage` (optional)   Custom docker image BYOC :param driver_instance_pool_id: str (optional)   The optional ID of the instance pool for the driver of the cluster belongs. The pool cluster uses   the instance pool with id (instance_pool_id) if the driver pool is not assigned. :param driver_node_type_flexibility: :class:`NodeTypeFlexibility` (optional)   Flexible node type configuration for the driver node. :param driver_node_type_id: str (optional)   The node type of the Spark driver. Note that this field is optional; if unset, the driver node type   will be set as the same value as `node_type_id` defined above.    This field, along with node_type_id, should not be set if virtual_cluster_size is set. If both   driver_node_type_id, node_type_id, and virtual_cluster_size are specified, driver_node_type_id and   node_type_id take precedence. :param enable_elastic_disk: bool (optional)   Autoscaling Local Storage: when enabled, this cluster will dynamically acquire additional disk space   when its Spark workers are running low on disk space. :param enable_local_disk_encryption: bool (optional)   Whether to enable LUKS on cluster VMs' local disks :param gcp_attributes: :class:`GcpAttributes` (optional)   Attributes related to clusters running on Google Cloud Platform. If not specified at cluster   creation, a set of default values will be used. :param init_scripts: List[:class:`InitScriptInfo`] (optional)   The configuration for storing init scripts. Any number of destinations can be specified. The scripts   are executed sequentially in the order provided. If `cluster_log_conf` is specified, init script   logs are sent to `<destination>/<cluster-ID>/init_scripts`. :param instance_pool_id: str (optional)   The optional ID of the instance pool to which the cluster belongs. :param is_single_node: bool (optional)   This field can only be used when `kind = CLASSIC_PREVIEW`.    When set to true, Databricks will automatically set single node related `custom_tags`, `spark_conf`,   and `num_workers` :param kind: :class:`Kind` (optional) :param node_type_id: str (optional)   This field encodes, through a single value, the resources available to each of the Spark nodes in   this cluster. For example, the Spark nodes can be provisioned and optimized for memory or compute   intensive workloads. A list of available node types can be retrieved by using the   :method:clusters/listNodeTypes API call. :param num_workers: int (optional)   Number of worker nodes that this cluster should have. A cluster has one Spark Driver and   `num_workers` Executors for a total of `num_workers` + 1 Spark nodes.    Note: When reading the properties of a cluster, this field reflects the desired number of workers   rather than the actual current number of workers. For instance, if a cluster is resized from 5 to 10   workers, this field will immediately be updated to reflect the target size of 10 workers, whereas   the workers listed in `spark_info` will gradually increase from 5 to 10 as the new nodes are   provisioned. :param policy_id: str (optional)   The ID of the cluster policy used to create the cluster if applicable. :param remote_disk_throughput: int (optional)   If set, what the configurable throughput (in Mb/s) for the remote disk is. Currently only supported   for GCP HYPERDISK_BALANCED disks. :param runtime_engine: :class:`RuntimeEngine` (optional)   Determines the cluster's runtime engine, either standard or Photon.    This field is not compatible with legacy `spark_version` values that contain `-photon-`. Remove   `-photon-` from the `spark_version` and set `runtime_engine` to `PHOTON`.    If left unspecified, the runtime engine defaults to standard unless the spark_version contains   -photon-, in which case Photon will be used. :param single_user_name: str (optional)   Single user name if data_security_mode is `SINGLE_USER` :param spark_conf: Dict[str,str] (optional)   An object containing a set of optional, user-specified Spark configuration key-value pairs. Users   can also pass in a string of extra JVM options to the driver and the executors via   `spark.driver.extraJavaOptions` and `spark.executor.extraJavaOptions` respectively. :param spark_env_vars: Dict[str,str] (optional)   An object containing a set of optional, user-specified environment variable key-value pairs. Please   note that key-value pair of the form (X,Y) will be exported as is (i.e., `export X='Y'`) while   launching the driver and workers.    In order to specify an additional set of `SPARK_DAEMON_JAVA_OPTS`, we recommend appending them to   `$SPARK_DAEMON_JAVA_OPTS` as shown in the example below. This ensures that all default databricks   managed environmental variables are included as well.    Example Spark environment variables: `{""SPARK_WORKER_MEMORY"": ""28000m"", ""SPARK_LOCAL_DIRS"":   ""/local_disk0""}` or `{""SPARK_DAEMON_JAVA_OPTS"": ""$SPARK_DAEMON_JAVA_OPTS   -Dspark.shuffle.service.enabled=true""}` :param ssh_public_keys: List[str] (optional)   SSH public key contents that will be added to each Spark node in this cluster. The corresponding   private keys can be used to login with the user name `ubuntu` on port `2200`. Up to 10 keys can be   specified. :param total_initial_remote_disk_size: int (optional)   If set, what the total initial volume size (in GB) of the remote disks should be. Currently only   supported for GCP HYPERDISK_BALANCED disks. :param use_ml_runtime: bool (optional)   This field can only be used when `kind = CLASSIC_PREVIEW`.    `effective_spark_version` is determined by `spark_version` (DBR release), this field   `use_ml_runtime`, and whether `node_type_id` is gpu node or not. :param worker_node_type_flexibility: :class:`NodeTypeFlexibility` (optional)   Flexible node type configuration for worker nodes. :param workload_type: :class:`WorkloadType` (optional)  :returns:   Long-running operation waiter for :class:`ClusterDetails`.   See :method:wait_get_cluster_running for more details.",clusters,create,insert,
compute.json,/api/2.1/clusters/delete,clusters_delete,post,ClusterDetails,"compute, clusters",cluster_id,Terminates the Spark cluster with the specified ID. The cluster is removed asynchronously. Once the,"Terminates the Spark cluster with the specified ID. The cluster is removed asynchronously. Once the termination has completed, the cluster will be in a `TERMINATED` state. If the cluster is already in a `TERMINATING` or `TERMINATED` state, nothing will happen.  :param cluster_id: str   The cluster to be terminated.  :returns:   Long-running operation waiter for :class:`ClusterDetails`.   See :method:wait_get_cluster_terminated for more details.",clusters,delete,exec,
compute.json,/api/2.1/clusters/edit,clusters_edit,post,ClusterDetails,"compute, clusters","cluster_id, spark_version, apply_policy_default_values, autoscale, autotermination_minutes, aws_attributes, azure_attributes, cluster_log_conf, cluster_name, custom_tags, data_security_mode, docker_image, driver_instance_pool_id, driver_node_type_flexibility, driver_node_type_id, enable_elastic_disk, enable_local_disk_encryption, gcp_attributes, init_scripts, instance_pool_id, is_single_node, kind, node_type_id, num_workers, policy_id, remote_disk_throughput, runtime_engine, single_user_name, spark_conf, spark_env_vars, ssh_public_keys, total_initial_remote_disk_size, use_ml_runtime, worker_node_type_flexibility, workload_type",Updates the configuration of a cluster to match the provided attributes and size. A cluster can be,"Updates the configuration of a cluster to match the provided attributes and size. A cluster can be updated if it is in a `RUNNING` or `TERMINATED` state.  If a cluster is updated while in a `RUNNING` state, it will be restarted so that the new attributes can take effect.  If a cluster is updated while in a `TERMINATED` state, it will remain `TERMINATED`. The next time it is started using the `clusters/start` API, the new attributes will take effect. Any attempt to update a cluster in any other state will be rejected with an `INVALID_STATE` error code.  Clusters created by the Databricks Jobs service cannot be edited.  :param cluster_id: str   ID of the cluster :param spark_version: str   The Spark version of the cluster, e.g. `3.3.x-scala2.11`. A list of available Spark versions can be   retrieved by using the :method:clusters/sparkVersions API call. :param apply_policy_default_values: bool (optional)   When set to true, fixed and default values from the policy will be used for fields that are omitted.   When set to false, only fixed values from the policy will be applied. :param autoscale: :class:`AutoScale` (optional)   Parameters needed in order to automatically scale clusters up and down based on load. Note:   autoscaling works best with DB runtime versions 3.0 or later. :param autotermination_minutes: int (optional)   Automatically terminates the cluster after it is inactive for this time in minutes. If not set, this   cluster will not be automatically terminated. If specified, the threshold must be between 10 and   10000 minutes. Users can also set this value to 0 to explicitly disable automatic termination. :param aws_attributes: :class:`AwsAttributes` (optional)   Attributes related to clusters running on Amazon Web Services. If not specified at cluster creation,   a set of default values will be used. :param azure_attributes: :class:`AzureAttributes` (optional)   Attributes related to clusters running on Microsoft Azure. If not specified at cluster creation, a   set of default values will be used. :param cluster_log_conf: :class:`ClusterLogConf` (optional)   The configuration for delivering spark logs to a long-term storage destination. Three kinds of   destinations (DBFS, S3 and Unity Catalog volumes) are supported. Only one destination can be   specified for one cluster. If the conf is given, the logs will be delivered to the destination every   `5 mins`. The destination of driver logs is `$destination/$clusterId/driver`, while the destination   of executor logs is `$destination/$clusterId/executor`. :param cluster_name: str (optional)   Cluster name requested by the user. This doesn't have to be unique. If not specified at creation,   the cluster name will be an empty string. For job clusters, the cluster name is automatically set   based on the job and job run IDs. :param custom_tags: Dict[str,str] (optional)   Additional tags for cluster resources. Databricks will tag all cluster resources (e.g., AWS   instances and EBS volumes) with these tags in addition to `default_tags`. Notes:    - Currently, Databricks allows at most 45 custom tags    - Clusters can only reuse cloud resources if the resources' tags are a subset of the cluster tags :param data_security_mode: :class:`DataSecurityMode` (optional) :param docker_image: :class:`DockerImage` (optional)   Custom docker image BYOC :param driver_instance_pool_id: str (optional)   The optional ID of the instance pool for the driver of the cluster belongs. The pool cluster uses   the instance pool with id (instance_pool_id) if the driver pool is not assigned. :param driver_node_type_flexibility: :class:`NodeTypeFlexibility` (optional)   Flexible node type configuration for the driver node. :param driver_node_type_id: str (optional)   The node type of the Spark driver. Note that this field is optional; if unset, the driver node type   will be set as the same value as `node_type_id` defined above.    This field, along with node_type_id, should not be set if virtual_cluster_size is set. If both   driver_node_type_id, node_type_id, and virtual_cluster_size are specified, driver_node_type_id and   node_type_id take precedence. :param enable_elastic_disk: bool (optional)   Autoscaling Local Storage: when enabled, this cluster will dynamically acquire additional disk space   when its Spark workers are running low on disk space. :param enable_local_disk_encryption: bool (optional)   Whether to enable LUKS on cluster VMs' local disks :param gcp_attributes: :class:`GcpAttributes` (optional)   Attributes related to clusters running on Google Cloud Platform. If not specified at cluster   creation, a set of default values will be used. :param init_scripts: List[:class:`InitScriptInfo`] (optional)   The configuration for storing init scripts. Any number of destinations can be specified. The scripts   are executed sequentially in the order provided. If `cluster_log_conf` is specified, init script   logs are sent to `<destination>/<cluster-ID>/init_scripts`. :param instance_pool_id: str (optional)   The optional ID of the instance pool to which the cluster belongs. :param is_single_node: bool (optional)   This field can only be used when `kind = CLASSIC_PREVIEW`.    When set to true, Databricks will automatically set single node related `custom_tags`, `spark_conf`,   and `num_workers` :param kind: :class:`Kind` (optional) :param node_type_id: str (optional)   This field encodes, through a single value, the resources available to each of the Spark nodes in   this cluster. For example, the Spark nodes can be provisioned and optimized for memory or compute   intensive workloads. A list of available node types can be retrieved by using the   :method:clusters/listNodeTypes API call. :param num_workers: int (optional)   Number of worker nodes that this cluster should have. A cluster has one Spark Driver and   `num_workers` Executors for a total of `num_workers` + 1 Spark nodes.    Note: When reading the properties of a cluster, this field reflects the desired number of workers   rather than the actual current number of workers. For instance, if a cluster is resized from 5 to 10   workers, this field will immediately be updated to reflect the target size of 10 workers, whereas   the workers listed in `spark_info` will gradually increase from 5 to 10 as the new nodes are   provisioned. :param policy_id: str (optional)   The ID of the cluster policy used to create the cluster if applicable. :param remote_disk_throughput: int (optional)   If set, what the configurable throughput (in Mb/s) for the remote disk is. Currently only supported   for GCP HYPERDISK_BALANCED disks. :param runtime_engine: :class:`RuntimeEngine` (optional)   Determines the cluster's runtime engine, either standard or Photon.    This field is not compatible with legacy `spark_version` values that contain `-photon-`. Remove   `-photon-` from the `spark_version` and set `runtime_engine` to `PHOTON`.    If left unspecified, the runtime engine defaults to standard unless the spark_version contains   -photon-, in which case Photon will be used. :param single_user_name: str (optional)   Single user name if data_security_mode is `SINGLE_USER` :param spark_conf: Dict[str,str] (optional)   An object containing a set of optional, user-specified Spark configuration key-value pairs. Users   can also pass in a string of extra JVM options to the driver and the executors via   `spark.driver.extraJavaOptions` and `spark.executor.extraJavaOptions` respectively. :param spark_env_vars: Dict[str,str] (optional)   An object containing a set of optional, user-specified environment variable key-value pairs. Please   note that key-value pair of the form (X,Y) will be exported as is (i.e., `export X='Y'`) while   launching the driver and workers.    In order to specify an additional set of `SPARK_DAEMON_JAVA_OPTS`, we recommend appending them to   `$SPARK_DAEMON_JAVA_OPTS` as shown in the example below. This ensures that all default databricks   managed environmental variables are included as well.    Example Spark environment variables: `{""SPARK_WORKER_MEMORY"": ""28000m"", ""SPARK_LOCAL_DIRS"":   ""/local_disk0""}` or `{""SPARK_DAEMON_JAVA_OPTS"": ""$SPARK_DAEMON_JAVA_OPTS   -Dspark.shuffle.service.enabled=true""}` :param ssh_public_keys: List[str] (optional)   SSH public key contents that will be added to each Spark node in this cluster. The corresponding   private keys can be used to login with the user name `ubuntu` on port `2200`. Up to 10 keys can be   specified. :param total_initial_remote_disk_size: int (optional)   If set, what the total initial volume size (in GB) of the remote disks should be. Currently only   supported for GCP HYPERDISK_BALANCED disks. :param use_ml_runtime: bool (optional)   This field can only be used when `kind = CLASSIC_PREVIEW`.    `effective_spark_version` is determined by `spark_version` (DBR release), this field   `use_ml_runtime`, and whether `node_type_id` is gpu node or not. :param worker_node_type_flexibility: :class:`NodeTypeFlexibility` (optional)   Flexible node type configuration for worker nodes. :param workload_type: :class:`WorkloadType` (optional)  :returns:   Long-running operation waiter for :class:`ClusterDetails`.   See :method:wait_get_cluster_running for more details.",clusters,edit,exec,
compute.json,/api/2.1/clusters/events,clusters_events,post,GetEventsResponse,"compute, clusters","cluster_id, end_time, event_types, limit, offset, order, page_size, page_token, start_time",Retrieves a list of events about the activity of a cluster. This API is paginated. If there are more,"Retrieves a list of events about the activity of a cluster. This API is paginated. If there are more events to read, the response includes all the parameters necessary to request the next page of events.  :param cluster_id: str   The ID of the cluster to retrieve events about. :param end_time: int (optional)   The end time in epoch milliseconds. If empty, returns events up to the current time. :param event_types: List[:class:`EventType`] (optional)   An optional set of event types to filter on. If empty, all event types are returned. :param limit: int (optional)   Deprecated: use page_token in combination with page_size instead.    The maximum number of events to include in a page of events. Defaults to 50, and maximum allowed   value is 500. :param offset: int (optional)   Deprecated: use page_token in combination with page_size instead.    The offset in the result set. Defaults to 0 (no offset). When an offset is specified and the results   are requested in descending order, the end_time field is required. :param order: :class:`GetEventsOrder` (optional)   The order to list events in; either ""ASC"" or ""DESC"". Defaults to ""DESC"". :param page_size: int (optional)   The maximum number of events to include in a page of events. The server may further constrain the   maximum number of results returned in a single page. If the page_size is empty or 0, the server will   decide the number of results to be returned. The field has to be in the range [0,500]. If the value   is outside the range, the server enforces 0 or 500. :param page_token: str (optional)   Use next_page_token or prev_page_token returned from the previous request to list the next or   previous page of events respectively. If page_token is empty, the first page is returned. :param start_time: int (optional)   The start time in epoch milliseconds. If empty, returns events starting from the beginning of time.  :returns: Iterator over :class:`ClusterEvent`",clusters,events,exec,$.events
compute.json,/api/2.1/clusters/get,clusters_get,get,ClusterDetails,"compute, clusters",cluster_id,Retrieves the information for a cluster given its identifier. Clusters can be described while they are,"Retrieves the information for a cluster given its identifier. Clusters can be described while they are running, or up to 60 days after they are terminated.  :param cluster_id: str   The cluster about which to retrieve information.  :returns: :class:`ClusterDetails`",clusters,get,select,
compute.json,/api/2.1/clusters/list,clusters_list,get,ListClustersResponse,"compute, clusters","filter_by, page_size, page_token, sort_by","Return information about all pinned and active clusters, and all clusters terminated within the last","Return information about all pinned and active clusters, and all clusters terminated within the last 30 days. Clusters terminated prior to this period are not included.  :param filter_by: :class:`ListClustersFilterBy` (optional)   Filters to apply to the list of clusters. :param page_size: int (optional)   Use this field to specify the maximum number of results to be returned by the server. The server may   further constrain the maximum number of results returned in a single page. :param page_token: str (optional)   Use next_page_token or prev_page_token returned from the previous request to list the next or   previous page of clusters respectively. :param sort_by: :class:`ListClustersSortBy` (optional)   Sort the list of clusters by a specific criteria.  :returns: Iterator over :class:`ClusterDetails`",clusters,list,select,$.clusters
compute.json,/api/2.1/clusters/permanent-delete,clusters_permanent_delete,post,,"compute, clusters",cluster_id,Permanently deletes a Spark cluster. This cluster is terminated and resources are asynchronously,"Permanently deletes a Spark cluster. This cluster is terminated and resources are asynchronously removed.  In addition, users will no longer see permanently deleted clusters in the cluster list, and API users can no longer perform any action on permanently deleted clusters.  :param cluster_id: str   The cluster to be deleted.",clusters,permanent_delete,exec,
compute.json,/api/2.1/clusters/pin,clusters_pin,post,,"compute, clusters",cluster_id,Pinning a cluster ensures that the cluster will always be returned by the ListClusters API. Pinning a,Pinning a cluster ensures that the cluster will always be returned by the ListClusters API. Pinning a cluster that is already pinned will have no effect. This API can only be called by workspace admins.  :param cluster_id: str,clusters,pin,exec,
compute.json,/api/2.1/clusters/resize,clusters_resize,post,ClusterDetails,"compute, clusters","cluster_id, autoscale, num_workers",Resizes a cluster to have a desired number of workers. This will fail unless the cluster is in a,"Resizes a cluster to have a desired number of workers. This will fail unless the cluster is in a `RUNNING` state.  :param cluster_id: str   The cluster to be resized. :param autoscale: :class:`AutoScale` (optional)   Parameters needed in order to automatically scale clusters up and down based on load. Note:   autoscaling works best with DB runtime versions 3.0 or later. :param num_workers: int (optional)   Number of worker nodes that this cluster should have. A cluster has one Spark Driver and   `num_workers` Executors for a total of `num_workers` + 1 Spark nodes.    Note: When reading the properties of a cluster, this field reflects the desired number of workers   rather than the actual current number of workers. For instance, if a cluster is resized from 5 to 10   workers, this field will immediately be updated to reflect the target size of 10 workers, whereas   the workers listed in `spark_info` will gradually increase from 5 to 10 as the new nodes are   provisioned.  :returns:   Long-running operation waiter for :class:`ClusterDetails`.   See :method:wait_get_cluster_running for more details.",clusters,resize,exec,
compute.json,/api/2.1/clusters/restart,clusters_restart,post,ClusterDetails,"compute, clusters","cluster_id, restart_user","Restarts a Spark cluster with the supplied ID. If the cluster is not currently in a `RUNNING` state,","Restarts a Spark cluster with the supplied ID. If the cluster is not currently in a `RUNNING` state, nothing will happen.  :param cluster_id: str   The cluster to be started. :param restart_user: str (optional)  :returns:   Long-running operation waiter for :class:`ClusterDetails`.   See :method:wait_get_cluster_running for more details.",clusters,restart,exec,
compute.json,/api/2.1/clusters/start,clusters_start,post,ClusterDetails,"compute, clusters",cluster_id,Starts a terminated Spark cluster with the supplied ID. This works similar to `createCluster` except:,"Starts a terminated Spark cluster with the supplied ID. This works similar to `createCluster` except: - The previous cluster id and attributes are preserved. - The cluster starts with the last specified cluster size. - If the previous cluster was an autoscaling cluster, the current cluster starts with the minimum number of nodes. - If the cluster is not currently in a ``TERMINATED`` state, nothing will happen. - Clusters launched to run a job cannot be started.  :param cluster_id: str   The cluster to be started.  :returns:   Long-running operation waiter for :class:`ClusterDetails`.   See :method:wait_get_cluster_running for more details.",clusters,start,exec,
compute.json,/api/2.1/clusters/unpin,clusters_unpin,post,,"compute, clusters",cluster_id,Unpinning a cluster will allow the cluster to eventually be removed from the ListClusters API.,Unpinning a cluster will allow the cluster to eventually be removed from the ListClusters API. Unpinning a cluster that is not pinned will have no effect. This API can only be called by workspace admins.  :param cluster_id: str,clusters,unpin,exec,
compute.json,/api/2.1/clusters/update,clusters_update,post,ClusterDetails,"compute, clusters","cluster_id, update_mask, cluster",Updates the configuration of a cluster to match the partial set of attributes and size. Denote which,"Updates the configuration of a cluster to match the partial set of attributes and size. Denote which fields to update using the `update_mask` field in the request body. A cluster can be updated if it is in a `RUNNING` or `TERMINATED` state. If a cluster is updated while in a `RUNNING` state, it will be restarted so that the new attributes can take effect. If a cluster is updated while in a `TERMINATED` state, it will remain `TERMINATED`. The updated attributes will take effect the next time the cluster is started using the `clusters/start` API. Attempts to update a cluster in any other state will be rejected with an `INVALID_STATE` error code. Clusters created by the Databricks Jobs service cannot be updated.  :param cluster_id: str   ID of the cluster. :param update_mask: str   Used to specify which cluster attributes and size fields to update. See https://google.aip.dev/161   for more details.    The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future. :param cluster: :class:`UpdateClusterResource` (optional)   The cluster to be updated.  :returns:   Long-running operation waiter for :class:`ClusterDetails`.   See :method:wait_get_cluster_running for more details.",clusters,update,exec,
compute.json,/api/1.2/commands/cancel,command_execution_cancel,post,CommandStatusResponse,"compute, command_execution","cluster_id, command_id, context_id",Cancels a currently running command within an execution context.,Cancels a currently running command within an execution context.  The command ID is obtained from a prior successful call to __execute__.  :param cluster_id: str (optional) :param command_id: str (optional) :param context_id: str (optional)  :returns:   Long-running operation waiter for :class:`CommandStatusResponse`.   See :method:wait_command_status_command_execution_cancelled for more details.,command_execution,cancel,exec,
compute.json,/api/1.2/commands/status,command_execution_command_status,get,CommandStatusResponse,"compute, command_execution","cluster_id, context_id, command_id","Gets the status of and, if available, the results from a currently executing command.","Gets the status of and, if available, the results from a currently executing command.  The command ID is obtained from a prior successful call to __execute__.  :param cluster_id: str :param context_id: str :param command_id: str  :returns: :class:`CommandStatusResponse`",command_execution,command_status,select,
compute.json,/api/1.2/contexts/create,command_execution_create,post,ContextStatusResponse,"compute, command_execution","cluster_id, language",Creates an execution context for running cluster commands.,"Creates an execution context for running cluster commands.  If successful, this method returns the ID of the new execution context.  :param cluster_id: str (optional)   Running cluster id :param language: :class:`Language` (optional)  :returns:   Long-running operation waiter for :class:`ContextStatusResponse`.   See :method:wait_context_status_command_execution_running for more details.",command_execution,create,insert,
compute.json,/api/1.2/contexts/destroy,command_execution_destroy,post,,"compute, command_execution","cluster_id, context_id",Deletes an execution context.,Deletes an execution context.  :param cluster_id: str :param context_id: str,command_execution,destroy,exec,
compute.json,/api/1.2/commands/execute,command_execution_execute,post,CommandStatusResponse,"compute, command_execution","cluster_id, command, context_id, language","Runs a cluster command in the given execution context, using the provided language.","Runs a cluster command in the given execution context, using the provided language.  If successful, it returns an ID for tracking the status of the command's execution.  :param cluster_id: str (optional)   Running cluster id :param command: str (optional)   Executable code :param context_id: str (optional)   Running context id :param language: :class:`Language` (optional)  :returns:   Long-running operation waiter for :class:`CommandStatusResponse`.   See :method:wait_command_status_command_execution_finished_or_error for more details.",command_execution,execute,exec,
compute.json,/api/1.2/contexts/status,command_execution_context_status,get,ContextStatusResponse,"compute, command_execution","cluster_id, context_id",Gets the status for an execution context.,Gets the status for an execution context.  :param cluster_id: str :param context_id: str  :returns: :class:`ContextStatusResponse`,execution_contexts,get,select,
compute.json,/api/2.0/global-init-scripts,global_init_scripts_create,post,CreateResponse,"compute, global_init_scripts","name, script, enabled, position",Creates a new global init script in this workspace.,"Creates a new global init script in this workspace.  :param name: str   The name of the script :param script: str   The Base64-encoded content of the script. :param enabled: bool (optional)   Specifies whether the script is enabled. The script runs only if enabled. :param position: int (optional)   The position of a global init script, where 0 represents the first script to run, 1 is the second   script to run, in ascending order.    If you omit the numeric position for a new global init script, it defaults to last position. It will   run after all current scripts. Setting any value greater than the position of the last script is   equivalent to the last position. Example: Take three existing scripts with positions 0, 1, and 2.   Any position of (3) or greater puts the script in the last position. If an explicit position value   conflicts with an existing script value, your request succeeds, but the original script at that   position and all later scripts have their positions incremented by 1.  :returns: :class:`CreateResponse`",global_init_scripts,create,insert,
compute.json,/api/2.0/global-init-scripts,global_init_scripts_list,get,ListGlobalInitScriptsResponse,"compute, global_init_scripts",,Get a list of all global init scripts for this workspace. This returns all properties for each script,"Get a list of all global init scripts for this workspace. This returns all properties for each script but **not** the script contents. To retrieve the contents of a script, use the [get a global init script](:method:globalinitscripts/get) operation.   :returns: Iterator over :class:`GlobalInitScriptDetails`",global_init_scripts,list,select,$.scripts
compute.json,/api/2.0/global-init-scripts/{script_id},global_init_scripts_delete,delete,,"compute, global_init_scripts",script_id,Deletes a global init script.,Deletes a global init script.  :param script_id: str   The ID of the global init script.,global_init_scripts,delete,delete,
compute.json,/api/2.0/global-init-scripts/{script_id},global_init_scripts_get,get,GlobalInitScriptDetailsWithContent,"compute, global_init_scripts",script_id,"Gets all the details of a script, including its Base64-encoded contents.","Gets all the details of a script, including its Base64-encoded contents.  :param script_id: str   The ID of the global init script.  :returns: :class:`GlobalInitScriptDetailsWithContent`",global_init_scripts,get,select,
compute.json,/api/2.0/global-init-scripts/{script_id},global_init_scripts_update,patch,,"compute, global_init_scripts","script_id, name, script, enabled, position","Updates a global init script, specifying only the fields to change. All fields are optional.","Updates a global init script, specifying only the fields to change. All fields are optional. Unspecified fields retain their current value.  :param script_id: str   The ID of the global init script. :param name: str   The name of the script :param script: str   The Base64-encoded content of the script. :param enabled: bool (optional)   Specifies whether the script is enabled. The script runs only if enabled. :param position: int (optional)   The position of a script, where 0 represents the first script to run, 1 is the second script to run,   in ascending order. To move the script to run first, set its position to 0.    To move the script to the end, set its position to any value greater or equal to the position of the   last script. Example, three existing scripts with positions 0, 1, and 2. Any position value of 2 or   greater puts the script in the last position (2).    If an explicit position value conflicts with an existing script, your request succeeds, but the   original script at that position and all later scripts have their positions incremented by 1.",global_init_scripts,update,update,
compute.json,/api/2.0/permissions/instance-pools/{instance_pool_id}/permissionLevels,instance_pools_get_permission_levels,get,GetInstancePoolPermissionLevelsResponse,"compute, instance_pools",instance_pool_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param instance_pool_id: str   The instance pool for which to get or manage permissions.  :returns: :class:`GetInstancePoolPermissionLevelsResponse`,instance_pool_permission_levels,get,select,
compute.json,/api/2.0/permissions/instance-pools/{instance_pool_id},instance_pools_get_permissions,get,InstancePoolPermissions,"compute, instance_pools",instance_pool_id,Gets the permissions of an instance pool. Instance pools can inherit permissions from their root,Gets the permissions of an instance pool. Instance pools can inherit permissions from their root object.  :param instance_pool_id: str   The instance pool for which to get or manage permissions.  :returns: :class:`InstancePoolPermissions`,instance_pool_permissions,get,select,
compute.json,/api/2.0/permissions/instance-pools/{instance_pool_id},instance_pools_set_permissions,put,InstancePoolPermissions,"compute, instance_pools","instance_pool_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param instance_pool_id: str   The instance pool for which to get or manage permissions. :param access_control_list: List[:class:`InstancePoolAccessControlRequest`] (optional)  :returns: :class:`InstancePoolPermissions`",instance_pool_permissions,set,replace,
compute.json,/api/2.0/permissions/instance-pools/{instance_pool_id},instance_pools_update_permissions,patch,InstancePoolPermissions,"compute, instance_pools","instance_pool_id, access_control_list",Updates the permissions on an instance pool. Instance pools can inherit permissions from their root,Updates the permissions on an instance pool. Instance pools can inherit permissions from their root object.  :param instance_pool_id: str   The instance pool for which to get or manage permissions. :param access_control_list: List[:class:`InstancePoolAccessControlRequest`] (optional)  :returns: :class:`InstancePoolPermissions`,instance_pool_permissions,update,update,
compute.json,/api/2.0/instance-pools/create,instance_pools_create,post,CreateInstancePoolResponse,"compute, instance_pools","instance_pool_name, node_type_id, aws_attributes, azure_attributes, custom_tags, disk_spec, enable_elastic_disk, gcp_attributes, idle_instance_autotermination_minutes, max_capacity, min_idle_instances, node_type_flexibility, preloaded_docker_images, preloaded_spark_versions, remote_disk_throughput, total_initial_remote_disk_size",Creates a new instance pool using idle and ready-to-use cloud instances.,"Creates a new instance pool using idle and ready-to-use cloud instances.  :param instance_pool_name: str   Pool name requested by the user. Pool name must be unique. Length must be between 1 and 100   characters. :param node_type_id: str   This field encodes, through a single value, the resources available to each of the Spark nodes in   this cluster. For example, the Spark nodes can be provisioned and optimized for memory or compute   intensive workloads. A list of available node types can be retrieved by using the   :method:clusters/listNodeTypes API call. :param aws_attributes: :class:`InstancePoolAwsAttributes` (optional)   Attributes related to instance pools running on Amazon Web Services. If not specified at pool   creation, a set of default values will be used. :param azure_attributes: :class:`InstancePoolAzureAttributes` (optional)   Attributes related to instance pools running on Azure. If not specified at pool creation, a set of   default values will be used. :param custom_tags: Dict[str,str] (optional)   Additional tags for pool resources. Databricks will tag all pool resources (e.g., AWS instances and   EBS volumes) with these tags in addition to `default_tags`. Notes:    - Currently, Databricks allows at most 45 custom tags :param disk_spec: :class:`DiskSpec` (optional)   Defines the specification of the disks that will be attached to all spark containers. :param enable_elastic_disk: bool (optional)   Autoscaling Local Storage: when enabled, this instances in this pool will dynamically acquire   additional disk space when its Spark workers are running low on disk space. In AWS, this feature   requires specific AWS permissions to function correctly - refer to the User Guide for more details. :param gcp_attributes: :class:`InstancePoolGcpAttributes` (optional)   Attributes related to instance pools running on Google Cloud Platform. If not specified at pool   creation, a set of default values will be used. :param idle_instance_autotermination_minutes: int (optional)   Automatically terminates the extra instances in the pool cache after they are inactive for this time   in minutes if min_idle_instances requirement is already met. If not set, the extra pool instances   will be automatically terminated after a default timeout. If specified, the threshold must be   between 0 and 10000 minutes. Users can also set this value to 0 to instantly remove idle instances   from the cache if min cache size could still hold. :param max_capacity: int (optional)   Maximum number of outstanding instances to keep in the pool, including both instances used by   clusters and idle instances. Clusters that require further instance provisioning will fail during   upsize requests. :param min_idle_instances: int (optional)   Minimum number of idle instances to keep in the instance pool :param node_type_flexibility: :class:`NodeTypeFlexibility` (optional)   Flexible node type configuration for the pool. :param preloaded_docker_images: List[:class:`DockerImage`] (optional)   Custom Docker Image BYOC :param preloaded_spark_versions: List[str] (optional)   A list containing at most one preloaded Spark image version for the pool. Pool-backed clusters   started with the preloaded Spark version will start faster. A list of available Spark versions can   be retrieved by using the :method:clusters/sparkVersions API call. :param remote_disk_throughput: int (optional)   If set, what the configurable throughput (in Mb/s) for the remote disk is. Currently only supported   for GCP HYPERDISK_BALANCED types. :param total_initial_remote_disk_size: int (optional)   If set, what the total initial volume size (in GB) of the remote disks should be. Currently only   supported for GCP HYPERDISK_BALANCED types.  :returns: :class:`CreateInstancePoolResponse`",instance_pools,create,insert,
compute.json,/api/2.0/instance-pools/delete,instance_pools_delete,post,,"compute, instance_pools",instance_pool_id,Deletes the instance pool permanently. The idle instances in the pool are terminated asynchronously.,Deletes the instance pool permanently. The idle instances in the pool are terminated asynchronously.  :param instance_pool_id: str   The instance pool to be terminated.,instance_pools,delete,delete,
compute.json,/api/2.0/instance-pools/edit,instance_pools_edit,post,,"compute, instance_pools","instance_pool_id, instance_pool_name, node_type_id, custom_tags, idle_instance_autotermination_minutes, max_capacity, min_idle_instances, node_type_flexibility, remote_disk_throughput, total_initial_remote_disk_size",Modifies the configuration of an existing instance pool.,"Modifies the configuration of an existing instance pool.  :param instance_pool_id: str   Instance pool ID :param instance_pool_name: str   Pool name requested by the user. Pool name must be unique. Length must be between 1 and 100   characters. :param node_type_id: str   This field encodes, through a single value, the resources available to each of the Spark nodes in   this cluster. For example, the Spark nodes can be provisioned and optimized for memory or compute   intensive workloads. A list of available node types can be retrieved by using the   :method:clusters/listNodeTypes API call. :param custom_tags: Dict[str,str] (optional)   Additional tags for pool resources. Databricks will tag all pool resources (e.g., AWS instances and   EBS volumes) with these tags in addition to `default_tags`. Notes:    - Currently, Databricks allows at most 45 custom tags :param idle_instance_autotermination_minutes: int (optional)   Automatically terminates the extra instances in the pool cache after they are inactive for this time   in minutes if min_idle_instances requirement is already met. If not set, the extra pool instances   will be automatically terminated after a default timeout. If specified, the threshold must be   between 0 and 10000 minutes. Users can also set this value to 0 to instantly remove idle instances   from the cache if min cache size could still hold. :param max_capacity: int (optional)   Maximum number of outstanding instances to keep in the pool, including both instances used by   clusters and idle instances. Clusters that require further instance provisioning will fail during   upsize requests. :param min_idle_instances: int (optional)   Minimum number of idle instances to keep in the instance pool :param node_type_flexibility: :class:`NodeTypeFlexibility` (optional)   Flexible node type configuration for the pool. :param remote_disk_throughput: int (optional)   If set, what the configurable throughput (in Mb/s) for the remote disk is. Currently only supported   for GCP HYPERDISK_BALANCED types. :param total_initial_remote_disk_size: int (optional)   If set, what the total initial volume size (in GB) of the remote disks should be. Currently only   supported for GCP HYPERDISK_BALANCED types.",instance_pools,replace,replace,
compute.json,/api/2.0/instance-pools/get,instance_pools_get,get,GetInstancePool,"compute, instance_pools",instance_pool_id,Retrieve the information for an instance pool based on its identifier.,Retrieve the information for an instance pool based on its identifier.  :param instance_pool_id: str   The canonical unique identifier for the instance pool.  :returns: :class:`GetInstancePool`,instance_pools,get,select,
compute.json,/api/2.0/instance-pools/list,instance_pools_list,get,ListInstancePools,"compute, instance_pools",,Gets a list of instance pools with their statistics.,Gets a list of instance pools with their statistics.   :returns: Iterator over :class:`InstancePoolAndStats`,instance_pools,list,select,$.instance_pools
compute.json,/api/2.0/instance-profiles/add,instance_profiles_add,post,,"compute, instance_profiles","instance_profile_arn, iam_role_arn, is_meta_instance_profile, skip_validation","Registers an instance profile in Databricks. In the UI, you can then give users the permission to use","Registers an instance profile in Databricks. In the UI, you can then give users the permission to use this instance profile when launching clusters.  This API is only available to admin users.  :param instance_profile_arn: str   The AWS ARN of the instance profile to register with Databricks. This field is required. :param iam_role_arn: str (optional)   The AWS IAM role ARN of the role associated with the instance profile. This field is required if   your role name and instance profile name do not match and you want to use the instance profile with   [Databricks SQL Serverless].    Otherwise, this field is optional.    [Databricks SQL Serverless]: https://docs.databricks.com/sql/admin/serverless.html :param is_meta_instance_profile: bool (optional)   Boolean flag indicating whether the instance profile should only be used in credential passthrough   scenarios. If true, it means the instance profile contains an meta IAM role which could assume a   wide range of roles. Therefore it should always be used with authorization. This field is optional,   the default value is `false`. :param skip_validation: bool (optional)   By default, Databricks validates that it has sufficient permissions to launch instances with the   instance profile. This validation uses AWS dry-run mode for the RunInstances API. If validation   fails with an error message that does not indicate an IAM related permission issue, (e.g. “Your   requested instance type is not supported in your requested availability zone”), you can pass this   flag to skip the validation and forcibly add the instance profile.",instance_profiles,add,insert,
compute.json,/api/2.0/instance-profiles/edit,instance_profiles_edit,post,,"compute, instance_profiles","instance_profile_arn, iam_role_arn, is_meta_instance_profile",The only supported field to change is the optional IAM role ARN associated with the instance profile.,"The only supported field to change is the optional IAM role ARN associated with the instance profile. It is required to specify the IAM role ARN if both of the following are true:  * Your role name and instance profile name do not match. The name is the part after the last slash in each ARN. * You want to use the instance profile with [Databricks SQL Serverless].  To understand where these fields are in the AWS console, see [Enable serverless SQL warehouses].  This API is only available to admin users.  [Databricks SQL Serverless]: https://docs.databricks.com/sql/admin/serverless.html [Enable serverless SQL warehouses]: https://docs.databricks.com/sql/admin/serverless.html  :param instance_profile_arn: str   The AWS ARN of the instance profile to register with Databricks. This field is required. :param iam_role_arn: str (optional)   The AWS IAM role ARN of the role associated with the instance profile. This field is required if   your role name and instance profile name do not match and you want to use the instance profile with   [Databricks SQL Serverless].    Otherwise, this field is optional.    [Databricks SQL Serverless]: https://docs.databricks.com/sql/admin/serverless.html :param is_meta_instance_profile: bool (optional)   Boolean flag indicating whether the instance profile should only be used in credential passthrough   scenarios. If true, it means the instance profile contains an meta IAM role which could assume a   wide range of roles. Therefore it should always be used with authorization. This field is optional,   the default value is `false`.",instance_profiles,edit,replace,
compute.json,/api/2.0/instance-profiles/list,instance_profiles_list,get,ListInstanceProfilesResponse,"compute, instance_profiles",,List the instance profiles that the calling user can use to launch a cluster.,List the instance profiles that the calling user can use to launch a cluster.  This API is available to all users.   :returns: Iterator over :class:`InstanceProfile`,instance_profiles,list,select,$.instance_profiles
compute.json,/api/2.0/instance-profiles/remove,instance_profiles_remove,post,,"compute, instance_profiles",instance_profile_arn,Remove the instance profile with the provided ARN. Existing clusters with this instance profile will,Remove the instance profile with the provided ARN. Existing clusters with this instance profile will continue to function.  This API is only accessible to admin users.  :param instance_profile_arn: str   The ARN of the instance profile to remove. This field is required.,instance_profiles,remove,delete,
compute.json,/api/2.0/libraries/cluster-status,libraries_cluster_status,get,ClusterLibraryStatuses,"compute, libraries",cluster_id,Get the status of libraries on a cluster. A status is returned for all libraries installed on this,"Get the status of libraries on a cluster. A status is returned for all libraries installed on this cluster via the API or the libraries UI. The order of returned libraries is as follows: 1. Libraries set to be installed on this cluster, in the order that the libraries were added to the cluster, are returned first. 2. Libraries that were previously requested to be installed on this cluster or, but are now marked for removal, in no particular order, are returned last.  :param cluster_id: str   Unique identifier of the cluster whose status should be retrieved.  :returns: Iterator over :class:`LibraryFullStatus`",libraries,get,select,$.library_statuses
compute.json,/api/2.0/libraries/install,libraries_install,post,,"compute, libraries","cluster_id, libraries",Add libraries to install on a cluster. The installation is asynchronous; it happens in the background,Add libraries to install on a cluster. The installation is asynchronous; it happens in the background after the completion of this request.  :param cluster_id: str   Unique identifier for the cluster on which to install these libraries. :param libraries: List[:class:`Library`]   The libraries to install.,libraries,install,insert,
compute.json,/api/2.0/libraries/uninstall,libraries_uninstall,post,,"compute, libraries","cluster_id, libraries",Set libraries to uninstall from a cluster. The libraries won't be uninstalled until the cluster is,Set libraries to uninstall from a cluster. The libraries won't be uninstalled until the cluster is restarted. A request to uninstall a library that is not currently installed is ignored.  :param cluster_id: str   Unique identifier for the cluster on which to uninstall these libraries. :param libraries: List[:class:`Library`]   The libraries to uninstall.,libraries,uninstall,exec,
compute.json,/api/2.0/policies/clusters/enforce-compliance,policy_compliance_for_clusters_enforce_compliance,post,EnforceClusterComplianceResponse,"compute, policy_compliance_for_clusters","cluster_id, validate_only",Updates a cluster to be compliant with the current version of its policy. A cluster can be updated if,"Updates a cluster to be compliant with the current version of its policy. A cluster can be updated if it is in a `RUNNING` or `TERMINATED` state.  If a cluster is updated while in a `RUNNING` state, it will be restarted so that the new attributes can take effect.  If a cluster is updated while in a `TERMINATED` state, it will remain `TERMINATED`. The next time the cluster is started, the new attributes will take effect.  Clusters created by the Databricks Jobs, DLT, or Models services cannot be enforced by this API. Instead, use the ""Enforce job policy compliance"" API to enforce policy compliance on jobs.  :param cluster_id: str   The ID of the cluster you want to enforce policy compliance on. :param validate_only: bool (optional)   If set, previews the changes that would be made to a cluster to enforce compliance but does not   update the cluster.  :returns: :class:`EnforceClusterComplianceResponse`",policy_compliance_for_clusters,enforce,insert,
compute.json,/api/2.0/policies/clusters/get-compliance,policy_compliance_for_clusters_get_compliance,get,GetClusterComplianceResponse,"compute, policy_compliance_for_clusters",cluster_id,Returns the policy compliance status of a cluster. Clusters could be out of compliance if their policy,Returns the policy compliance status of a cluster. Clusters could be out of compliance if their policy was updated after the cluster was last edited.  :param cluster_id: str   The ID of the cluster to get the compliance status  :returns: :class:`GetClusterComplianceResponse`,policy_compliance_for_clusters,get,select,
compute.json,/api/2.0/policies/clusters/list-compliance,policy_compliance_for_clusters_list_compliance,get,ListClusterCompliancesResponse,"compute, policy_compliance_for_clusters","policy_id, page_size, page_token",Returns the policy compliance status of all clusters that use a given policy. Clusters could be out of,Returns the policy compliance status of all clusters that use a given policy. Clusters could be out of compliance if their policy was updated after the cluster was last edited.  :param policy_id: str   Canonical unique identifier for the cluster policy. :param page_size: int (optional)   Use this field to specify the maximum number of results to be returned by the server. The server may   further constrain the maximum number of results returned in a single page. :param page_token: str (optional)   A page token that can be used to navigate to the next page or previous page as returned by   `next_page_token` or `prev_page_token`.  :returns: Iterator over :class:`ClusterCompliance`,policy_compliance_for_clusters,list,select,$.clusters
compute.json,/api/2.0/policy-families/{policy_family_id},policy_families_get,get,PolicyFamily,"compute, policy_families","policy_family_id, version",Retrieve the information for an policy family based on its identifier and version,Retrieve the information for an policy family based on its identifier and version  :param policy_family_id: str   The family ID about which to retrieve information. :param version: int (optional)   The version number for the family to fetch. Defaults to the latest version.  :returns: :class:`PolicyFamily`,policy_families,get,select,
compute.json,/api/2.0/policy-families,policy_families_list,get,ListPolicyFamiliesResponse,"compute, policy_families","max_results, page_token",Returns the list of policy definition types available to use at their latest version. This API is,Returns the list of policy definition types available to use at their latest version. This API is paginated.  :param max_results: int (optional)   Maximum number of policy families to return. :param page_token: str (optional)   A token that can be used to get the next page of results.  :returns: Iterator over :class:`PolicyFamily`,policy_families,list,select,$.policy_families
compute.json,/api/2.1/clusters/spark-versions,clusters_spark_versions,get,GetSparkVersionsResponse,"compute, clusters",,Returns the list of available Spark versions. These versions can be used to launch a cluster.,Returns the list of available Spark versions. These versions can be used to launch a cluster.   :returns: :class:`GetSparkVersionsResponse`,spark_versions,list,select,
dashboards.json,/api/2.0/genie/spaces,genie_create_space,post,GenieSpace,"dashboards, genie","warehouse_id, serialized_space, description, parent_path, title",Creates a Genie space from a serialized payload.,"Creates a Genie space from a serialized payload.  :param warehouse_id: str   Warehouse to associate with the new space :param serialized_space: str   The contents of the Genie Space in serialized string form. Use the [Get Genie   Space](:method:genie/getspace) API to retrieve an example response, which includes the   `serialized_space` field. This field provides the structure of the JSON string that represents the   space's layout and components. :param description: str (optional)   Optional description :param parent_path: str (optional)   Parent folder path where the space will be registered :param title: str (optional)   Optional title override  :returns: :class:`GenieSpace`",genie,create,insert,
dashboards.json,/api/2.0/genie/spaces,genie_list_spaces,get,GenieListSpacesResponse,"dashboards, genie","page_size, page_token",Get list of Genie Spaces.,Get list of Genie Spaces.  :param page_size: int (optional)   Maximum number of spaces to return per page :param page_token: str (optional)   Pagination token for getting the next page of results  :returns: :class:`GenieListSpacesResponse`,genie,list,select,
dashboards.json,/api/2.0/genie/spaces/{space_id},genie_get_space,get,GenieSpace,"dashboards, genie","space_id, include_serialized_space",Get details of a Genie Space.,Get details of a Genie Space.  :param space_id: str   The ID associated with the Genie space :param include_serialized_space: bool (optional)   Whether to include the serialized space export in the response. Requires at least CAN EDIT   permission on the space.  :returns: :class:`GenieSpace`,genie,get,select,
dashboards.json,/api/2.0/genie/spaces/{space_id},genie_trash_space,delete,,"dashboards, genie",space_id,Move a Genie Space to the trash.,Move a Genie Space to the trash.  :param space_id: str   The ID associated with the Genie space to be sent to the trash.,genie,delete,delete,
dashboards.json,/api/2.0/genie/spaces/{space_id},genie_update_space,patch,GenieSpace,"dashboards, genie","space_id, description, serialized_space, title, warehouse_id",Updates a Genie space with a serialized payload.,"Updates a Genie space with a serialized payload.  :param space_id: str   Genie space ID :param description: str (optional)   Optional description :param serialized_space: str (optional)   The contents of the Genie Space in serialized string form (full replacement). Use the [Get Genie   Space](:method:genie/getspace) API to retrieve an example response, which includes the   `serialized_space` field. This field provides the structure of the JSON string that represents the   space's layout and components. :param title: str (optional)   Optional title override :param warehouse_id: str (optional)   Optional warehouse override  :returns: :class:`GenieSpace`",genie,update,update,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id},genie_delete_conversation,delete,,"dashboards, genie","space_id, conversation_id",Delete a conversation.,Delete a conversation.  :param space_id: str   The ID associated with the Genie space where the conversation is located. :param conversation_id: str   The ID of the conversation to delete.,genie_conversations,delete,delete,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations,genie_list_conversations,get,GenieListConversationsResponse,"dashboards, genie","space_id, include_all, page_size, page_token",Get a list of conversations in a Genie Space.,Get a list of conversations in a Genie Space.  :param space_id: str   The ID of the Genie space to retrieve conversations from. :param include_all: bool (optional)   Include all conversations in the space across all users. Requires at least CAN MANAGE permission on   the space. :param page_size: int (optional)   Maximum number of conversations to return per page :param page_token: str (optional)   Token to get the next page of results  :returns: :class:`GenieListConversationsResponse`,genie_conversations,list,select,
dashboards.json,/api/2.0/genie/spaces/{space_id}/start-conversation,genie_start_conversation,post,GenieMessage,"dashboards, genie","space_id, content",Start a new conversation.,Start a new conversation.  :param space_id: str   The ID associated with the Genie space where you want to start a conversation. :param content: str   The text of the message that starts the conversation.  :returns:   Long-running operation waiter for :class:`GenieMessage`.   See :method:wait_get_message_genie_completed for more details.,genie_conversations,start,exec,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/attachments/{attachment_id}/downloads,genie_generate_download_full_query_result,post,GenieGenerateDownloadFullQueryResultResponse,"dashboards, genie","space_id, conversation_id, message_id, attachment_id",Initiates a new SQL execution and returns a `download_id` and `download_id_signature` that you can use,"Initiates a new SQL execution and returns a `download_id` and `download_id_signature` that you can use to track the progress of the download. The query result is stored in an external link and can be retrieved using the [Get Download Full Query Result](:method:genie/getdownloadfullqueryresult) API. Both `download_id` and `download_id_signature` must be provided when calling the Get endpoint.  ----  ### **Warning: Databricks strongly recommends that you protect the URLs that are returned by the `EXTERNAL_LINKS` disposition.**  When you use the `EXTERNAL_LINKS` disposition, a short-lived, URL is generated, which can be used to download the results directly from . As a short-lived is embedded in this URL, you should protect the URL.  Because URLs are already generated with embedded temporary s, you must not set an `Authorization` header in the download requests.  See [Execute Statement](:method:statementexecution/executestatement) for more details.  ----  :param space_id: str   Genie space ID :param conversation_id: str   Conversation ID :param message_id: str   Message ID :param attachment_id: str   Attachment ID  :returns: :class:`GenieGenerateDownloadFullQueryResultResponse`",genie_message_attachment_downloads,generate_download,exec,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/attachments/{attachment_id}/downloads/{download_id},genie_get_download_full_query_result,get,GenieGetDownloadFullQueryResultResponse,"dashboards, genie","space_id, conversation_id, message_id, attachment_id, download_id, download_id_signature",After [Generating a Full Query Result Download](:method:genie/generatedownloadfullqueryresult) and,"After [Generating a Full Query Result Download](:method:genie/generatedownloadfullqueryresult) and successfully receiving a `download_id` and `download_id_signature`, use this API to poll the download progress. Both `download_id` and `download_id_signature` are required to call this endpoint. When the download is complete, the API returns the result in the `EXTERNAL_LINKS` disposition, containing one or more external links to the query result files.  ----  ### **Warning: Databricks strongly recommends that you protect the URLs that are returned by the `EXTERNAL_LINKS` disposition.**  When you use the `EXTERNAL_LINKS` disposition, a short-lived, URL is generated, which can be used to download the results directly from . As a short-lived is embedded in this URL, you should protect the URL.  Because URLs are already generated with embedded temporary s, you must not set an `Authorization` header in the download requests.  See [Execute Statement](:method:statementexecution/executestatement) for more details.  ----  :param space_id: str   Genie space ID :param conversation_id: str   Conversation ID :param message_id: str   Message ID :param attachment_id: str   Attachment ID :param download_id: str   Download ID. This ID is provided by the [Generate Download   endpoint](:method:genie/generateDownloadFullQueryResult) :param download_id_signature: str (optional)   JWT signature for the download_id to ensure secure access to query results  :returns: :class:`GenieGetDownloadFullQueryResultResponse`",genie_message_attachment_downloads,get_download,select,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/attachments/{attachment_id}/execute-query,genie_execute_message_attachment_query,post,GenieGetMessageQueryResultResponse,"dashboards, genie","space_id, conversation_id, message_id, attachment_id",Execute the SQL for a message query attachment. Use this API when the query attachment has expired and,Execute the SQL for a message query attachment. Use this API when the query attachment has expired and needs to be re-executed.  :param space_id: str   Genie space ID :param conversation_id: str   Conversation ID :param message_id: str   Message ID :param attachment_id: str   Attachment ID  :returns: :class:`GenieGetMessageQueryResultResponse`,genie_message_attachments,execute_attachment_query,exec,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/attachments/{attachment_id}/query-result,genie_get_message_attachment_query_result,get,GenieGetMessageQueryResultResponse,"dashboards, genie","space_id, conversation_id, message_id, attachment_id",Get the result of SQL query if the message has a query attachment. This is only available if a message,Get the result of SQL query if the message has a query attachment. This is only available if a message has a query attachment and the message status is `EXECUTING_QUERY` OR `COMPLETED`.  :param space_id: str   Genie space ID :param conversation_id: str   Conversation ID :param message_id: str   Message ID :param attachment_id: str   Attachment ID  :returns: :class:`GenieGetMessageQueryResultResponse`,genie_message_attachments,get_query_result,select,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/execute-query,genie_execute_message_query,post,GenieGetMessageQueryResultResponse,"dashboards, genie","space_id, conversation_id, message_id",DEPRECATED: Use [Execute Message Attachment Query](:method:genie/executemessageattachmentquery),DEPRECATED: Use [Execute Message Attachment Query](:method:genie/executemessageattachmentquery) instead.  :param space_id: str   Genie space ID :param conversation_id: str   Conversation ID :param message_id: str   Message ID  :returns: :class:`GenieGetMessageQueryResultResponse`,genie_messages,execute_query,exec,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/query-result,genie_get_message_query_result,get,GenieGetMessageQueryResultResponse,"dashboards, genie","space_id, conversation_id, message_id",DEPRECATED: Use [Get Message Attachment Query Result](:method:genie/getmessageattachmentqueryresult),DEPRECATED: Use [Get Message Attachment Query Result](:method:genie/getmessageattachmentqueryresult) instead.  :param space_id: str   Genie space ID :param conversation_id: str   Conversation ID :param message_id: str   Message ID  :returns: :class:`GenieGetMessageQueryResultResponse`,genie_messages,get_query_result_deprecated,exec,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/query-result/{attachment_id},genie_get_message_query_result_by_attachment,get,GenieGetMessageQueryResultResponse,"dashboards, genie","space_id, conversation_id, message_id, attachment_id",DEPRECATED: Use [Get Message Attachment Query Result](:method:genie/getmessageattachmentqueryresult),DEPRECATED: Use [Get Message Attachment Query Result](:method:genie/getmessageattachmentqueryresult) instead.  :param space_id: str   Genie space ID :param conversation_id: str   Conversation ID :param message_id: str   Message ID :param attachment_id: str   Attachment ID  :returns: :class:`GenieGetMessageQueryResultResponse`,genie_messages,get_query_result_by_attachment,select,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages,genie_create_message,post,GenieMessage,"dashboards, genie","space_id, conversation_id, content",Create new message in a [conversation](:method:genie/startconversation). The AI response uses all,Create new message in a [conversation](:method:genie/startconversation). The AI response uses all previously created messages in the conversation to respond.  :param space_id: str   The ID associated with the Genie space where the conversation is started. :param conversation_id: str   The ID associated with the conversation. :param content: str   User message content.  :returns:   Long-running operation waiter for :class:`GenieMessage`.   See :method:wait_get_message_genie_completed for more details.,genie_messages,create,insert,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages,genie_list_conversation_messages,get,GenieListConversationMessagesResponse,"dashboards, genie","space_id, conversation_id, page_size, page_token",List messages in a conversation,List messages in a conversation  :param space_id: str   The ID associated with the Genie space where the conversation is located :param conversation_id: str   The ID of the conversation to list messages from :param page_size: int (optional)   Maximum number of messages to return per page :param page_token: str (optional)   Token to get the next page of results  :returns: :class:`GenieListConversationMessagesResponse`,genie_messages,list,select,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id},genie_delete_conversation_message,delete,,"dashboards, genie","space_id, conversation_id, message_id",Delete a conversation message.,Delete a conversation message.  :param space_id: str   The ID associated with the Genie space where the message is located. :param conversation_id: str   The ID associated with the conversation. :param message_id: str   The ID associated with the message to delete.,genie_messages,delete,delete,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id},genie_get_message,get,GenieMessage,"dashboards, genie","space_id, conversation_id, message_id",Get message from conversation.,Get message from conversation.  :param space_id: str   The ID associated with the Genie space where the target conversation is located. :param conversation_id: str   The ID associated with the target conversation. :param message_id: str   The ID associated with the target message from the identified conversation.  :returns: :class:`GenieMessage`,genie_messages,get,select,
dashboards.json,/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/feedback,genie_send_message_feedback,post,,"dashboards, genie","space_id, conversation_id, message_id, rating",Send feedback for a message.,"Send feedback for a message.  :param space_id: str   The ID associated with the Genie space where the message is located. :param conversation_id: str   The ID associated with the conversation. :param message_id: str   The ID associated with the message to provide feedback for. :param rating: :class:`GenieFeedbackRating`   The rating (POSITIVE, NEGATIVE, or NONE).",genie_messages,send_feedback,exec,
dashboards.json,/api/2.0/lakeview/dashboards,lakeview_create,post,Dashboard,"dashboards, lakeview","dataset_catalog, dataset_schema, dashboard",Create a draft dashboard.,Create a draft dashboard.  :param dashboard: :class:`Dashboard` :param dataset_catalog: str (optional)   Sets the default catalog for all datasets in this dashboard. Does not impact table references that   use fully qualified catalog names (ex: samples.nyctaxi.trips). Leave blank to keep each dataset’s   existing configuration. :param dataset_schema: str (optional)   Sets the default schema for all datasets in this dashboard. Does not impact table references that   use fully qualified schema names (ex: nyctaxi.trips). Leave blank to keep each dataset’s existing   configuration.  :returns: :class:`Dashboard`,lakeview,create,insert,
dashboards.json,/api/2.0/lakeview/dashboards,lakeview_list,get,ListDashboardsResponse,"dashboards, lakeview","page_size, page_token, show_trashed, view",List dashboards.,"List dashboards.  :param page_size: int (optional)   The number of dashboards to return per page. :param page_token: str (optional)   A page token, received from a previous `ListDashboards` call. This token can be used to retrieve the   subsequent page. :param show_trashed: bool (optional)   The flag to include dashboards located in the trash. If unspecified, only active dashboards will be   returned. :param view: :class:`DashboardView` (optional)   `DASHBOARD_VIEW_BASIC`only includes summary metadata from the dashboard.  :returns: Iterator over :class:`Dashboard`",lakeview,list,select,$.dashboards
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules/{schedule_id},lakeview_update_schedule,put,Schedule,"dashboards, lakeview","dashboard_id, schedule_id, schedule",Update dashboard schedule.,Update dashboard schedule.  :param dashboard_id: str   UUID identifying the dashboard to which the schedule belongs. :param schedule_id: str   UUID identifying the schedule. :param schedule: :class:`Schedule`   The schedule to update.  :returns: :class:`Schedule`,lakeview,update,replace,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id},lakeview_get,get,Dashboard,"dashboards, lakeview",dashboard_id,Get a draft dashboard.,Get a draft dashboard.  :param dashboard_id: str   UUID identifying the dashboard.  :returns: :class:`Dashboard`,lakeview,get,select,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id},lakeview_trash,delete,,"dashboards, lakeview",dashboard_id,Trash a dashboard.,Trash a dashboard.  :param dashboard_id: str   UUID identifying the dashboard.,lakeview,delete,delete,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id},lakeview_update,patch,Dashboard,"dashboards, lakeview","dashboard_id, dataset_catalog, dataset_schema, dashboard",Update a draft dashboard.,Update a draft dashboard.  :param dashboard_id: str   UUID identifying the dashboard. :param dashboard: :class:`Dashboard` :param dataset_catalog: str (optional)   Sets the default catalog for all datasets in this dashboard. Does not impact table references that   use fully qualified catalog names (ex: samples.nyctaxi.trips). Leave blank to keep each dataset’s   existing configuration. :param dataset_schema: str (optional)   Sets the default schema for all datasets in this dashboard. Does not impact table references that   use fully qualified schema names (ex: nyctaxi.trips). Leave blank to keep each dataset’s existing   configuration.  :returns: :class:`Dashboard`,lakeview,update,update,
dashboards.json,/api/2.0/lakeview/dashboards/migrate,lakeview_migrate,post,Dashboard,"dashboards, lakeview","source_dashboard_id, display_name, parent_path, update_parameter_syntax",Migrates a classic SQL dashboard to Lakeview.,Migrates a classic SQL dashboard to Lakeview.  :param source_dashboard_id: str   UUID of the dashboard to be migrated. :param display_name: str (optional)   Display name for the new Lakeview dashboard. :param parent_path: str (optional)   The workspace path of the folder to contain the migrated Lakeview dashboard. :param update_parameter_syntax: bool (optional)   Flag to indicate if mustache parameter syntax ({{ param }}) should be auto-updated to named syntax   (:param) when converting datasets in the dashboard.  :returns: :class:`Dashboard`,lakeview,migrate,exec,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/published/tokeninfo,lakeview_embedded_get_published_dashboard_token_info,get,GetPublishedDashboardTokenInfoResponse,"dashboards, lakeview_embedded","dashboard_id, external_value, external_viewer_id",Get a required authorization details and scopes of a published dashboard to mint an OAuth token.,Get a required authorization details and scopes of a published dashboard to mint an OAuth token.  :param dashboard_id: str   UUID identifying the published dashboard. :param external_value: str (optional)   Provided external value to be included in the custom claim. :param external_viewer_id: str (optional)   Provided external viewer id to be included in the custom claim.  :returns: :class:`GetPublishedDashboardTokenInfoResponse`,lakeview_embedded,get,select,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/published,lakeview_get_published,get,PublishedDashboard,"dashboards, lakeview",dashboard_id,Get the current published dashboard.,Get the current published dashboard.  :param dashboard_id: str   UUID identifying the published dashboard.  :returns: :class:`PublishedDashboard`,lakeview_published,get,select,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/published,lakeview_publish,post,PublishedDashboard,"dashboards, lakeview","dashboard_id, embed_credentials, warehouse_id",Publish the current draft dashboard.,Publish the current draft dashboard.  :param dashboard_id: str   UUID identifying the dashboard to be published. :param embed_credentials: bool (optional)   Flag to indicate if the publisher's credentials should be embedded in the published dashboard. These   embedded credentials will be used to execute the published dashboard's queries. :param warehouse_id: str (optional)   The ID of the warehouse that can be used to override the warehouse which was set in the draft.  :returns: :class:`PublishedDashboard`,lakeview_published,publish,exec,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/published,lakeview_unpublish,delete,,"dashboards, lakeview",dashboard_id,Unpublish the dashboard.,Unpublish the dashboard.  :param dashboard_id: str   UUID identifying the published dashboard.,lakeview_published,unpublish,exec,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules,lakeview_create_schedule,post,Schedule,"dashboards, lakeview","dashboard_id, schedule",Create dashboard schedule.,Create dashboard schedule.  :param dashboard_id: str   UUID identifying the dashboard to which the schedule belongs. :param schedule: :class:`Schedule`   The schedule to create. A dashboard is limited to 10 schedules.  :returns: :class:`Schedule`,lakeview_schedules,create,insert,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules,lakeview_list_schedules,get,ListSchedulesResponse,"dashboards, lakeview","dashboard_id, page_size, page_token",List dashboard schedules.,"List dashboard schedules.  :param dashboard_id: str   UUID identifying the dashboard to which the schedules belongs. :param page_size: int (optional)   The number of schedules to return per page. :param page_token: str (optional)   A page token, received from a previous `ListSchedules` call. Use this to retrieve the subsequent   page.  :returns: Iterator over :class:`Schedule`",lakeview_schedules,list,select,$.schedules
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules/{schedule_id},lakeview_delete_schedule,delete,,"dashboards, lakeview","dashboard_id, schedule_id, etag",Delete dashboard schedule.,"Delete dashboard schedule.  :param dashboard_id: str   UUID identifying the dashboard to which the schedule belongs. :param schedule_id: str   UUID identifying the schedule. :param etag: str (optional)   The etag for the schedule. Optionally, it can be provided to verify that the schedule has not been   modified from its last retrieval.",lakeview_schedules,delete,delete,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules/{schedule_id},lakeview_get_schedule,get,Schedule,"dashboards, lakeview","dashboard_id, schedule_id",Get dashboard schedule.,Get dashboard schedule.  :param dashboard_id: str   UUID identifying the dashboard to which the schedule belongs. :param schedule_id: str   UUID identifying the schedule.  :returns: :class:`Schedule`,lakeview_schedules,get,select,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules/{schedule_id}/subscriptions,lakeview_create_subscription,post,Subscription,"dashboards, lakeview","dashboard_id, schedule_id, subscription",Create schedule subscription.,Create schedule subscription.  :param dashboard_id: str   UUID identifying the dashboard to which the subscription belongs. :param schedule_id: str   UUID identifying the schedule to which the subscription belongs. :param subscription: :class:`Subscription`   The subscription to create. A schedule is limited to 100 subscriptions.  :returns: :class:`Subscription`,lakeview_subscriptions,create,insert,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules/{schedule_id}/subscriptions,lakeview_list_subscriptions,get,ListSubscriptionsResponse,"dashboards, lakeview","dashboard_id, schedule_id, page_size, page_token",List schedule subscriptions.,"List schedule subscriptions.  :param dashboard_id: str   UUID identifying the dashboard which the subscriptions belongs. :param schedule_id: str   UUID identifying the schedule which the subscriptions belongs. :param page_size: int (optional)   The number of subscriptions to return per page. :param page_token: str (optional)   A page token, received from a previous `ListSubscriptions` call. Use this to retrieve the subsequent   page.  :returns: Iterator over :class:`Subscription`",lakeview_subscriptions,list,select,$.subscriptions
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules/{schedule_id}/subscriptions/{subscription_id},lakeview_delete_subscription,delete,,"dashboards, lakeview","dashboard_id, schedule_id, subscription_id, etag",Delete schedule subscription.,Delete schedule subscription.  :param dashboard_id: str   UUID identifying the dashboard which the subscription belongs. :param schedule_id: str   UUID identifying the schedule which the subscription belongs. :param subscription_id: str   UUID identifying the subscription. :param etag: str (optional)   The etag for the subscription. Can be optionally provided to ensure that the subscription has not   been modified since the last read.,lakeview_subscriptions,delete,delete,
dashboards.json,/api/2.0/lakeview/dashboards/{dashboard_id}/schedules/{schedule_id}/subscriptions/{subscription_id},lakeview_get_subscription,get,Subscription,"dashboards, lakeview","dashboard_id, schedule_id, subscription_id",Get schedule subscription.,Get schedule subscription.  :param dashboard_id: str   UUID identifying the dashboard which the subscription belongs. :param schedule_id: str   UUID identifying the schedule which the subscription belongs. :param subscription_id: str   UUID identifying the subscription.  :returns: :class:`Subscription`,lakeview_subscriptions,get,select,
database.json,/api/2.0/database/catalogs,database_create_database_catalog,post,DatabaseCatalog,database,catalog,Create a Database Catalog.,Create a Database Catalog.  :param catalog: :class:`DatabaseCatalog`  :returns: :class:`DatabaseCatalog`,database_catalogs,create,insert,
database.json,/api/2.0/database/instances/{instance_name}/catalogs,database_list_database_catalogs,get,ListDatabaseCatalogsResponse,database,"instance_name, page_size, page_token","This API is currently unimplemented, but exposed for Terraform support.","This API is currently unimplemented, but exposed for Terraform support.  :param instance_name: str   Name of the instance to get database catalogs for. :param page_size: int (optional)   Upper bound for items returned. :param page_token: str (optional)   Pagination token to go to the next page of synced database tables. Requests first page if absent.  :returns: Iterator over :class:`DatabaseCatalog`",database_catalogs,list,select,$.database_catalogs
database.json,/api/2.0/database/catalogs/{name},database_delete_database_catalog,delete,,database,name,Delete a Database Catalog.,Delete a Database Catalog.  :param name: str,database_catalogs,delete,delete,
database.json,/api/2.0/database/catalogs/{name},database_get_database_catalog,get,DatabaseCatalog,database,name,Get a Database Catalog.,Get a Database Catalog.  :param name: str  :returns: :class:`DatabaseCatalog`,database_catalogs,get,select,
database.json,/api/2.0/database/catalogs/{name},database_update_database_catalog,patch,DatabaseCatalog,database,"name, update_mask, database_catalog","This API is currently unimplemented, but exposed for Terraform support.","This API is currently unimplemented, but exposed for Terraform support.  :param name: str   The name of the catalog in UC. :param database_catalog: :class:`DatabaseCatalog`   Note that updating a database catalog is not yet supported. :param update_mask: str   The list of fields to update. Setting this field is not yet supported.  :returns: :class:`DatabaseCatalog`",database_catalogs,update,update,
database.json,/api/2.0/database/credentials,database_generate_database_credential,post,DatabaseCredential,database,"claims, instance_names, request_id",Generates a credential that can be used to access database instances.,"Generates a credential that can be used to access database instances.  :param claims: List[:class:`RequestedClaims`] (optional)   The returned token will be scoped to the union of instance_names and instances containing the   specified UC tables, so instance_names is allowed to be empty. :param instance_names: List[str] (optional)   Instances to which the token will be scoped. :param request_id: str (optional)  :returns: :class:`DatabaseCredential`",database_credentials,generate,exec,
database.json,/api/2.0/database/instances/{instance_name}/roles,database_create_database_instance_role,post,DatabaseInstanceRole,database,"instance_name, database_instance_name, database_instance_role",Create a role for a Database Instance.,Create a role for a Database Instance.  :param instance_name: str :param database_instance_role: :class:`DatabaseInstanceRole` :param database_instance_name: str (optional)  :returns: :class:`DatabaseInstanceRole`,database_instance_roles,create,insert,
database.json,/api/2.0/database/instances/{instance_name}/roles/{name},database_get_database_instance_role,get,DatabaseInstanceRole,database,"instance_name, name",Gets a role for a Database Instance.,Gets a role for a Database Instance.  :param instance_name: str :param name: str  :returns: :class:`DatabaseInstanceRole`,database_instance_roles,get,select,
database.json,/api/2.0/database/instances/{instance_name}/roles/{name},database_delete_database_instance_role,delete,,database,"instance_name, name, allow_missing, reassign_owned_to",Deletes a role for a Database Instance.,Deletes a role for a Database Instance.  :param instance_name: str :param name: str :param allow_missing: bool (optional)   This is the AIP standard name for the equivalent of Postgres' `IF EXISTS` option :param reassign_owned_to: str (optional),database_instance_roles,delete,delete,
database.json,/api/2.0/database/instances/{instance_name}/roles,database_list_database_instance_roles,get,ListDatabaseInstanceRolesResponse,database,"instance_name, page_size, page_token",START OF PG ROLE APIs Section These APIs are marked a PUBLIC with stage < PUBLIC_PREVIEW. With more,"START OF PG ROLE APIs Section These APIs are marked a PUBLIC with stage < PUBLIC_PREVIEW. With more recent Lakebase V2 plans, we don't plan to ever advance these to PUBLIC_PREVIEW. These APIs will remain effectively undocumented/UI-only and we'll aim for a new public roles API as part of V2 PuPr.  :param instance_name: str :param page_size: int (optional)   Upper bound for items returned. :param page_token: str (optional)   Pagination token to go to the next page of Database Instances. Requests first page if absent.  :returns: Iterator over :class:`DatabaseInstanceRole`",database_instance_roles,list,select,$.database_instance_roles
database.json,/api/2.0/database/instances,database_create_database_instance,post,DatabaseInstance,database,database_instance,Create a Database Instance.,Create a Database Instance.  :param database_instance: :class:`DatabaseInstance`   Instance to create.  :returns:   Long-running operation waiter for :class:`DatabaseInstance`.   See :method:wait_get_database_instance_database_available for more details.,database_instances,create,insert,
database.json,/api/2.0/database/instances/{name},database_get_database_instance,get,DatabaseInstance,database,name,Get a Database Instance.,Get a Database Instance.  :param name: str   Name of the cluster to get.  :returns: :class:`DatabaseInstance`,database_instances,get,select,
database.json,/api/2.0/database/instances/{name},database_delete_database_instance,delete,,database,"name, force, purge",Delete a Database Instance.,"Delete a Database Instance.  :param name: str   Name of the instance to delete. :param force: bool (optional)   By default, a instance cannot be deleted if it has descendant instances created via PITR. If this   flag is specified as true, all descendent instances will be deleted as well. :param purge: bool (optional)   Deprecated. Omitting the field or setting it to true will result in the field being hard deleted.   Setting a value of false will throw a bad request.",database_instances,delete,delete,
database.json,/api/2.0/database/instances/{name},database_update_database_instance,patch,DatabaseInstance,database,"name, update_mask, database_instance",Update a Database Instance.,"Update a Database Instance.  :param name: str   The name of the instance. This is the unique identifier for the instance. :param database_instance: :class:`DatabaseInstance` :param update_mask: str   The list of fields to update. If unspecified, all fields will be updated when possible. To wipe out   custom_tags, specify custom_tags in the update_mask with an empty custom_tags map.  :returns: :class:`DatabaseInstance`",database_instances,update,update,
database.json,/api/2.0/database/instances,database_list_database_instances,get,ListDatabaseInstancesResponse,database,"page_size, page_token",List Database Instances.,List Database Instances.  :param page_size: int (optional)   Upper bound for items returned. :param page_token: str (optional)   Pagination token to go to the next page of Database Instances. Requests first page if absent.  :returns: Iterator over :class:`DatabaseInstance`,database_instances,list,select,$.database_instances
database.json,/api/2.0/database/instances:findByUid,database_find_database_instance_by_uid,get,DatabaseInstance,database,uid,Find a Database Instance by uid.,Find a Database Instance by uid.  :param uid: str (optional)   UID of the cluster to get.  :returns: :class:`DatabaseInstance`,database_instances,find_by_uid,select,
database.json,/api/2.0/database/tables/{name},database_delete_database_table,delete,,database,name,Delete a Database Table.,Delete a Database Table.  :param name: str,database_tables,delete,delete,
database.json,/api/2.0/database/tables/{name},database_get_database_table,get,DatabaseTable,database,name,Get a Database Table.,Get a Database Table.  :param name: str  :returns: :class:`DatabaseTable`,database_tables,get,select,
database.json,/api/2.0/database/tables,database_create_database_table,post,DatabaseTable,database,table,Create a Database Table. Useful for registering pre-existing PG tables in UC. See,Create a Database Table. Useful for registering pre-existing PG tables in UC. See CreateSyncedDatabaseTable for creating synced tables in PG from a source table in UC.  :param table: :class:`DatabaseTable`  :returns: :class:`DatabaseTable`,database_tables,create,insert,
database.json,/api/2.0/database/instances/{instance_name}/synced_tables,database_list_synced_database_tables,get,ListSyncedDatabaseTablesResponse,database,"instance_name, page_size, page_token","This API is currently unimplemented, but exposed for Terraform support.","This API is currently unimplemented, but exposed for Terraform support.  :param instance_name: str   Name of the instance to get synced tables for. :param page_size: int (optional)   Upper bound for items returned. :param page_token: str (optional)   Pagination token to go to the next page of synced database tables. Requests first page if absent.  :returns: Iterator over :class:`SyncedDatabaseTable`",synced_database_tables,list,select,$.synced_tables
database.json,/api/2.0/database/synced_tables/{name},database_get_synced_database_table,get,SyncedDatabaseTable,database,name,Get a Synced Database Table.,Get a Synced Database Table.  :param name: str  :returns: :class:`SyncedDatabaseTable`,synced_database_tables,get,select,
database.json,/api/2.0/database/synced_tables/{name},database_delete_synced_database_table,delete,,database,"name, purge_data",Delete a Synced Database Table.,"Delete a Synced Database Table.  :param name: str :param purge_data: bool (optional)   Optional. When set to true, the actual PostgreSQL table will be dropped from the database.",synced_database_tables,delete,delete,
database.json,/api/2.0/database/synced_tables/{name},database_update_synced_database_table,patch,SyncedDatabaseTable,database,"name, update_mask, synced_table","This API is currently unimplemented, but exposed for Terraform support.","This API is currently unimplemented, but exposed for Terraform support.  :param name: str   Full three-part (catalog, schema, table) name of the table. :param synced_table: :class:`SyncedDatabaseTable`   Note that updating a synced database table is not yet supported. :param update_mask: str   The list of fields to update. Setting this field is not yet supported.  :returns: :class:`SyncedDatabaseTable`",synced_database_tables,update,update,
database.json,/api/2.0/database/synced_tables,database_create_synced_database_table,post,SyncedDatabaseTable,database,synced_table,Create a Synced Database Table.,Create a Synced Database Table.  :param synced_table: :class:`SyncedDatabaseTable`  :returns: :class:`SyncedDatabaseTable`,synced_database_tables,create,insert,
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id}/refreshes/{refresh_id}/cancel,data_quality_cancel_refresh,post,CancelRefreshResponse,"dataquality, data_quality","object_type, object_id, refresh_id",Cancels a data quality monitor refresh. Currently only supported for the `table` `object_type`. The,"Cancels a data quality monitor refresh. Currently only supported for the `table` `object_type`. The call must be made in the same workspace as where the monitor was created.  The caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the table's parent catalog. 2. **USE_CATALOG** on the table's parent catalog, and **MANAGE** and **USE_SCHEMA** on the table's parent schema. 3. **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **MANAGE** on the table.  :param object_type: str   The type of the monitored object. Can be one of the following: `schema` or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id :param refresh_id: int   Unique id of the refresh operation.  :returns: :class:`CancelRefreshResponse`",data_quality_refreshes,cancel,exec,
dataquality.json,/api/data-quality/v1/monitors,data_quality_create_monitor,post,Monitor,"dataquality, data_quality",monitor,Create a data quality monitor on a Unity Catalog object. The caller must provide either,"Create a data quality monitor on a Unity Catalog object. The caller must provide either `anomaly_detection_config` for a schema monitor or `data_profiling_config` for a table monitor.  For the `table` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **SELECT** on the table 2. **USE_CATALOG** on the table's parent catalog, **MANAGE** and **USE_SCHEMA** on the table's parent schema, and **SELECT** on the table. 3. **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **MANAGE** and **SELECT** on the table.  Workspace assets, such as the dashboard, will be created in the workspace where this call was made.  For the `schema` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the schema's parent catalog. 2. **USE_CATALOG** on the schema's parent catalog, and **MANAGE** and **USE_SCHEMA** on the schema.  :param monitor: :class:`Monitor`   The monitor to create.  :returns: :class:`Monitor`",data_quality,create,insert,
dataquality.json,/api/data-quality/v1/monitors,data_quality_list_monitor,get,ListMonitorResponse,"dataquality, data_quality","page_size, page_token",(Unimplemented) List data quality monitors.,(Unimplemented) List data quality monitors.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`Monitor`,data_quality,list,select,$.monitors
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id}/refreshes,data_quality_create_refresh,post,Refresh,"dataquality, data_quality","object_type, object_id, refresh",Creates a refresh. Currently only supported for the `table` `object_type`. The call must be made in,"Creates a refresh. Currently only supported for the `table` `object_type`. The call must be made in the same workspace as where the monitor was created.  The caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the table's parent catalog. 2. **USE_CATALOG** on the table's parent catalog, and **MANAGE** and **USE_SCHEMA** on the table's parent schema. 3. **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **MANAGE** on the table.  :param object_type: str   The type of the monitored object. Can be one of the following: `schema`or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id :param refresh: :class:`Refresh`   The refresh to create  :returns: :class:`Refresh`",data_quality_refreshes,create,insert,
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id}/refreshes,data_quality_list_refresh,get,ListRefreshResponse,"dataquality, data_quality","object_type, object_id, page_size, page_token",List data quality monitor refreshes. The call must be made in the same workspace as where the monitor,"List data quality monitor refreshes. The call must be made in the same workspace as where the monitor was created.  For the `table` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the table's parent catalog. 2. **USE_CATALOG** on the table's parent catalog, and **MANAGE** and **USE_SCHEMA** on the table's parent schema. 3. **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **SELECT** on the table.  For the `schema` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the schema's parent catalog. 2. **USE_CATALOG** on the schema's parent catalog, and **USE_SCHEMA** on the schema.  :param object_type: str   The type of the monitored object. Can be one of the following: `schema` or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`Refresh`",data_quality_refreshes,list,select,$.refreshes
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id},data_quality_delete_monitor,delete,,"dataquality, data_quality","object_type, object_id",Delete a data quality monitor on Unity Catalog object.,"Delete a data quality monitor on Unity Catalog object.  For the `table` `object_type`, the caller must have either of the following sets of permissions: **MANAGE** and **USE_CATALOG** on the table's parent catalog. **USE_CATALOG** on the table's parent catalog, and **MANAGE** and **USE_SCHEMA** on the table's parent schema. **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **MANAGE** on the table.  Note that the metric tables and dashboard will not be deleted as part of this call; those assets must be manually cleaned up (if desired).  For the `schema` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the schema's parent catalog. 2. **USE_CATALOG** on the schema's parent catalog, and **MANAGE** and **USE_SCHEMA** on the schema.  :param object_type: str   The type of the monitored object. Can be one of the following: `schema` or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id",data_quality,delete,delete,
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id},data_quality_get_monitor,get,Monitor,"dataquality, data_quality","object_type, object_id",Read a data quality monitor on a Unity Catalog object.,"Read a data quality monitor on a Unity Catalog object.  For the `table` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the table's parent catalog. 2. **USE_CATALOG** on the table's parent catalog, and **MANAGE** and **USE_SCHEMA** on the table's parent schema. 3. **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **SELECT** on the table.  For the `schema` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the schema's parent catalog. 2. **USE_CATALOG** on the schema's parent catalog, and **USE_SCHEMA** on the schema.  The returned information includes configuration values on the entity and parent entity as well as information on assets created by the monitor. Some information (e.g. dashboard) may be filtered out if the caller is in a different workspace than where the monitor was created.  :param object_type: str   The type of the monitored object. Can be one of the following: `schema` or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id  :returns: :class:`Monitor`",data_quality,get,select,
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id},data_quality_update_monitor,patch,Monitor,"dataquality, data_quality","object_type, object_id, update_mask, monitor",Update a data quality monitor on Unity Catalog object.,"Update a data quality monitor on Unity Catalog object.  For the `table` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the table's parent catalog. 2. **USE_CATALOG** on the table's parent catalog, and **MANAGE** and **USE_SCHEMA** on the table's parent schema. 3. **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **MANAGE** on the table.  For the `schema` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the schema's parent catalog. 2. **USE_CATALOG** on the schema's parent catalog, and **MANAGE** and **USE_SCHEMA** on the schema.  :param object_type: str   The type of the monitored object. Can be one of the following: `schema` or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id :param monitor: :class:`Monitor`   The monitor to update. :param update_mask: str   The field mask to specify which fields to update as a comma-separated list. Example value:   `data_profiling_config.custom_metrics,data_profiling_config.schedule.quartz_cron_expression`  :returns: :class:`Monitor`",data_quality,update,update,
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id}/refreshes/{refresh_id},data_quality_delete_refresh,delete,,"dataquality, data_quality","object_type, object_id, refresh_id",(Unimplemented) Delete a refresh,"(Unimplemented) Delete a refresh  :param object_type: str   The type of the monitored object. Can be one of the following: `schema` or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id :param refresh_id: int   Unique id of the refresh operation.",data_quality_refreshes,delete,delete,
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id}/refreshes/{refresh_id},data_quality_get_refresh,get,Refresh,"dataquality, data_quality","object_type, object_id, refresh_id",Get data quality monitor refresh. The call must be made in the same workspace as where the monitor was,"Get data quality monitor refresh. The call must be made in the same workspace as where the monitor was created.  For the `table` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the table's parent catalog. 2. **USE_CATALOG** on the table's parent catalog, and **MANAGE** and **USE_SCHEMA** on the table's parent schema. 3. **USE_CATALOG** on the table's parent catalog, **USE_SCHEMA** on the table's parent schema, and **SELECT** on the table.  For the `schema` `object_type`, the caller must have either of the following sets of permissions: 1. **MANAGE** and **USE_CATALOG** on the schema's parent catalog. 2. **USE_CATALOG** on the schema's parent catalog, and **USE_SCHEMA** on the schema.  :param object_type: str   The type of the monitored object. Can be one of the following: `schema` or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id :param refresh_id: int   Unique id of the refresh operation.  :returns: :class:`Refresh`",data_quality_refreshes,get,select,
dataquality.json,/api/data-quality/v1/monitors/{object_type}/{object_id}/refreshes/{refresh_id},data_quality_update_refresh,patch,Refresh,"dataquality, data_quality","object_type, object_id, refresh_id, update_mask, refresh",(Unimplemented) Update a refresh,"(Unimplemented) Update a refresh  :param object_type: str   The type of the monitored object. Can be one of the following: `schema` or `table`. :param object_id: str   The UUID of the request object. It is `schema_id` for `schema`, and `table_id` for `table`.    Find the `schema_id` from either: 1. The [schema_id] of the `Schemas` resource. 2. In [Catalog   Explorer] > select the `schema` > go to the `Details` tab > the `Schema ID` field.    Find the `table_id` from either: 1. The [table_id] of the `Tables` resource. 2. In [Catalog   Explorer] > select the `table` > go to the `Details` tab > the `Table ID` field.    [Catalog Explorer]: https://docs.databricks.com/aws/en/catalog-explorer/   [schema_id]: https://docs.databricks.com/api/workspace/schemas/get#schema_id   [table_id]: https://docs.databricks.com/api/workspace/tables/get#table_id :param refresh_id: int   Unique id of the refresh operation. :param refresh: :class:`Refresh`   The refresh to update. :param update_mask: str   The field mask to specify which fields to update.  :returns: :class:`Refresh`",data_quality_refreshes,update,update,
files.json,/api/2.0/dbfs/add-block,dbfs_add_block,post,,"files, dbfs","handle, data","Appends a block of data to the stream specified by the input handle. If the handle does not exist,","Appends a block of data to the stream specified by the input handle. If the handle does not exist, this call will throw an exception with ``RESOURCE_DOES_NOT_EXIST``.  If the block of data exceeds 1 MB, this call will throw an exception with ``MAX_BLOCK_SIZE_EXCEEDED``.  :param handle: int   The handle on an open stream. :param data: str   The base64-encoded data to append to the stream. This has a limit of 1 MB.",dbfs,add_block,exec,
files.json,/api/2.0/dbfs/close,dbfs_close,post,,"files, dbfs",handle,"Closes the stream specified by the input handle. If the handle does not exist, this call throws an","Closes the stream specified by the input handle. If the handle does not exist, this call throws an exception with ``RESOURCE_DOES_NOT_EXIST``.  :param handle: int   The handle on an open stream.",dbfs,close,exec,
files.json,/api/2.0/dbfs/create,dbfs_create,post,CreateResponse,"files, dbfs","path, overwrite",Opens a stream to write to a file and returns a handle to this stream. There is a 10 minute idle,"Opens a stream to write to a file and returns a handle to this stream. There is a 10 minute idle timeout on this handle. If a file or directory already exists on the given path and __overwrite__ is set to false, this call will throw an exception with ``RESOURCE_ALREADY_EXISTS``.  A typical workflow for file upload would be:  1. Issue a ``create`` call and get a handle. 2. Issue one or more ``add-block`` calls with the handle you have. 3. Issue a ``close`` call with the handle you have.  :param path: str   The path of the new file. The path should be the absolute DBFS path. :param overwrite: bool (optional)   The flag that specifies whether to overwrite existing file/files.  :returns: :class:`CreateResponse`",dbfs,create,insert,
files.json,/api/2.0/dbfs/delete,dbfs_delete,post,,"files, dbfs","path, recursive",Delete the file or directory (optionally recursively delete all files in the directory). This call,"Delete the file or directory (optionally recursively delete all files in the directory). This call throws an exception with `IO_ERROR` if the path is a non-empty directory and `recursive` is set to `false` or on other similar errors.  When you delete a large number of files, the delete operation is done in increments. The call returns a response after approximately 45 seconds with an error message (503 Service Unavailable) asking you to re-invoke the delete operation until the directory structure is fully deleted.  For operations that delete more than 10K files, we discourage using the DBFS REST API, but advise you to perform such operations in the context of a cluster, using the [File system utility (dbutils.fs)](/dev-tools/databricks-utils.html#dbutils-fs). `dbutils.fs` covers the functional scope of the DBFS REST API, but from notebooks. Running such operations using notebooks provides better control and manageability, such as selective deletes, and the possibility to automate periodic delete jobs.  :param path: str   The path of the file or directory to delete. The path should be the absolute DBFS path. :param recursive: bool (optional)   Whether or not to recursively delete the directory's contents. Deleting empty directories can be   done without providing the recursive flag.",dbfs,delete,delete,
files.json,/api/2.0/dbfs/get-status,dbfs_get_status,get,FileInfo,"files, dbfs",path,"Gets the file information for a file or directory. If the file or directory does not exist, this call","Gets the file information for a file or directory. If the file or directory does not exist, this call throws an exception with `RESOURCE_DOES_NOT_EXIST`.  :param path: str   The path of the file or directory. The path should be the absolute DBFS path.  :returns: :class:`FileInfo`",dbfs,get_status,exec,
files.json,/api/2.0/dbfs/list,dbfs_list,get,ListStatusResponse,"files, dbfs",path,"List the contents of a directory, or details of the file. If the file or directory does not exist,","List the contents of a directory, or details of the file. If the file or directory does not exist, this call throws an exception with `RESOURCE_DOES_NOT_EXIST`.  When calling list on a large directory, the list operation will time out after approximately 60 seconds. We strongly recommend using list only on directories containing less than 10K files and discourage using the DBFS REST API for operations that list more than 10K files. Instead, we recommend that you perform such operations in the context of a cluster, using the [File system utility (dbutils.fs)](/dev-tools/databricks-utils.html#dbutils-fs), which provides the same functionality without timing out.  :param path: str   The path of the file or directory. The path should be the absolute DBFS path.  :returns: Iterator over :class:`FileInfo`",dbfs,list,select,$.files
files.json,/api/2.0/dbfs/mkdirs,dbfs_mkdirs,post,,"files, dbfs",path,Creates the given directory and necessary parent directories if they do not exist. If a file (not a,"Creates the given directory and necessary parent directories if they do not exist. If a file (not a directory) exists at any prefix of the input path, this call throws an exception with `RESOURCE_ALREADY_EXISTS`. **Note**: If this operation fails, it might have succeeded in creating some of the necessary parent directories.  :param path: str   The path of the new directory. The path should be the absolute DBFS path.",dbfs,mkdirs,exec,
files.json,/api/2.0/dbfs/move,dbfs_move,post,,"files, dbfs","source_path, destination_path","Moves a file from one location to another location within DBFS. If the source file does not exist,","Moves a file from one location to another location within DBFS. If the source file does not exist, this call throws an exception with `RESOURCE_DOES_NOT_EXIST`. If a file already exists in the destination path, this call throws an exception with `RESOURCE_ALREADY_EXISTS`. If the given source path is a directory, this call always recursively moves all files.  :param source_path: str   The source path of the file or directory. The path should be the absolute DBFS path. :param destination_path: str   The destination path of the file or directory. The path should be the absolute DBFS path.",dbfs,move,exec,
files.json,/api/2.0/dbfs/put,dbfs_put,post,,"files, dbfs","path, contents, overwrite","Uploads a file through the use of multipart form post. It is mainly used for streaming uploads, but","Uploads a file through the use of multipart form post. It is mainly used for streaming uploads, but can also be used as a convenient single call for data upload.  Alternatively you can pass contents as base64 string.  The amount of data that can be passed (when not streaming) using the __contents__ parameter is limited to 1 MB. `MAX_BLOCK_SIZE_EXCEEDED` will be thrown if this limit is exceeded.  If you want to upload large files, use the streaming upload. For details, see :method:dbfs/create, :method:dbfs/addBlock, :method:dbfs/close.  :param path: str   The path of the new file. The path should be the absolute DBFS path. :param contents: str (optional)   This parameter might be absent, and instead a posted file will be used. :param overwrite: bool (optional)   The flag that specifies whether to overwrite existing file/files.",dbfs,put,exec,
files.json,/api/2.0/dbfs/read,dbfs_read,get,ReadResponse,"files, dbfs","path, length, offset","Returns the contents of a file. If the file does not exist, this call throws an exception with","Returns the contents of a file. If the file does not exist, this call throws an exception with `RESOURCE_DOES_NOT_EXIST`. If the path is a directory, the read length is negative, or if the offset is negative, this call throws an exception with `INVALID_PARAMETER_VALUE`. If the read length exceeds 1 MB, this call throws an exception with `MAX_READ_SIZE_EXCEEDED`.  If `offset + length` exceeds the number of bytes in a file, it reads the contents until the end of file.  :param path: str   The path of the file to read. The path should be the absolute DBFS path. :param length: int (optional)   The number of bytes to read starting from the offset. This has a limit of 1 MB, and a default value   of 0.5 MB. :param offset: int (optional)   The offset to read from in bytes.  :returns: :class:`ReadResponse`",dbfs,read,exec,
files.json,/api/2.0/fs/directories{directory_path},files_create_directory,put,,files,directory_path,"Creates an empty directory. If necessary, also creates any parent directories of the new, empty","Creates an empty directory. If necessary, also creates any parent directories of the new, empty directory (like the shell command `mkdir -p`). If called on an existing directory, returns a success response; this method is idempotent (it will succeed if the directory already exists).  :param directory_path: str   The absolute path of a directory.",files,create_directory,replace,
files.json,/api/2.0/fs/directories{directory_path},files_delete_directory,delete,,files,directory_path,Deletes an empty directory.,"Deletes an empty directory.  To delete a non-empty directory, first delete all of its contents. This can be done by listing the directory contents and deleting each file and subdirectory recursively.  :param directory_path: str   The absolute path of a directory.",files,delete_directory,delete,
files.json,/api/2.0/fs/directories{directory_path},files_list_directory_contents,get,ListDirectoryResponse,files,"directory_path, page_size, page_token","Returns the contents of a directory. If there is no directory at the specified path, the API returns a","Returns the contents of a directory. If there is no directory at the specified path, the API returns a HTTP 404 error.  :param directory_path: str   The absolute path of a directory. :param page_size: int (optional)   The maximum number of directory entries to return. The response may contain fewer entries. If the   response contains a `next_page_token`, there may be more entries, even if fewer than `page_size`   entries are in the response.    We recommend not to set this value unless you are intentionally listing less than the complete   directory contents.    If unspecified, at most 1000 directory entries will be returned. The maximum value is 1000. Values   above 1000 will be coerced to 1000. :param page_token: str (optional)   An opaque page token which was the `next_page_token` in the response of the previous request to list   the contents of this directory. Provide this token to retrieve the next page of directory entries.   When providing a `page_token`, all other parameters provided to the request must match the previous   request. To list all of the entries in a directory, it is necessary to continue requesting pages of   entries until the response contains no `next_page_token`. Note that the number of entries returned   must not be used to determine when the listing is complete.  :returns: Iterator over :class:`DirectoryEntry`",files,list_directory_contents,select,$.contents
files.json,/api/2.0/fs/files{file_path},files_delete,delete,,files,file_path,"Deletes a file. If the request is successful, there is no response body.","Deletes a file. If the request is successful, there is no response body.  :param file_path: str   The absolute path of the file.",files,delete,delete,
files.json,/api/2.0/fs/files{file_path},files_download,get,DownloadResponse,files,file_path,"Downloads a file. The file contents are the response body. This is a standard HTTP file download, not","Downloads a file. The file contents are the response body. This is a standard HTTP file download, not a JSON RPC. It supports the Range and If-Unmodified-Since HTTP headers.  :param file_path: str   The absolute path of the file.  :returns: :class:`DownloadResponse`",files,download,select,
files.json,/api/2.0/fs/files{file_path},files_upload,put,,files,"file_path, overwrite, contents",Uploads a file of up to 5 GiB. The file contents should be sent as the request body as raw bytes (an,"Uploads a file of up to 5 GiB. The file contents should be sent as the request body as raw bytes (an octet stream); do not encode or otherwise modify the bytes before sending. The contents of the resulting file will be exactly the bytes sent in the request body. If the request is successful, there is no response body.  :param file_path: str   The absolute path of the file. :param contents: BinaryIO :param overwrite: bool (optional)   If true or unspecified, an existing file will be overwritten. If false, an error will be returned if   the path points to an existing file.",files,upload,replace,
iam.json,/api/2.0/access-control/check-policy-v2,access_control_check_policy,get,CheckPolicyResponse,"iam, access_control","actor, permission, resource, consistency_token, authz_identity, resource_info",Check access policy to a resource.,"Check access policy to a resource.  :param actor: :class:`Actor` :param permission: str :param resource: str   Ex: (servicePrincipal/use, accounts/<account-id>/servicePrincipals/<sp-id>) Ex:   (servicePrincipal.ruleSet/update, accounts/<account-id>/servicePrincipals/<sp-id>/ruleSets/default) :param consistency_token: :class:`ConsistencyToken` :param authz_identity: :class:`RequestAuthzIdentity` :param resource_info: :class:`ResourceInfo` (optional)  :returns: :class:`CheckPolicyResponse`",access_control,check,select,
iam.json,/api/2.0/preview/accounts/access-control/assignable-roles,account_access_control_proxy_get_assignable_roles_for_resource,get,GetAssignableRolesForResourceResponse,"iam, account_access_control_proxy",resource,Gets all the roles that can be granted on an account level resource. A role is grantable if the rule,Gets all the roles that can be granted on an account level resource. A role is grantable if the rule set on the resource can contain an access rule of the role.  :param resource: str   The resource name for which assignable roles will be listed.    Examples | Summary :--- | :--- `resource=accounts/<ACCOUNT_ID>` | A resource name for the account.   `resource=accounts/<ACCOUNT_ID>/groups/<GROUP_ID>` | A resource name for the group.   `resource=accounts/<ACCOUNT_ID>/servicePrincipals/<SP_ID>` | A resource name for the service   principal. `resource=accounts/<ACCOUNT_ID>/tagPolicies/<TAG_POLICY_ID>` | A resource name for the   tag policy.  :returns: :class:`GetAssignableRolesForResourceResponse`,assignable_roles,get,select,
iam.json,/api/2.0/preview/accounts/access-control/rule-sets,account_access_control_proxy_get_rule_set,get,RuleSetResponse,"iam, account_access_control_proxy","name, etag",Get a rule set by its name. A rule set is always attached to a resource and contains a list of access,"Get a rule set by its name. A rule set is always attached to a resource and contains a list of access rules on the said resource. Currently only a default rule set for each resource is supported.  :param name: str   The ruleset name associated with the request.    Examples | Summary :--- | :--- `name=accounts/<ACCOUNT_ID>/ruleSets/default` | A name for a rule set   on the account. `name=accounts/<ACCOUNT_ID>/groups/<GROUP_ID>/ruleSets/default` | A name for a rule   set on the group.   `name=accounts/<ACCOUNT_ID>/servicePrincipals/<SERVICE_PRINCIPAL_APPLICATION_ID>/ruleSets/default` |   A name for a rule set on the service principal.   `name=accounts/<ACCOUNT_ID>/tagPolicies/<TAG_POLICY_ID>/ruleSets/default` | A name for a rule set on   the tag policy. :param etag: str   Etag used for versioning. The response is at least as fresh as the eTag provided. Etag is used for   optimistic concurrency control as a way to help prevent simultaneous updates of a rule set from   overwriting each other. It is strongly suggested that systems make use of the etag in the read ->   modify -> write pattern to perform rule set updates in order to avoid race conditions that is get an   etag from a GET rule set request, and pass it with the PUT update request to identify the rule set   version you are updating.    Examples | Summary :--- | :--- `etag=` | An empty etag can only be used in GET to indicate no   freshness requirements. `etag=RENUAAABhSweA4NvVmmUYdiU717H3Tgy0UJdor3gE4a+mq/oj9NjAf8ZsQ==` | An   etag encoded a specific version of the rule set to get or to be updated.  :returns: :class:`RuleSetResponse`",rule_sets,get,select,
iam.json,/api/2.0/preview/accounts/access-control/rule-sets,account_access_control_proxy_update_rule_set,put,RuleSetResponse,"iam, account_access_control_proxy","name, rule_set","Replace the rules of a rule set. First, use get to read the current version of the rule set before","Replace the rules of a rule set. First, use get to read the current version of the rule set before modifying it. This pattern helps prevent conflicts between concurrent updates.  :param name: str   Name of the rule set. :param rule_set: :class:`RuleSetUpdateRequest`  :returns: :class:`RuleSetResponse`",rule_sets,update,replace,
iam.json,/api/2.0/preview/scim/v2/Me,current_user_me,get,User,"iam, current_user",,Get details about the current method caller's identity.,Get details about the current method caller's identity.   :returns: :class:`User`,current_user,get,select,
iam.json,/api/2.0/preview/scim/v2/Groups,groups_v2_create,post,Group,"iam, groups_v2","display_name, entitlements, external_id, groups, id, members, meta, roles, schemas","Creates a group in the Databricks workspace with a unique name, using the supplied group details.","Creates a group in the Databricks workspace with a unique name, using the supplied group details.  :param display_name: str (optional)   String that represents a human-readable group name :param entitlements: List[:class:`ComplexValue`] (optional)   Entitlements assigned to the group. See [assigning entitlements] for a full list of supported   values.    [assigning entitlements]: https://docs.databricks.com/administration-guide/users-groups/index.html#assigning-entitlements :param external_id: str (optional) :param groups: List[:class:`ComplexValue`] (optional) :param id: str (optional)   Databricks group ID :param members: List[:class:`ComplexValue`] (optional) :param meta: :class:`ResourceMeta` (optional)   Container for the group identifier. Workspace local versus account. :param roles: List[:class:`ComplexValue`] (optional)   Corresponds to AWS instance profile/arn role. :param schemas: List[:class:`GroupSchema`] (optional)   The schema of the group.  :returns: :class:`Group`",groups_v2,create,insert,
iam.json,/api/2.0/preview/scim/v2/Groups,groups_v2_list,get,ListGroupsResponse,"iam, groups_v2","attributes, count, excluded_attributes, filter, sort_by, sort_order, start_index",Gets all details of the groups associated with the Databricks workspace.,"Gets all details of the groups associated with the Databricks workspace.  :param attributes: str (optional)   Comma-separated list of attributes to return in response. :param count: int (optional)   Desired number of results per page. :param excluded_attributes: str (optional)   Comma-separated list of attributes to exclude in response. :param filter: str (optional)   Query by which the results have to be filtered. Supported operators are equals(`eq`),   contains(`co`), starts with(`sw`) and not equals(`ne`). Additionally, simple expressions can be   formed using logical operators - `and` and `or`. The [SCIM RFC] has more details but we currently   only support simple expressions.    [SCIM RFC]: https://tools.ietf.org/html/rfc7644#section-3.4.2.2 :param sort_by: str (optional)   Attribute to sort the results. :param sort_order: :class:`ListSortOrder` (optional)   The order to sort the results. :param start_index: int (optional)   Specifies the index of the first result. First item is number 1.  :returns: Iterator over :class:`Group`",groups_v2,list,select,$.Resources
iam.json,/api/2.0/preview/scim/v2/Groups/{id},groups_v2_delete,delete,,"iam, groups_v2",id,Deletes a group from the Databricks workspace.,Deletes a group from the Databricks workspace.  :param id: str   Unique ID for a group in the Databricks workspace.,groups_v2,delete,delete,
iam.json,/api/2.0/preview/scim/v2/Groups/{id},groups_v2_get,get,Group,"iam, groups_v2",id,Gets the information for a specific group in the Databricks workspace.,Gets the information for a specific group in the Databricks workspace.  :param id: str   Unique ID for a group in the Databricks workspace.  :returns: :class:`Group`,groups_v2,get,select,
iam.json,/api/2.0/preview/scim/v2/Groups/{id},groups_v2_patch,patch,,"iam, groups_v2","id, operations, schemas",Partially updates the details of a group.,"Partially updates the details of a group.  :param id: str   Unique ID in the Databricks workspace. :param operations: List[:class:`Patch`] (optional) :param schemas: List[:class:`PatchSchema`] (optional)   The schema of the patch request. Must be [""urn:ietf:params:scim:api:messages:2.0:PatchOp""].",groups_v2,patch,update,
iam.json,/api/2.0/preview/scim/v2/Groups/{id},groups_v2_update,put,,"iam, groups_v2","id, display_name, entitlements, external_id, groups, members, meta, roles, schemas",Updates the details of a group by replacing the entire group entity.,Updates the details of a group by replacing the entire group entity.  :param id: str   Databricks group ID :param display_name: str (optional)   String that represents a human-readable group name :param entitlements: List[:class:`ComplexValue`] (optional)   Entitlements assigned to the group. See [assigning entitlements] for a full list of supported   values.    [assigning entitlements]: https://docs.databricks.com/administration-guide/users-groups/index.html#assigning-entitlements :param external_id: str (optional) :param groups: List[:class:`ComplexValue`] (optional) :param members: List[:class:`ComplexValue`] (optional) :param meta: :class:`ResourceMeta` (optional)   Container for the group identifier. Workspace local versus account. :param roles: List[:class:`ComplexValue`] (optional)   Corresponds to AWS instance profile/arn role. :param schemas: List[:class:`GroupSchema`] (optional)   The schema of the group.,groups_v2,replace,replace,
iam.json,/api/2.0/permissionmigration,permission_migration_migrate_permissions,post,MigratePermissionsResponse,"iam, permission_migration","workspace_id, from_workspace_group_name, to_account_group_name, size",Migrate Permissions.,Migrate Permissions.  :param workspace_id: int   WorkspaceId of the associated workspace where the permission migration will occur. :param from_workspace_group_name: str   The name of the workspace group that permissions will be migrated from. :param to_account_group_name: str   The name of the account group that permissions will be migrated to. :param size: int (optional)   The maximum number of permissions that will be migrated.  :returns: :class:`MigratePermissionsResponse`,permission_migration,migrate,insert,
iam.json,/api/2.0/permissions/{request_object_type}/{request_object_id},permissions_get,get,ObjectPermissions,"iam, permissions","request_object_type, request_object_id",Gets the permissions of an object. Objects can inherit permissions from their parent objects or root,"Gets the permissions of an object. Objects can inherit permissions from their parent objects or root object.  :param request_object_type: str   The type of the request object. Can be one of the following: alerts, alertsv2, authorization,   clusters, cluster-policies, dashboards, dbsql-dashboards, directories, experiments, files, genie,   instance-pools, jobs, notebooks, pipelines, queries, registered-models, repos, serving-endpoints, or   warehouses. :param request_object_id: str   The id of the request object.  :returns: :class:`ObjectPermissions`",permissions,get,select,
iam.json,/api/2.0/permissions/{request_object_type}/{request_object_id},permissions_set,put,ObjectPermissions,"iam, permissions","request_object_type, request_object_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their parent objects or root object.  :param request_object_type: str   The type of the request object. Can be one of the following: alerts, alertsv2, authorization,   clusters, cluster-policies, dashboards, dbsql-dashboards, directories, experiments, files, genie,   instance-pools, jobs, notebooks, pipelines, queries, registered-models, repos, serving-endpoints, or   warehouses. :param request_object_id: str   The id of the request object. :param access_control_list: List[:class:`AccessControlRequest`] (optional)  :returns: :class:`ObjectPermissions`",permissions,set,replace,
iam.json,/api/2.0/permissions/{request_object_type}/{request_object_id},permissions_update,patch,ObjectPermissions,"iam, permissions","request_object_type, request_object_id, access_control_list",Updates the permissions on an object. Objects can inherit permissions from their parent objects or,"Updates the permissions on an object. Objects can inherit permissions from their parent objects or root object.  :param request_object_type: str   The type of the request object. Can be one of the following: alerts, alertsv2, authorization,   clusters, cluster-policies, dashboards, dbsql-dashboards, directories, experiments, files, genie,   instance-pools, jobs, notebooks, pipelines, queries, registered-models, repos, serving-endpoints, or   warehouses. :param request_object_id: str   The id of the request object. :param access_control_list: List[:class:`AccessControlRequest`] (optional)  :returns: :class:`ObjectPermissions`",permissions,update,update,
iam.json,/api/2.0/permissions/{request_object_type}/{request_object_id}/permissionLevels,permissions_get_permission_levels,get,GetPermissionLevelsResponse,"iam, permissions","request_object_type, request_object_id",Gets the permission levels that a user can have on an object.,"Gets the permission levels that a user can have on an object.  :param request_object_type: str   The type of the request object. Can be one of the following: alerts, alertsv2, authorization,   clusters, cluster-policies, dashboards, dbsql-dashboards, directories, experiments, files, genie,   instance-pools, jobs, notebooks, pipelines, queries, registered-models, repos, serving-endpoints, or   warehouses. :param request_object_id: str  :returns: :class:`GetPermissionLevelsResponse`",permission_levels,get,select,
iam.json,/api/2.0/preview/scim/v2/ServicePrincipals,service_principals_v2_create,post,ServicePrincipal,"iam, service_principals_v2","active, application_id, display_name, entitlements, external_id, groups, id, roles, schemas",Creates a new service principal in the Databricks workspace.,Creates a new service principal in the Databricks workspace.  :param active: bool (optional)   If this user is active :param application_id: str (optional)   UUID relating to the service principal :param display_name: str (optional)   String that represents a concatenation of given and family names. :param entitlements: List[:class:`ComplexValue`] (optional)   Entitlements assigned to the service principal. See [assigning entitlements] for a full list of   supported values.    [assigning entitlements]: https://docs.databricks.com/administration-guide/users-groups/index.html#assigning-entitlements :param external_id: str (optional) :param groups: List[:class:`ComplexValue`] (optional) :param id: str (optional)   Databricks service principal ID. :param roles: List[:class:`ComplexValue`] (optional)   Corresponds to AWS instance profile/arn role. :param schemas: List[:class:`ServicePrincipalSchema`] (optional)   The schema of the List response.  :returns: :class:`ServicePrincipal`,service_principals_v2,create,insert,
iam.json,/api/2.0/preview/scim/v2/ServicePrincipals,service_principals_v2_list,get,ListServicePrincipalResponse,"iam, service_principals_v2","attributes, count, excluded_attributes, filter, sort_by, sort_order, start_index",Gets the set of service principals associated with a Databricks workspace.,"Gets the set of service principals associated with a Databricks workspace.  :param attributes: str (optional)   Comma-separated list of attributes to return in response. :param count: int (optional)   Desired number of results per page. :param excluded_attributes: str (optional)   Comma-separated list of attributes to exclude in response. :param filter: str (optional)   Query by which the results have to be filtered. Supported operators are equals(`eq`),   contains(`co`), starts with(`sw`) and not equals(`ne`). Additionally, simple expressions can be   formed using logical operators - `and` and `or`. The [SCIM RFC] has more details but we currently   only support simple expressions.    [SCIM RFC]: https://tools.ietf.org/html/rfc7644#section-3.4.2.2 :param sort_by: str (optional)   Attribute to sort the results. :param sort_order: :class:`ListSortOrder` (optional)   The order to sort the results. :param start_index: int (optional)   Specifies the index of the first result. First item is number 1.  :returns: Iterator over :class:`ServicePrincipal`",service_principals_v2,list,select,$.Resources
iam.json,/api/2.0/preview/scim/v2/ServicePrincipals/{id},service_principals_v2_delete,delete,,"iam, service_principals_v2",id,Delete a single service principal in the Databricks workspace.,Delete a single service principal in the Databricks workspace.  :param id: str   Unique ID for a service principal in the Databricks workspace.,service_principals_v2,delete,delete,
iam.json,/api/2.0/preview/scim/v2/ServicePrincipals/{id},service_principals_v2_get,get,ServicePrincipal,"iam, service_principals_v2",id,Gets the details for a single service principal define in the Databricks workspace.,Gets the details for a single service principal define in the Databricks workspace.  :param id: str   Unique ID for a service principal in the Databricks workspace.  :returns: :class:`ServicePrincipal`,service_principals_v2,get,select,
iam.json,/api/2.0/preview/scim/v2/ServicePrincipals/{id},service_principals_v2_patch,patch,,"iam, service_principals_v2","id, operations, schemas",Partially updates the details of a single service principal in the Databricks workspace.,"Partially updates the details of a single service principal in the Databricks workspace.  :param id: str   Unique ID in the Databricks workspace. :param operations: List[:class:`Patch`] (optional) :param schemas: List[:class:`PatchSchema`] (optional)   The schema of the patch request. Must be [""urn:ietf:params:scim:api:messages:2.0:PatchOp""].",service_principals_v2,patch,update,
iam.json,/api/2.0/preview/scim/v2/ServicePrincipals/{id},service_principals_v2_update,put,,"iam, service_principals_v2","id, active, application_id, display_name, entitlements, external_id, groups, roles, schemas",Updates the details of a single service principal.,Updates the details of a single service principal.  This action replaces the existing service principal with the same name.  :param id: str   Databricks service principal ID. :param active: bool (optional)   If this user is active :param application_id: str (optional)   UUID relating to the service principal :param display_name: str (optional)   String that represents a concatenation of given and family names. :param entitlements: List[:class:`ComplexValue`] (optional)   Entitlements assigned to the service principal. See [assigning entitlements] for a full list of   supported values.    [assigning entitlements]: https://docs.databricks.com/administration-guide/users-groups/index.html#assigning-entitlements :param external_id: str (optional) :param groups: List[:class:`ComplexValue`] (optional) :param roles: List[:class:`ComplexValue`] (optional)   Corresponds to AWS instance profile/arn role. :param schemas: List[:class:`ServicePrincipalSchema`] (optional)   The schema of the List response.,service_principals_v2,replace,replace,
iam.json,/api/2.0/preview/scim/v2/Users,users_v2_create,post,User,"iam, users_v2","active, display_name, emails, entitlements, external_id, groups, id, name, roles, schemas, user_name",Creates a new user in the Databricks workspace. This new user will also be added to the Databricks,Creates a new user in the Databricks workspace. This new user will also be added to the Databricks account.  :param active: bool (optional)   If this user is active :param display_name: str (optional)   String that represents a concatenation of given and family names. For example `John Smith`. This   field cannot be updated through the Workspace SCIM APIs when [identity federation is enabled]. Use   Account SCIM APIs to update `displayName`.    [identity federation is enabled]: https://docs.databricks.com/administration-guide/users-groups/best-practices.html#enable-identity-federation :param emails: List[:class:`ComplexValue`] (optional)   All the emails associated with the Databricks user. :param entitlements: List[:class:`ComplexValue`] (optional)   Entitlements assigned to the user. See [assigning entitlements] for a full list of supported values.    [assigning entitlements]: https://docs.databricks.com/administration-guide/users-groups/index.html#assigning-entitlements :param external_id: str (optional)   External ID is not currently supported. It is reserved for future use. :param groups: List[:class:`ComplexValue`] (optional) :param id: str (optional)   Databricks user ID. :param name: :class:`Name` (optional) :param roles: List[:class:`ComplexValue`] (optional)   Corresponds to AWS instance profile/arn role. :param schemas: List[:class:`UserSchema`] (optional)   The schema of the user. :param user_name: str (optional)   Email address of the Databricks user.  :returns: :class:`User`,users_v2,create,insert,
iam.json,/api/2.0/preview/scim/v2/Users,users_v2_list,get,ListUsersResponse,"iam, users_v2","attributes, count, excluded_attributes, filter, sort_by, sort_order, start_index",Gets details for all the users associated with a Databricks workspace.,"Gets details for all the users associated with a Databricks workspace.  :param attributes: str (optional)   Comma-separated list of attributes to return in response. :param count: int (optional)   Desired number of results per page. :param excluded_attributes: str (optional)   Comma-separated list of attributes to exclude in response. :param filter: str (optional)   Query by which the results have to be filtered. Supported operators are equals(`eq`),   contains(`co`), starts with(`sw`) and not equals(`ne`). Additionally, simple expressions can be   formed using logical operators - `and` and `or`. The [SCIM RFC] has more details but we currently   only support simple expressions.    [SCIM RFC]: https://tools.ietf.org/html/rfc7644#section-3.4.2.2 :param sort_by: str (optional)   Attribute to sort the results. Multi-part paths are supported. For example, `userName`,   `name.givenName`, and `emails`. :param sort_order: :class:`ListSortOrder` (optional)   The order to sort the results. :param start_index: int (optional)   Specifies the index of the first result. First item is number 1.  :returns: Iterator over :class:`User`",users_v2,list,select,$.Resources
iam.json,/api/2.0/preview/scim/v2/Users/{id},users_v2_delete,delete,,"iam, users_v2",id,Deletes a user. Deleting a user from a Databricks workspace also removes objects associated with the,Deletes a user. Deleting a user from a Databricks workspace also removes objects associated with the user.  :param id: str   Unique ID for a user in the Databricks workspace.,users_v2,delete,delete,
iam.json,/api/2.0/preview/scim/v2/Users/{id},users_v2_get,get,User,"iam, users_v2","id, attributes, count, excluded_attributes, filter, sort_by, sort_order, start_index",Gets information for a specific user in Databricks workspace.,"Gets information for a specific user in Databricks workspace.  :param id: str   Unique ID for a user in the Databricks workspace. :param attributes: str (optional)   Comma-separated list of attributes to return in response. :param count: int (optional)   Desired number of results per page. :param excluded_attributes: str (optional)   Comma-separated list of attributes to exclude in response. :param filter: str (optional)   Query by which the results have to be filtered. Supported operators are equals(`eq`),   contains(`co`), starts with(`sw`) and not equals(`ne`). Additionally, simple expressions can be   formed using logical operators - `and` and `or`. The [SCIM RFC] has more details but we currently   only support simple expressions.    [SCIM RFC]: https://tools.ietf.org/html/rfc7644#section-3.4.2.2 :param sort_by: str (optional)   Attribute to sort the results. Multi-part paths are supported. For example, `userName`,   `name.givenName`, and `emails`. :param sort_order: :class:`GetSortOrder` (optional)   The order to sort the results. :param start_index: int (optional)   Specifies the index of the first result. First item is number 1.  :returns: :class:`User`",users_v2,get,select,
iam.json,/api/2.0/preview/scim/v2/Users/{id},users_v2_patch,patch,,"iam, users_v2","id, operations, schemas",Partially updates a user resource by applying the supplied operations on specific user attributes.,"Partially updates a user resource by applying the supplied operations on specific user attributes.  :param id: str   Unique ID in the Databricks workspace. :param operations: List[:class:`Patch`] (optional) :param schemas: List[:class:`PatchSchema`] (optional)   The schema of the patch request. Must be [""urn:ietf:params:scim:api:messages:2.0:PatchOp""].",users_v2,patch,update,
iam.json,/api/2.0/preview/scim/v2/Users/{id},users_v2_update,put,,"iam, users_v2","id, active, display_name, emails, entitlements, external_id, groups, name, roles, schemas, user_name",Replaces a user's information with the data supplied in request.,Replaces a user's information with the data supplied in request.  :param id: str   Databricks user ID. :param active: bool (optional)   If this user is active :param display_name: str (optional)   String that represents a concatenation of given and family names. For example `John Smith`. This   field cannot be updated through the Workspace SCIM APIs when [identity federation is enabled]. Use   Account SCIM APIs to update `displayName`.    [identity federation is enabled]: https://docs.databricks.com/administration-guide/users-groups/best-practices.html#enable-identity-federation :param emails: List[:class:`ComplexValue`] (optional)   All the emails associated with the Databricks user. :param entitlements: List[:class:`ComplexValue`] (optional)   Entitlements assigned to the user. See [assigning entitlements] for a full list of supported values.    [assigning entitlements]: https://docs.databricks.com/administration-guide/users-groups/index.html#assigning-entitlements :param external_id: str (optional)   External ID is not currently supported. It is reserved for future use. :param groups: List[:class:`ComplexValue`] (optional) :param name: :class:`Name` (optional) :param roles: List[:class:`ComplexValue`] (optional)   Corresponds to AWS instance profile/arn role. :param schemas: List[:class:`UserSchema`] (optional)   The schema of the user. :param user_name: str (optional)   Email address of the Databricks user.,users_v2,replace,replace,
iam.json,/api/2.0/permissions/authorization/passwords/permissionLevels,users_v2_get_permission_levels,get,GetPasswordPermissionLevelsResponse,"iam, users_v2",,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.   :returns: :class:`GetPasswordPermissionLevelsResponse`,password_permission_levels,get,select,
iam.json,/api/2.0/permissions/authorization/passwords,users_v2_get_permissions,get,PasswordPermissions,"iam, users_v2",,Gets the permissions of all passwords. Passwords can inherit permissions from their root object.,Gets the permissions of all passwords. Passwords can inherit permissions from their root object.   :returns: :class:`PasswordPermissions`,password_permissions,get,select,
iam.json,/api/2.0/permissions/authorization/passwords,users_v2_set_permissions,put,PasswordPermissions,"iam, users_v2",access_control_list,"Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param access_control_list: List[:class:`PasswordAccessControlRequest`] (optional)  :returns: :class:`PasswordPermissions`",password_permissions,set,replace,
iam.json,/api/2.0/permissions/authorization/passwords,users_v2_update_permissions,patch,PasswordPermissions,"iam, users_v2",access_control_list,Updates the permissions on all passwords. Passwords can inherit permissions from their root object.,Updates the permissions on all passwords. Passwords can inherit permissions from their root object.  :param access_control_list: List[:class:`PasswordAccessControlRequest`] (optional)  :returns: :class:`PasswordPermissions`,password_permissions,update,update,
iamv2.json,/api/2.0/identity/workspaceAccessDetails/{principal_id},workspace_iam_v2_get_workspace_access_detail_local,get,WorkspaceAccessDetail,"iamv2, workspace_iam_v2","principal_id, view",Returns the access details for a principal in the current workspace. Allows for checking access,"Returns the access details for a principal in the current workspace. Allows for checking access details for any provisioned principal (user, service principal, or group) in the current workspace. * Provisioned principal here refers to one that has been synced into Databricks from the customer's IdP or added explicitly to Databricks via SCIM/UI. Allows for passing in a ""view"" parameter to control what fields are returned (BASIC by default or FULL).  :param principal_id: int   Required. The internal ID of the principal (user/sp/group) for which the access details are being   requested. :param view: :class:`WorkspaceAccessDetailView` (optional)   Controls what fields are returned.  :returns: :class:`WorkspaceAccessDetail`",workspace_iam_v2,get_workspace_access_detail_local,select,
iamv2.json,/api/2.0/identity/groups/resolveByExternalId,workspace_iam_v2_resolve_group_proxy,post,ResolveGroupResponse,"iamv2, workspace_iam_v2",external_id,"Resolves a group with the given external ID from the customer's IdP. If the group does not exist, it","Resolves a group with the given external ID from the customer's IdP. If the group does not exist, it will be created in the account. If the customer is not onboarded onto Automatic Identity Management (AIM), this will return an error.  :param external_id: str   Required. The external ID of the group in the customer's IdP.  :returns: :class:`ResolveGroupResponse`",workspace_iam_v2,resolve_group_proxy,exec,
iamv2.json,/api/2.0/identity/servicePrincipals/resolveByExternalId,workspace_iam_v2_resolve_service_principal_proxy,post,ResolveServicePrincipalResponse,"iamv2, workspace_iam_v2",external_id,"Resolves an SP with the given external ID from the customer's IdP. If the SP does not exist, it will","Resolves an SP with the given external ID from the customer's IdP. If the SP does not exist, it will be created. If the customer is not onboarded onto Automatic Identity Management (AIM), this will return an error.  :param external_id: str   Required. The external ID of the service principal in the customer's IdP.  :returns: :class:`ResolveServicePrincipalResponse`",workspace_iam_v2,resolve_service_principal_proxy,exec,
iamv2.json,/api/2.0/identity/users/resolveByExternalId,workspace_iam_v2_resolve_user_proxy,post,ResolveUserResponse,"iamv2, workspace_iam_v2",external_id,"Resolves a user with the given external ID from the customer's IdP. If the user does not exist, it","Resolves a user with the given external ID from the customer's IdP. If the user does not exist, it will be created. If the customer is not onboarded onto Automatic Identity Management (AIM), this will return an error.  :param external_id: str   Required. The external ID of the user in the customer's IdP.  :returns: :class:`ResolveUserResponse`",workspace_iam_v2,resolve_user_proxy,exec,
jobs.json,/api/2.0/permissions/jobs/{job_id}/permissionLevels,jobs_get_permission_levels,get,GetJobPermissionLevelsResponse,jobs,job_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param job_id: str   The job for which to get or manage permissions.  :returns: :class:`GetJobPermissionLevelsResponse`,job_permission_levels,get,select,
jobs.json,/api/2.0/permissions/jobs/{job_id},jobs_get_permissions,get,JobPermissions,jobs,job_id,Gets the permissions of a job. Jobs can inherit permissions from their root object.,Gets the permissions of a job. Jobs can inherit permissions from their root object.  :param job_id: str   The job for which to get or manage permissions.  :returns: :class:`JobPermissions`,job_permissions,get,select,
jobs.json,/api/2.0/permissions/jobs/{job_id},jobs_set_permissions,put,JobPermissions,jobs,"job_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param job_id: str   The job for which to get or manage permissions. :param access_control_list: List[:class:`JobAccessControlRequest`] (optional)  :returns: :class:`JobPermissions`",job_permissions,set,replace,
jobs.json,/api/2.0/permissions/jobs/{job_id},jobs_update_permissions,patch,JobPermissions,jobs,"job_id, access_control_list",Updates the permissions on a job. Jobs can inherit permissions from their root object.,Updates the permissions on a job. Jobs can inherit permissions from their root object.  :param job_id: str   The job for which to get or manage permissions. :param access_control_list: List[:class:`JobAccessControlRequest`] (optional)  :returns: :class:`JobPermissions`,job_permissions,update,update,
jobs.json,/api/2.2/jobs/runs/cancel-all,jobs_cancel_all_runs,post,,jobs,"all_queued_runs, job_id","Cancels all active runs of a job. The runs are canceled asynchronously, so it doesn't prevent new runs","Cancels all active runs of a job. The runs are canceled asynchronously, so it doesn't prevent new runs from being started.  :param all_queued_runs: bool (optional)   Optional boolean parameter to cancel all queued runs. If no job_id is provided, all queued runs in   the workspace are canceled. :param job_id: int (optional)   The canonical identifier of the job to cancel all runs of.",job_runs,cancel_all,exec,
jobs.json,/api/2.2/jobs/runs/cancel,jobs_cancel_run,post,Run,jobs,run_id,"Cancels a job run or a task run. The run is canceled asynchronously, so it may still be running when","Cancels a job run or a task run. The run is canceled asynchronously, so it may still be running when this request completes.  :param run_id: int   This field is required.  :returns:   Long-running operation waiter for :class:`Run`.   See :method:wait_get_run_job_terminated_or_skipped for more details.",job_runs,cancel,exec,
jobs.json,/api/2.2/jobs/runs/delete,jobs_delete_run,post,,jobs,run_id,Deletes a non-active run. Returns an error if the run is active.,Deletes a non-active run. Returns an error if the run is active.  :param run_id: int   ID of the run to delete.,job_runs,delete,delete,
jobs.json,/api/2.2/jobs/runs/export,jobs_export_run,get,ExportRunOutput,jobs,"run_id, views_to_export",Export and retrieve the job run task.,"Export and retrieve the job run task.  :param run_id: int   The canonical identifier for the run. This field is required. :param views_to_export: :class:`ViewsToExport` (optional)   Which views to export (CODE, DASHBOARDS, or ALL). Defaults to CODE.  :returns: :class:`ExportRunOutput`",job_runs,export,exec,
jobs.json,/api/2.2/jobs/runs/get,jobs_get_run,get,Run,jobs,"run_id, include_history, include_resolved_values, page_token",Retrieves the metadata of a run.,"Retrieves the metadata of a run.  Large arrays in the results will be paginated when they exceed 100 elements. A request for a single run will return all properties for that run, and the first 100 elements of array properties (`tasks`, `job_clusters`, `job_parameters` and `repair_history`). Use the next_page_token field to check for more results and pass its value as the page_token in subsequent requests. If any array properties have more than 100 elements, additional results will be returned on subsequent requests. Arrays without additional results will be empty on later pages.  :param run_id: int   The canonical identifier of the run for which to retrieve the metadata. This field is required. :param include_history: bool (optional)   Whether to include the repair history in the response. :param include_resolved_values: bool (optional)   Whether to include resolved parameter values in the response. :param page_token: str (optional)   Use `next_page_token` returned from the previous GetRun response to request the next page of the   run's array properties.  :returns: :class:`Run`",job_runs,get,select,
jobs.json,/api/2.2/jobs/runs/get-output,jobs_get_run_output,get,RunOutput,jobs,run_id,Retrieve the output and metadata of a single task run. When a notebook task returns a value through,"Retrieve the output and metadata of a single task run. When a notebook task returns a value through the `dbutils.notebook.exit()` call, you can use this endpoint to retrieve that value. Databricks restricts this API to returning the first 5 MB of the output. To return a larger result, you can store job results in a cloud storage service.  This endpoint validates that the __run_id__ parameter is valid and returns an HTTP status code 400 if the __run_id__ parameter is invalid. Runs are automatically removed after 60 days. If you to want to reference them beyond 60 days, you must save old run results before they expire.  :param run_id: int   The canonical identifier for the run.  :returns: :class:`RunOutput`",job_run_output,get_output,select,
jobs.json,/api/2.2/jobs/runs/list,jobs_list_runs,get,ListRunsResponse,jobs,"active_only, completed_only, expand_tasks, job_id, limit, offset, page_token, run_type, start_time_from, start_time_to",List runs in descending order by start time.,"List runs in descending order by start time.  :param active_only: bool (optional)   If active_only is `true`, only active runs are included in the results; otherwise, lists both active   and completed runs. An active run is a run in the `QUEUED`, `PENDING`, `RUNNING`, or `TERMINATING`.   This field cannot be `true` when completed_only is `true`. :param completed_only: bool (optional)   If completed_only is `true`, only completed runs are included in the results; otherwise, lists both   active and completed runs. This field cannot be `true` when active_only is `true`. :param expand_tasks: bool (optional)   Whether to include task and cluster details in the response. Note that only the first 100 elements   will be shown. Use :method:jobs/getrun to paginate through all tasks and clusters. :param job_id: int (optional)   The job for which to list runs. If omitted, the Jobs service lists runs from all jobs. :param limit: int (optional)   The number of runs to return. This value must be greater than 0 and less than 25. The default value   is 20. If a request specifies a limit of 0, the service instead uses the maximum limit. :param offset: int (optional)   The offset of the first run to return, relative to the most recent run. Deprecated since June 2023.   Use `page_token` to iterate through the pages instead. :param page_token: str (optional)   Use `next_page_token` or `prev_page_token` returned from the previous request to list the next or   previous page of runs respectively. :param run_type: :class:`RunType` (optional)   The type of runs to return. For a description of run types, see :method:jobs/getRun. :param start_time_from: int (optional)   Show runs that started _at or after_ this value. The value must be a UTC timestamp in milliseconds.   Can be combined with _start_time_to_ to filter by a time range. :param start_time_to: int (optional)   Show runs that started _at or before_ this value. The value must be a UTC timestamp in milliseconds.   Can be combined with _start_time_from_ to filter by a time range.  :returns: Iterator over :class:`BaseRun`",job_runs,list,select,$.runs
jobs.json,/api/2.2/jobs/runs/repair,jobs_repair_run,post,Run,jobs,"run_id, dbt_commands, jar_params, job_parameters, latest_repair_id, notebook_params, performance_target, pipeline_params, python_named_params, python_params, rerun_all_failed_tasks, rerun_dependent_tasks, rerun_tasks, spark_submit_params, sql_params",Re-run one or more tasks. Tasks are re-run as part of the original job run. They use the current job,"Re-run one or more tasks. Tasks are re-run as part of the original job run. They use the current job and task settings, and can be viewed in the history for the original job run.  :param run_id: int   The job run ID of the run to repair. The run must not be in progress. :param dbt_commands: List[str] (optional)   An array of commands to execute for jobs with the dbt task, for example `""dbt_commands"": [""dbt   deps"", ""dbt seed"", ""dbt deps"", ""dbt seed"", ""dbt run""]`    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param jar_params: List[str] (optional)   A list of parameters for jobs with Spark JAR tasks, for example `""jar_params"": [""john doe"", ""35""]`.   The parameters are used to invoke the main function of the main class specified in the Spark JAR   task. If not specified upon `run-now`, it defaults to an empty list. jar_params cannot be specified   in conjunction with notebook_params. The JSON representation of this field (for example   `{""jar_params"":[""john doe"",""35""]}`) cannot exceed 10,000 bytes.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param job_parameters: Dict[str,str] (optional)   Job-level parameters used in the run. for example `""param"": ""overriding_val""` :param latest_repair_id: int (optional)   The ID of the latest repair. This parameter is not required when repairing a run for the first time,   but must be provided on subsequent requests to repair the same run. :param notebook_params: Dict[str,str] (optional)   A map from keys to values for jobs with notebook task, for example `""notebook_params"": {""name"":   ""john doe"", ""age"": ""35""}`. The map is passed to the notebook and is accessible through the   [dbutils.widgets.get] function.    If not specified upon `run-now`, the triggered run uses the job’s base parameters.    notebook_params cannot be specified in conjunction with jar_params.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    The JSON representation of this field (for example `{""notebook_params"":{""name"":""john   doe"",""age"":""35""}}`) cannot exceed 10,000 bytes.    [dbutils.widgets.get]: https://docs.databricks.com/dev-tools/databricks-utils.html   [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param performance_target: :class:`PerformanceTarget` (optional)   The performance mode on a serverless job. The performance target determines the level of compute   performance or cost-efficiency for the run. This field overrides the performance target defined on   the job level.    * `STANDARD`: Enables cost-efficient execution of serverless workloads. * `PERFORMANCE_OPTIMIZED`:   Prioritizes fast startup and execution times through rapid scaling and optimized cluster   performance. :param pipeline_params: :class:`PipelineParams` (optional)   Controls whether the pipeline should perform a full refresh :param python_named_params: Dict[str,str] (optional) :param python_params: List[str] (optional)   A list of parameters for jobs with Python tasks, for example `""python_params"": [""john doe"", ""35""]`.   The parameters are passed to Python file as command-line parameters. If specified upon `run-now`, it   would overwrite the parameters specified in job setting. The JSON representation of this field (for   example `{""python_params"":[""john doe"",""35""]}`) cannot exceed 10,000 bytes.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    Important    These parameters accept only Latin characters (ASCII character set). Using non-ASCII characters   returns an error. Examples of invalid, non-ASCII characters are Chinese, Japanese kanjis, and   emojis.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param rerun_all_failed_tasks: bool (optional)   If true, repair all failed tasks. Only one of `rerun_tasks` or `rerun_all_failed_tasks` can be used. :param rerun_dependent_tasks: bool (optional)   If true, repair all tasks that depend on the tasks in `rerun_tasks`, even if they were previously   successful. Can be also used in combination with `rerun_all_failed_tasks`. :param rerun_tasks: List[str] (optional)   The task keys of the task runs to repair. :param spark_submit_params: List[str] (optional)   A list of parameters for jobs with spark submit task, for example `""spark_submit_params"":   [""--class"", ""org.apache.spark.examples.SparkPi""]`. The parameters are passed to spark-submit script   as command-line parameters. If specified upon `run-now`, it would overwrite the parameters specified   in job setting. The JSON representation of this field (for example `{""python_params"":[""john   doe"",""35""]}`) cannot exceed 10,000 bytes.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    Important    These parameters accept only Latin characters (ASCII character set). Using non-ASCII characters   returns an error. Examples of invalid, non-ASCII characters are Chinese, Japanese kanjis, and   emojis.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param sql_params: Dict[str,str] (optional)   A map from keys to values for jobs with SQL task, for example `""sql_params"": {""name"": ""john doe"",   ""age"": ""35""}`. The SQL alert task does not support custom parameters.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown  :returns:   Long-running operation waiter for :class:`Run`.   See :method:wait_get_run_job_terminated_or_skipped for more details.",job_runs,repair,exec,
jobs.json,/api/2.2/jobs/runs/submit,jobs_submit,post,Run,jobs,"access_control_list, budget_policy_id, email_notifications, environments, git_source, health, idempotency_token, notification_settings, queue, run_as, run_name, tasks, timeout_seconds, usage_policy_id, webhook_notifications",Submit a one-time run. This endpoint allows you to submit a workload directly without creating a job.,"Submit a one-time run. This endpoint allows you to submit a workload directly without creating a job. Runs submitted using this endpoint don’t display in the UI. Use the `jobs/runs/get` API to check the run state after the job is submitted.  **Important:** Jobs submitted using this endpoint are not saved as a job. They do not show up in the Jobs UI, and do not retry when they fail. Because they are not saved, Databricks cannot auto-optimize serverless compute in case of failure. If your job fails, you may want to use classic compute to specify the compute needs for the job. Alternatively, use the `POST /jobs/create` and `POST /jobs/run-now` endpoints to create and run a saved job.  :param access_control_list: List[:class:`JobAccessControlRequest`] (optional)   List of permissions to set on the job. :param budget_policy_id: str (optional)   The user specified id of the budget policy to use for this one-time run. If not specified, the run   will be not be attributed to any budget policy. :param email_notifications: :class:`JobEmailNotifications` (optional)   An optional set of email addresses notified when the run begins or completes. :param environments: List[:class:`JobEnvironment`] (optional)   A list of task execution environment specifications that can be referenced by tasks of this run. :param git_source: :class:`GitSource` (optional)   An optional specification for a remote Git repository containing the source code used by tasks.   Version-controlled source code is supported by notebook, dbt, Python script, and SQL File tasks.    If `git_source` is set, these tasks retrieve the file from the remote repository by default.   However, this behavior can be overridden by setting `source` to `WORKSPACE` on the task.    Note: dbt and SQL File tasks support only version-controlled sources. If dbt or SQL File tasks are   used, `git_source` must be defined on the job. :param health: :class:`JobsHealthRules` (optional) :param idempotency_token: str (optional)   An optional token that can be used to guarantee the idempotency of job run requests. If a run with   the provided token already exists, the request does not create a new run but returns the ID of the   existing run instead. If a run with the provided token is deleted, an error is returned.    If you specify the idempotency token, upon failure you can retry until the request succeeds.   Databricks guarantees that exactly one run is launched with that idempotency token.    This token must have at most 64 characters.    For more information, see [How to ensure idempotency for jobs].    [How to ensure idempotency for jobs]: https://kb.databricks.com/jobs/jobs-idempotency.html :param notification_settings: :class:`JobNotificationSettings` (optional)   Optional notification settings that are used when sending notifications to each of the   `email_notifications` and `webhook_notifications` for this run. :param queue: :class:`QueueSettings` (optional)   The queue settings of the one-time run. :param run_as: :class:`JobRunAs` (optional)   Specifies the user or service principal that the job runs as. If not specified, the job runs as the   user who submits the request. :param run_name: str (optional)   An optional name for the run. The default value is `Untitled`. :param tasks: List[:class:`SubmitTask`] (optional) :param timeout_seconds: int (optional)   An optional timeout applied to each run of this job. A value of `0` means no timeout. :param usage_policy_id: str (optional)   The user specified id of the usage policy to use for this one-time run. If not specified, a default   usage policy may be applied when creating or modifying the job. :param webhook_notifications: :class:`WebhookNotifications` (optional)   A collection of system notification IDs to notify when the run begins or completes.  :returns:   Long-running operation waiter for :class:`Run`.   See :method:wait_get_run_job_terminated_or_skipped for more details.",job_runs,submit,insert,
jobs.json,/api/2.2/jobs/create,jobs_create,post,CreateResponse,jobs,"access_control_list, budget_policy_id, continuous, deployment, description, edit_mode, email_notifications, environments, format, git_source, health, job_clusters, max_concurrent_runs, name, notification_settings, parameters, performance_target, queue, run_as, schedule, tags, tasks, timeout_seconds, trigger, usage_policy_id, webhook_notifications",Create a new job.,"Create a new job.  :param access_control_list: List[:class:`JobAccessControlRequest`] (optional)   List of permissions to set on the job. :param budget_policy_id: str (optional)   The id of the user specified budget policy to use for this job. If not specified, a default budget   policy may be applied when creating or modifying the job. See `effective_budget_policy_id` for the   budget policy used by this workload. :param continuous: :class:`Continuous` (optional)   An optional continuous property for this job. The continuous property will ensure that there is   always one run executing. Only one of `schedule` and `continuous` can be used. :param deployment: :class:`JobDeployment` (optional)   Deployment information for jobs managed by external sources. :param description: str (optional)   An optional description for the job. The maximum length is 27700 characters in UTF-8 encoding. :param edit_mode: :class:`JobEditMode` (optional)   Edit mode of the job.    * `UI_LOCKED`: The job is in a locked UI state and cannot be modified. * `EDITABLE`: The job is in   an editable state and can be modified. :param email_notifications: :class:`JobEmailNotifications` (optional)   An optional set of email addresses that is notified when runs of this job begin or complete as well   as when this job is deleted. :param environments: List[:class:`JobEnvironment`] (optional)   A list of task execution environment specifications that can be referenced by serverless tasks of   this job. For serverless notebook tasks, if the environment_key is not specified, the notebook   environment will be used if present. If a jobs environment is specified, it will override the   notebook environment. For other serverless tasks, the task environment is required to be specified   using environment_key in the task settings. :param format: :class:`Format` (optional)   Used to tell what is the format of the job. This field is ignored in Create/Update/Reset calls. When   using the Jobs API 2.1 this value is always set to `""MULTI_TASK""`. :param git_source: :class:`GitSource` (optional)   An optional specification for a remote Git repository containing the source code used by tasks.   Version-controlled source code is supported by notebook, dbt, Python script, and SQL File tasks.    If `git_source` is set, these tasks retrieve the file from the remote repository by default.   However, this behavior can be overridden by setting `source` to `WORKSPACE` on the task.    Note: dbt and SQL File tasks support only version-controlled sources. If dbt or SQL File tasks are   used, `git_source` must be defined on the job. :param health: :class:`JobsHealthRules` (optional) :param job_clusters: List[:class:`JobCluster`] (optional)   A list of job cluster specifications that can be shared and reused by tasks of this job. Libraries   cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. :param max_concurrent_runs: int (optional)   An optional maximum allowed number of concurrent runs of the job. Set this value if you want to be   able to execute multiple runs of the same job concurrently. This is useful for example if you   trigger your job on a frequent schedule and want to allow consecutive runs to overlap with each   other, or if you want to trigger multiple runs which differ by their input parameters. This setting   affects only new runs. For example, suppose the job’s concurrency is 4 and there are 4 concurrent   active runs. Then setting the concurrency to 3 won’t kill any of the active runs. However, from   then on, new runs are skipped unless there are fewer than 3 active runs. This value cannot exceed   1000. Setting this value to `0` causes all new runs to be skipped. :param name: str (optional)   An optional name for the job. The maximum length is 4096 bytes in UTF-8 encoding. :param notification_settings: :class:`JobNotificationSettings` (optional)   Optional notification settings that are used when sending notifications to each of the   `email_notifications` and `webhook_notifications` for this job. :param parameters: List[:class:`JobParameterDefinition`] (optional)   Job-level parameter definitions :param performance_target: :class:`PerformanceTarget` (optional)   The performance mode on a serverless job. This field determines the level of compute performance or   cost-efficiency for the run. The performance target does not apply to tasks that run on Serverless   GPU compute.    * `STANDARD`: Enables cost-efficient execution of serverless workloads. * `PERFORMANCE_OPTIMIZED`:   Prioritizes fast startup and execution times through rapid scaling and optimized cluster   performance. :param queue: :class:`QueueSettings` (optional)   The queue settings of the job. :param run_as: :class:`JobRunAs` (optional)   The user or service principal that the job runs as, if specified in the request. This field   indicates the explicit configuration of `run_as` for the job. To find the value in all cases,   explicit or implicit, use `run_as_user_name`. :param schedule: :class:`CronSchedule` (optional)   An optional periodic schedule for this job. The default behavior is that the job only runs when   triggered by clicking “Run Now” in the Jobs UI or sending an API request to `runNow`. :param tags: Dict[str,str] (optional)   A map of tags associated with the job. These are forwarded to the cluster as cluster tags for jobs   clusters, and are subject to the same limitations as cluster tags. A maximum of 25 tags can be added   to the job. :param tasks: List[:class:`Task`] (optional)   A list of task specifications to be executed by this job. It supports up to 1000 elements in write   endpoints (:method:jobs/create, :method:jobs/reset, :method:jobs/update, :method:jobs/submit). Read   endpoints return only 100 tasks. If more than 100 tasks are available, you can paginate through them   using :method:jobs/get. Use the `next_page_token` field at the object root to determine if more   results are available. :param timeout_seconds: int (optional)   An optional timeout applied to each run of this job. A value of `0` means no timeout. :param trigger: :class:`TriggerSettings` (optional)   A configuration to trigger a run when certain conditions are met. The default behavior is that the   job runs only when triggered by clicking “Run Now” in the Jobs UI or sending an API request to   `runNow`. :param usage_policy_id: str (optional)   The id of the user specified usage policy to use for this job. If not specified, a default usage   policy may be applied when creating or modifying the job. See `effective_usage_policy_id` for the   usage policy used by this workload. :param webhook_notifications: :class:`WebhookNotifications` (optional)   A collection of system notification IDs to notify when runs of this job begin or complete.  :returns: :class:`CreateResponse`",jobs,create,insert,
jobs.json,/api/2.2/jobs/delete,jobs_delete,post,,jobs,job_id,Deletes a job.,Deletes a job.  :param job_id: int   The canonical identifier of the job to delete. This field is required.,jobs,delete,delete,
jobs.json,/api/2.2/jobs/get,jobs_get,get,Job,jobs,"job_id, page_token",Retrieves the details for a single job.,"Retrieves the details for a single job.  Large arrays in the results will be paginated when they exceed 100 elements. A request for a single job will return all properties for that job, and the first 100 elements of array properties (`tasks`, `job_clusters`, `environments` and `parameters`). Use the `next_page_token` field to check for more results and pass its value as the `page_token` in subsequent requests. If any array properties have more than 100 elements, additional results will be returned on subsequent requests. Arrays without additional results will be empty on later pages.  :param job_id: int   The canonical identifier of the job to retrieve information about. This field is required. :param page_token: str (optional)   Use `next_page_token` returned from the previous GetJob response to request the next page of the   job's array properties.  :returns: :class:`Job`",jobs,get,select,
jobs.json,/api/2.2/jobs/list,jobs_list,get,ListJobsResponse,jobs,"expand_tasks, limit, name, offset, page_token",Retrieves a list of jobs.,"Retrieves a list of jobs.  :param expand_tasks: bool (optional)   Whether to include task and cluster details in the response. Note that only the first 100 elements   will be shown. Use :method:jobs/get to paginate through all tasks and clusters. :param limit: int (optional)   The number of jobs to return. This value must be greater than 0 and less or equal to 100. The   default value is 20. :param name: str (optional)   A filter on the list based on the exact (case insensitive) job name. :param offset: int (optional)   The offset of the first job to return, relative to the most recently created job. Deprecated since   June 2023. Use `page_token` to iterate through the pages instead. :param page_token: str (optional)   Use `next_page_token` or `prev_page_token` returned from the previous request to list the next or   previous page of jobs respectively.  :returns: Iterator over :class:`BaseJob`",jobs,list,select,$.jobs
jobs.json,/api/2.2/jobs/reset,jobs_reset,post,,jobs,"job_id, new_settings",Overwrite all settings for the given job. Use the [_Update_ endpoint](:method:jobs/update) to update,Overwrite all settings for the given job. Use the [_Update_ endpoint](:method:jobs/update) to update job settings partially.  :param job_id: int   The canonical identifier of the job to reset. This field is required. :param new_settings: :class:`JobSettings`   The new settings of the job. These settings completely replace the old settings.    Changes to the field `JobBaseSettings.timeout_seconds` are applied to active runs. Changes to other   fields are applied to future runs only.,jobs,reset,replace,
jobs.json,/api/2.2/jobs/run-now,jobs_run_now,post,Run,jobs,"job_id, dbt_commands, idempotency_token, jar_params, job_parameters, notebook_params, only, performance_target, pipeline_params, python_named_params, python_params, queue, spark_submit_params, sql_params",Run a job and return the `run_id` of the triggered run.,"Run a job and return the `run_id` of the triggered run.  :param job_id: int   The ID of the job to be executed :param dbt_commands: List[str] (optional)   An array of commands to execute for jobs with the dbt task, for example `""dbt_commands"": [""dbt   deps"", ""dbt seed"", ""dbt deps"", ""dbt seed"", ""dbt run""]`    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param idempotency_token: str (optional)   An optional token to guarantee the idempotency of job run requests. If a run with the provided token   already exists, the request does not create a new run but returns the ID of the existing run   instead. If a run with the provided token is deleted, an error is returned.    If you specify the idempotency token, upon failure you can retry until the request succeeds.   Databricks guarantees that exactly one run is launched with that idempotency token.    This token must have at most 64 characters.    For more information, see [How to ensure idempotency for jobs].    [How to ensure idempotency for jobs]: https://kb.databricks.com/jobs/jobs-idempotency.html :param jar_params: List[str] (optional)   A list of parameters for jobs with Spark JAR tasks, for example `""jar_params"": [""john doe"", ""35""]`.   The parameters are used to invoke the main function of the main class specified in the Spark JAR   task. If not specified upon `run-now`, it defaults to an empty list. jar_params cannot be specified   in conjunction with notebook_params. The JSON representation of this field (for example   `{""jar_params"":[""john doe"",""35""]}`) cannot exceed 10,000 bytes.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param job_parameters: Dict[str,str] (optional)   Job-level parameters used in the run. for example `""param"": ""overriding_val""` :param notebook_params: Dict[str,str] (optional)   A map from keys to values for jobs with notebook task, for example `""notebook_params"": {""name"":   ""john doe"", ""age"": ""35""}`. The map is passed to the notebook and is accessible through the   [dbutils.widgets.get] function.    If not specified upon `run-now`, the triggered run uses the job’s base parameters.    notebook_params cannot be specified in conjunction with jar_params.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    The JSON representation of this field (for example `{""notebook_params"":{""name"":""john   doe"",""age"":""35""}}`) cannot exceed 10,000 bytes.    [dbutils.widgets.get]: https://docs.databricks.com/dev-tools/databricks-utils.html   [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param only: List[str] (optional)   A list of task keys to run inside of the job. If this field is not provided, all tasks in the job   will be run. :param performance_target: :class:`PerformanceTarget` (optional)   The performance mode on a serverless job. The performance target determines the level of compute   performance or cost-efficiency for the run. This field overrides the performance target defined on   the job level.    * `STANDARD`: Enables cost-efficient execution of serverless workloads. * `PERFORMANCE_OPTIMIZED`:   Prioritizes fast startup and execution times through rapid scaling and optimized cluster   performance. :param pipeline_params: :class:`PipelineParams` (optional)   Controls whether the pipeline should perform a full refresh :param python_named_params: Dict[str,str] (optional) :param python_params: List[str] (optional)   A list of parameters for jobs with Python tasks, for example `""python_params"": [""john doe"", ""35""]`.   The parameters are passed to Python file as command-line parameters. If specified upon `run-now`, it   would overwrite the parameters specified in job setting. The JSON representation of this field (for   example `{""python_params"":[""john doe"",""35""]}`) cannot exceed 10,000 bytes.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    Important    These parameters accept only Latin characters (ASCII character set). Using non-ASCII characters   returns an error. Examples of invalid, non-ASCII characters are Chinese, Japanese kanjis, and   emojis.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param queue: :class:`QueueSettings` (optional)   The queue settings of the run. :param spark_submit_params: List[str] (optional)   A list of parameters for jobs with spark submit task, for example `""spark_submit_params"":   [""--class"", ""org.apache.spark.examples.SparkPi""]`. The parameters are passed to spark-submit script   as command-line parameters. If specified upon `run-now`, it would overwrite the parameters specified   in job setting. The JSON representation of this field (for example `{""python_params"":[""john   doe"",""35""]}`) cannot exceed 10,000 bytes.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    Important    These parameters accept only Latin characters (ASCII character set). Using non-ASCII characters   returns an error. Examples of invalid, non-ASCII characters are Chinese, Japanese kanjis, and   emojis.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown :param sql_params: Dict[str,str] (optional)   A map from keys to values for jobs with SQL task, for example `""sql_params"": {""name"": ""john doe"",   ""age"": ""35""}`. The SQL alert task does not support custom parameters.    ⚠ **Deprecation note** Use [job parameters] to pass information down to tasks.    [job parameters]: https://docs.databricks.com/jobs/job-parameters.html#job-parameter-pushdown  :returns:   Long-running operation waiter for :class:`Run`.   See :method:wait_get_run_job_terminated_or_skipped for more details.",jobs,run_now,exec,
jobs.json,/api/2.2/jobs/update,jobs_update,post,,jobs,"job_id, fields_to_remove, new_settings","Add, update, or remove specific settings of an existing job. Use the [_Reset_","Add, update, or remove specific settings of an existing job. Use the [_Reset_ endpoint](:method:jobs/reset) to overwrite all job settings.  :param job_id: int   The canonical identifier of the job to update. This field is required. :param fields_to_remove: List[str] (optional)   Remove top-level fields in the job settings. Removing nested fields is not supported, except for   tasks and job clusters (`tasks/task_1`). This field is optional. :param new_settings: :class:`JobSettings` (optional)   The new settings for the job.    Top-level fields specified in `new_settings` are completely replaced, except for arrays which are   merged. That is, new and existing entries are completely replaced based on the respective key   fields, i.e. `task_key` or `job_cluster_key`, while previous entries are kept.    Partially updating nested fields is not supported.    Changes to the field `JobSettings.timeout_seconds` are applied to active runs. Changes to other   fields are applied to future runs only.",jobs,update,update,
jobs.json,/api/2.0/policies/jobs/enforce-compliance,policy_compliance_for_jobs_enforce_compliance,post,EnforcePolicyComplianceResponse,"jobs, policy_compliance_for_jobs","job_id, validate_only",Updates a job so the job clusters that are created when running the job (specified in `new_cluster`),"Updates a job so the job clusters that are created when running the job (specified in `new_cluster`) are compliant with the current versions of their respective cluster policies. All-purpose clusters used in the job will not be updated.  :param job_id: int   The ID of the job you want to enforce policy compliance on. :param validate_only: bool (optional)   If set, previews changes made to the job to comply with its policy, but does not update the job.  :returns: :class:`EnforcePolicyComplianceResponse`",policy_compliance_for_jobs,enforce,insert,
jobs.json,/api/2.0/policies/jobs/get-compliance,policy_compliance_for_jobs_get_compliance,get,GetPolicyComplianceResponse,"jobs, policy_compliance_for_jobs",job_id,Returns the policy compliance status of a job. Jobs could be out of compliance if a cluster policy,Returns the policy compliance status of a job. Jobs could be out of compliance if a cluster policy they use was updated after the job was last edited and some of its job clusters no longer comply with their updated policies.  :param job_id: int   The ID of the job whose compliance status you are requesting.  :returns: :class:`GetPolicyComplianceResponse`,policy_compliance_for_jobs,get,select,
jobs.json,/api/2.0/policies/jobs/list-compliance,policy_compliance_for_jobs_list_compliance,get,ListJobComplianceForPolicyResponse,"jobs, policy_compliance_for_jobs","policy_id, page_size, page_token",Returns the policy compliance status of all jobs that use a given policy. Jobs could be out of,Returns the policy compliance status of all jobs that use a given policy. Jobs could be out of compliance if a cluster policy they use was updated after the job was last edited and its job clusters no longer comply with the updated policy.  :param policy_id: str   Canonical unique identifier for the cluster policy. :param page_size: int (optional)   Use this field to specify the maximum number of results to be returned by the server. The server may   further constrain the maximum number of results returned in a single page. :param page_token: str (optional)   A page token that can be used to navigate to the next page or previous page as returned by   `next_page_token` or `prev_page_token`.  :returns: Iterator over :class:`JobCompliance`,policy_compliance_for_jobs,list,select,$.jobs
marketplace.json,/api/2.1/marketplace-consumer/listings/{listing_id}/content,consumer_fulfillments_get,get,GetListingContentMetadataResponse,"marketplace, consumer_fulfillments","listing_id, page_size, page_token",Get a high level preview of the metadata of listing installable content.,Get a high level preview of the metadata of listing installable content.  :param listing_id: str :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`SharedDataObject`,consumer_listing_content,get,select,$.shared_data_objects
marketplace.json,/api/2.1/marketplace-consumer/listings/{listing_id}/fulfillments,consumer_fulfillments_list,get,ListFulfillmentsResponse,"marketplace, consumer_fulfillments","listing_id, page_size, page_token",Get all listings fulfillments associated with a listing. A _fulfillment_ is a potential installation.,"Get all listings fulfillments associated with a listing. A _fulfillment_ is a potential installation. Standard installations contain metadata about the attached share or git repo. Only one of these fields will be present. Personalized installations contain metadata about the attached share or git repo, as well as the Delta Sharing recipient type.  :param listing_id: str :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ListingFulfillment`",consumer_fulfillments,list,select,$.fulfillments
marketplace.json,/api/2.1/marketplace-consumer/listings/{listing_id}/installations,consumer_installations_create,post,Installation,"marketplace, consumer_installations","listing_id, accepted_consumer_terms, catalog_name, recipient_type, repo_detail, share_name",Install payload associated with a Databricks Marketplace listing.,Install payload associated with a Databricks Marketplace listing.  :param listing_id: str :param accepted_consumer_terms: :class:`ConsumerTerms` (optional) :param catalog_name: str (optional) :param recipient_type: :class:`DeltaSharingRecipientType` (optional) :param repo_detail: :class:`RepoInstallation` (optional)   for git repo installations :param share_name: str (optional)  :returns: :class:`Installation`,consumer_installations,create,insert,
marketplace.json,/api/2.1/marketplace-consumer/listings/{listing_id}/installations,consumer_installations_list_listing_installations,get,ListAllInstallationsResponse,"marketplace, consumer_installations","listing_id, page_size, page_token",List all installations for a particular listing.,List all installations for a particular listing.  :param listing_id: str :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`InstallationDetail`,consumer_installations,list_for_listing,select,$.installations
marketplace.json,/api/2.1/marketplace-consumer/listings/{listing_id}/installations/{installation_id},consumer_installations_delete,delete,,"marketplace, consumer_installations","listing_id, installation_id",Uninstall an installation associated with a Databricks Marketplace listing.,Uninstall an installation associated with a Databricks Marketplace listing.  :param listing_id: str :param installation_id: str,consumer_installations,delete,delete,
marketplace.json,/api/2.1/marketplace-consumer/listings/{listing_id}/installations/{installation_id},consumer_installations_update,put,UpdateInstallationResponse,"marketplace, consumer_installations","listing_id, installation_id, installation, rotate_token",This is a update API that will update the part of the fields defined in the installation table as well,This is a update API that will update the part of the fields defined in the installation table as well as interact with external services according to the fields not included in the installation table 1. the token will be rotate if the rotateToken flag is true 2. the token will be forcibly rotate if the rotateToken flag is true and the tokenInfo field is empty  :param listing_id: str :param installation_id: str :param installation: :class:`InstallationDetail` :param rotate_token: bool (optional)  :returns: :class:`UpdateInstallationResponse`,consumer_installations,update,replace,
marketplace.json,/api/2.1/marketplace-consumer/installations,consumer_installations_list,get,ListAllInstallationsResponse,"marketplace, consumer_installations","page_size, page_token",List all installations across all listings.,List all installations across all listings.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`InstallationDetail`,consumer_installations,list,select,$.installations
marketplace.json,/api/2.1/marketplace-consumer/listings:batchGet,consumer_listings_batch_get,get,BatchGetListingsResponse,"marketplace, consumer_listings",ids,Batch get a published listing in the Databricks Marketplace that the consumer has access to.,Batch get a published listing in the Databricks Marketplace that the consumer has access to.  :param ids: List[str] (optional)  :returns: :class:`BatchGetListingsResponse`,consumer_listings,batch_get,exec,
marketplace.json,/api/2.1/marketplace-consumer/listings/{id},consumer_listings_get,get,GetListingResponse,"marketplace, consumer_listings",id,Get a published listing in the Databricks Marketplace that the consumer has access to.,Get a published listing in the Databricks Marketplace that the consumer has access to.  :param id: str  :returns: :class:`GetListingResponse`,consumer_listings,get,select,
marketplace.json,/api/2.1/marketplace-consumer/listings,consumer_listings_list,get,BatchGetListingsResponse,"marketplace, consumer_listings","assets, categories, is_free, is_private_exchange, is_staff_pick, page_size, page_token, provider_ids, tags",List all published listings in the Databricks Marketplace that the consumer has access to.,List all published listings in the Databricks Marketplace that the consumer has access to.  :param assets: List[:class:`AssetType`] (optional)   Matches any of the following asset types :param categories: List[:class:`Category`] (optional)   Matches any of the following categories :param is_free: bool (optional)   Filters each listing based on if it is free. :param is_private_exchange: bool (optional)   Filters each listing based on if it is a private exchange. :param is_staff_pick: bool (optional)   Filters each listing based on whether it is a staff pick. :param page_size: int (optional) :param page_token: str (optional) :param provider_ids: List[str] (optional)   Matches any of the following provider ids :param tags: List[:class:`ListingTag`] (optional)   Matches any of the following tags  :returns: Iterator over :class:`Listing`,consumer_listings,list,select,$.listings
marketplace.json,/api/2.1/marketplace-consumer/search-listings,consumer_listings_search,get,BatchGetListingsResponse,"marketplace, consumer_listings","query, assets, categories, is_free, is_private_exchange, page_size, page_token, provider_ids",Search published listings in the Databricks Marketplace that the consumer has access to. This query,Search published listings in the Databricks Marketplace that the consumer has access to. This query supports a variety of different search parameters and performs fuzzy matching.  :param query: str   Fuzzy matches query :param assets: List[:class:`AssetType`] (optional)   Matches any of the following asset types :param categories: List[:class:`Category`] (optional)   Matches any of the following categories :param is_free: bool (optional) :param is_private_exchange: bool (optional) :param page_size: int (optional) :param page_token: str (optional) :param provider_ids: List[str] (optional)   Matches any of the following provider ids  :returns: Iterator over :class:`Listing`,consumer_listings,search,exec,$.listings
marketplace.json,/api/2.1/marketplace-consumer/listings/{listing_id}/personalization-requests,consumer_personalization_requests_create,post,CreatePersonalizationRequestResponse,"marketplace, consumer_personalization_requests","listing_id, intended_use, accepted_consumer_terms, comment, company, first_name, is_from_lighthouse, last_name, recipient_type",Create a personalization request for a listing.,Create a personalization request for a listing.  :param listing_id: str :param intended_use: str :param accepted_consumer_terms: :class:`ConsumerTerms` :param comment: str (optional) :param company: str (optional) :param first_name: str (optional) :param is_from_lighthouse: bool (optional) :param last_name: str (optional) :param recipient_type: :class:`DeltaSharingRecipientType` (optional)  :returns: :class:`CreatePersonalizationRequestResponse`,consumer_personalization_requests,create,insert,
marketplace.json,/api/2.1/marketplace-consumer/listings/{listing_id}/personalization-requests,consumer_personalization_requests_get,get,GetPersonalizationRequestResponse,"marketplace, consumer_personalization_requests",listing_id,Get the personalization request for a listing. Each consumer can make at *most* one personalization,Get the personalization request for a listing. Each consumer can make at *most* one personalization request for a listing.  :param listing_id: str  :returns: :class:`GetPersonalizationRequestResponse`,consumer_personalization_requests,get,select,
marketplace.json,/api/2.1/marketplace-consumer/personalization-requests,consumer_personalization_requests_list,get,GetPersonalizationRequestResponse,"marketplace, consumer_personalization_requests","page_size, page_token",List personalization requests for a consumer across all listings.,List personalization requests for a consumer across all listings.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`PersonalizationRequest`,consumer_personalization_requests,list,select,$.personalization_requests
marketplace.json,/api/2.1/marketplace-consumer/providers:batchGet,consumer_providers_batch_get,get,BatchGetProvidersResponse,"marketplace, consumer_providers",ids,Batch get a provider in the Databricks Marketplace with at least one visible listing.,Batch get a provider in the Databricks Marketplace with at least one visible listing.  :param ids: List[str] (optional)  :returns: :class:`BatchGetProvidersResponse`,consumer_providers,batch_get,exec,
marketplace.json,/api/2.1/marketplace-consumer/providers/{id},consumer_providers_get,get,GetProviderResponse,"marketplace, consumer_providers",id,Get a provider in the Databricks Marketplace with at least one visible listing.,Get a provider in the Databricks Marketplace with at least one visible listing.  :param id: str  :returns: :class:`GetProviderResponse`,consumer_providers,get,select,
marketplace.json,/api/2.1/marketplace-consumer/providers,consumer_providers_list,get,BatchGetProvidersResponse,"marketplace, consumer_providers","is_featured, page_size, page_token",List all providers in the Databricks Marketplace with at least one visible listing.,List all providers in the Databricks Marketplace with at least one visible listing.  :param is_featured: bool (optional) :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ProviderInfo`,consumer_providers,list,select,$.providers
marketplace.json,/api/2.0/marketplace-exchange/filters,provider_exchange_filters_create,post,CreateExchangeFilterResponse,"marketplace, provider_exchange_filters",filter,Add an exchange filter.,Add an exchange filter.  :param filter: :class:`ExchangeFilter`  :returns: :class:`CreateExchangeFilterResponse`,provider_exchange_filters,create,insert,
marketplace.json,/api/2.0/marketplace-exchange/filters,provider_exchange_filters_list,get,ListExchangeFiltersResponse,"marketplace, provider_exchange_filters","exchange_id, page_size, page_token",List exchange filter,List exchange filter  :param exchange_id: str :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ExchangeFilter`,provider_exchange_filters,list,select,$.filters
marketplace.json,/api/2.0/marketplace-exchange/filters/{id},provider_exchange_filters_delete,delete,,"marketplace, provider_exchange_filters",id,Delete an exchange filter,Delete an exchange filter  :param id: str,provider_exchange_filters,delete,delete,
marketplace.json,/api/2.0/marketplace-exchange/filters/{id},provider_exchange_filters_update,put,UpdateExchangeFilterResponse,"marketplace, provider_exchange_filters","id, filter",Update an exchange filter.,Update an exchange filter.  :param id: str :param filter: :class:`ExchangeFilter`  :returns: :class:`UpdateExchangeFilterResponse`,provider_exchange_filters,update,replace,
marketplace.json,/api/2.0/marketplace-exchange/exchanges-for-listing,provider_exchanges_add_listing_to_exchange,post,AddExchangeForListingResponse,"marketplace, provider_exchanges","listing_id, exchange_id",Associate an exchange with a listing,Associate an exchange with a listing  :param listing_id: str :param exchange_id: str  :returns: :class:`AddExchangeForListingResponse`,provider_exchange_listings,add,insert,
marketplace.json,/api/2.0/marketplace-exchange/exchanges-for-listing,provider_exchanges_list_exchanges_for_listing,get,ListExchangesForListingResponse,"marketplace, provider_exchanges","listing_id, page_size, page_token",List exchanges associated with a listing,List exchanges associated with a listing  :param listing_id: str :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ExchangeListing`,provider_exchange_listings,list_for_listing,select,$.exchange_listing
marketplace.json,/api/2.0/marketplace-exchange/exchanges,provider_exchanges_create,post,CreateExchangeResponse,"marketplace, provider_exchanges",exchange,Create an exchange,Create an exchange  :param exchange: :class:`Exchange`  :returns: :class:`CreateExchangeResponse`,provider_exchanges,create,insert,
marketplace.json,/api/2.0/marketplace-exchange/exchanges,provider_exchanges_list,get,ListExchangesResponse,"marketplace, provider_exchanges","page_size, page_token",List exchanges visible to provider,List exchanges visible to provider  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`Exchange`,provider_exchanges,list,select,$.exchanges
marketplace.json,/api/2.0/marketplace-exchange/exchanges/{id},provider_exchanges_delete,delete,,"marketplace, provider_exchanges",id,This removes a listing from marketplace.,This removes a listing from marketplace.  :param id: str,provider_exchanges,delete,delete,
marketplace.json,/api/2.0/marketplace-exchange/exchanges/{id},provider_exchanges_get,get,GetExchangeResponse,"marketplace, provider_exchanges",id,Get an exchange.,Get an exchange.  :param id: str  :returns: :class:`GetExchangeResponse`,provider_exchanges,get,select,
marketplace.json,/api/2.0/marketplace-exchange/exchanges/{id},provider_exchanges_update,put,UpdateExchangeResponse,"marketplace, provider_exchanges","id, exchange",Update an exchange,Update an exchange  :param id: str :param exchange: :class:`Exchange`  :returns: :class:`UpdateExchangeResponse`,provider_exchanges,update,replace,
marketplace.json,/api/2.0/marketplace-exchange/exchanges-for-listing/{id},provider_exchanges_delete_listing_from_exchange,delete,,"marketplace, provider_exchanges",id,Disassociate an exchange with a listing,Disassociate an exchange with a listing  :param id: str,provider_exchange_listings,delete,delete,
marketplace.json,/api/2.0/marketplace-exchange/listings-for-exchange,provider_exchanges_list_listings_for_exchange,get,ListExchangesForListingResponse,"marketplace, provider_exchanges","exchange_id, page_size, page_token",List listings associated with an exchange,List listings associated with an exchange  :param exchange_id: str :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ExchangeListing`,provider_exchange_listings,list_for_exchange,select,$.exchange_listings
marketplace.json,/api/2.0/marketplace-provider/files,provider_files_create,post,CreateFileResponse,"marketplace, provider_files","file_parent, marketplace_file_type, mime_type, display_name","Create a file. Currently, only provider icons and attached notebooks are supported.","Create a file. Currently, only provider icons and attached notebooks are supported.  :param file_parent: :class:`FileParent` :param marketplace_file_type: :class:`MarketplaceFileType` :param mime_type: str :param display_name: str (optional)  :returns: :class:`CreateFileResponse`",provider_files,create,insert,
marketplace.json,/api/2.0/marketplace-provider/files,provider_files_list,get,ListFilesResponse,"marketplace, provider_files","file_parent, page_size, page_token",List files attached to a parent entity.,List files attached to a parent entity.  :param file_parent: :class:`FileParent` :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`FileInfo`,provider_files,list,select,$.file_infos
marketplace.json,/api/2.0/marketplace-provider/files/{file_id},provider_files_delete,delete,,"marketplace, provider_files",file_id,Delete a file,Delete a file  :param file_id: str,provider_files,delete,delete,
marketplace.json,/api/2.0/marketplace-provider/files/{file_id},provider_files_get,get,GetFileResponse,"marketplace, provider_files",file_id,Get a file,Get a file  :param file_id: str  :returns: :class:`GetFileResponse`,provider_files,get,select,
marketplace.json,/api/2.0/marketplace-provider/listing,provider_listings_create,post,CreateListingResponse,"marketplace, provider_listings",listing,Create a new listing,Create a new listing  :param listing: :class:`Listing`  :returns: :class:`CreateListingResponse`,provider_listings,create,insert,
marketplace.json,/api/2.0/marketplace-provider/listings/{id},provider_listings_delete,delete,,"marketplace, provider_listings",id,Delete a listing,Delete a listing  :param id: str,provider_listings,delete,delete,
marketplace.json,/api/2.0/marketplace-provider/listings/{id},provider_listings_get,get,GetListingResponse,"marketplace, provider_listings",id,Get a listing,Get a listing  :param id: str  :returns: :class:`GetListingResponse`,provider_listings,get,select,
marketplace.json,/api/2.0/marketplace-provider/listings/{id},provider_listings_update,put,UpdateListingResponse,"marketplace, provider_listings","id, listing",Update a listing,Update a listing  :param id: str :param listing: :class:`Listing`  :returns: :class:`UpdateListingResponse`,provider_listings,update,replace,
marketplace.json,/api/2.0/marketplace-provider/listings,provider_listings_list,get,BatchGetListingsResponse,"marketplace, provider_listings","page_size, page_token",List listings owned by this provider,List listings owned by this provider  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`Listing`,provider_listings,list,select,$.listings
marketplace.json,/api/2.0/marketplace-provider/personalization-requests,provider_personalization_requests_list,get,GetPersonalizationRequestResponse,"marketplace, provider_personalization_requests","page_size, page_token","List personalization requests to this provider. This will return all personalization requests,","List personalization requests to this provider. This will return all personalization requests, regardless of which listing they are for.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`PersonalizationRequest`",provider_personalization_requests,list,select,$.personalization_requests
marketplace.json,/api/2.0/marketplace-provider/listings/{listing_id}/personalization-requests/{request_id}/request-status,provider_personalization_requests_update,put,UpdatePersonalizationRequestResponse,"marketplace, provider_personalization_requests","listing_id, request_id, status, reason, share",Update personalization request. This method only permits updating the status of the request.,Update personalization request. This method only permits updating the status of the request.  :param listing_id: str :param request_id: str :param status: :class:`PersonalizationRequestStatus` :param reason: str (optional) :param share: :class:`ShareInfo` (optional)  :returns: :class:`UpdatePersonalizationRequestResponse`,provider_personalization_requests,update,replace,
marketplace.json,/api/2.0/marketplace-provider/analytics_dashboard,provider_provider_analytics_dashboards_create,post,ProviderAnalyticsDashboard,"marketplace, provider_provider_analytics_dashboards",,Create provider analytics dashboard. Returns Marketplace specific `id`. Not to be confused with the,Create provider analytics dashboard. Returns Marketplace specific `id`. Not to be confused with the Lakeview dashboard id.   :returns: :class:`ProviderAnalyticsDashboard`,provider_provider_analytics_dashboards,create,insert,
marketplace.json,/api/2.0/marketplace-provider/analytics_dashboard,provider_provider_analytics_dashboards_get,get,ListProviderAnalyticsDashboardResponse,"marketplace, provider_provider_analytics_dashboards",,Get provider analytics dashboard.,Get provider analytics dashboard.   :returns: :class:`ListProviderAnalyticsDashboardResponse`,provider_provider_analytics_dashboards,get,select,
marketplace.json,/api/2.0/marketplace-provider/analytics_dashboard/latest,provider_provider_analytics_dashboards_get_latest_version,get,GetLatestVersionProviderAnalyticsDashboardResponse,"marketplace, provider_provider_analytics_dashboards",,Get latest version of provider analytics dashboard.,Get latest version of provider analytics dashboard.   :returns: :class:`GetLatestVersionProviderAnalyticsDashboardResponse`,provider_provider_analytics_dashboards,get_latest_version,exec,
marketplace.json,/api/2.0/marketplace-provider/analytics_dashboard/{id},provider_provider_analytics_dashboards_update,put,UpdateProviderAnalyticsDashboardResponse,"marketplace, provider_provider_analytics_dashboards","id, version",Update provider analytics dashboard.,Update provider analytics dashboard.  :param id: str   id is immutable property and can't be updated. :param version: int (optional)   this is the version of the dashboard template we want to update our user to current expectation is   that it should be equal to latest version of the dashboard template  :returns: :class:`UpdateProviderAnalyticsDashboardResponse`,provider_provider_analytics_dashboards,update,replace,
marketplace.json,/api/2.0/marketplace-provider/provider,provider_providers_create,post,CreateProviderResponse,"marketplace, provider_providers",provider,Create a provider,Create a provider  :param provider: :class:`ProviderInfo`  :returns: :class:`CreateProviderResponse`,provider_providers,create,insert,
marketplace.json,/api/2.0/marketplace-provider/providers/{id},provider_providers_delete,delete,,"marketplace, provider_providers",id,Delete provider,Delete provider  :param id: str,provider_providers,delete,delete,
marketplace.json,/api/2.0/marketplace-provider/providers/{id},provider_providers_get,get,GetProviderResponse,"marketplace, provider_providers",id,Get provider profile,Get provider profile  :param id: str  :returns: :class:`GetProviderResponse`,provider_providers,get,select,
marketplace.json,/api/2.0/marketplace-provider/providers/{id},provider_providers_update,put,UpdateProviderResponse,"marketplace, provider_providers","id, provider",Update provider profile,Update provider profile  :param id: str :param provider: :class:`ProviderInfo`  :returns: :class:`UpdateProviderResponse`,provider_providers,update,replace,
marketplace.json,/api/2.0/marketplace-provider/providers,provider_providers_list,get,BatchGetProvidersResponse,"marketplace, provider_providers","page_size, page_token",List provider profiles for account.,List provider profiles for account.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ProviderInfo`,provider_providers,list,select,$.providers
ml.json,/api/2.0/permissions/experiments/{experiment_id}/permissionLevels,experiments_get_permission_levels,get,GetExperimentPermissionLevelsResponse,"ml, experiments",experiment_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param experiment_id: str   The experiment for which to get or manage permissions.  :returns: :class:`GetExperimentPermissionLevelsResponse`,experiment_permission_levels,get,select,
ml.json,/api/2.0/permissions/experiments/{experiment_id},experiments_get_permissions,get,ExperimentPermissions,"ml, experiments",experiment_id,Gets the permissions of an experiment. Experiments can inherit permissions from their root object.,Gets the permissions of an experiment. Experiments can inherit permissions from their root object.  :param experiment_id: str   The experiment for which to get or manage permissions.  :returns: :class:`ExperimentPermissions`,experiment_permissions,get,select,
ml.json,/api/2.0/permissions/experiments/{experiment_id},experiments_set_permissions,put,ExperimentPermissions,"ml, experiments","experiment_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param experiment_id: str   The experiment for which to get or manage permissions. :param access_control_list: List[:class:`ExperimentAccessControlRequest`] (optional)  :returns: :class:`ExperimentPermissions`",experiment_permissions,set,replace,
ml.json,/api/2.0/permissions/experiments/{experiment_id},experiments_update_permissions,patch,ExperimentPermissions,"ml, experiments","experiment_id, access_control_list",Updates the permissions on an experiment. Experiments can inherit permissions from their root object.,Updates the permissions on an experiment. Experiments can inherit permissions from their root object.  :param experiment_id: str   The experiment for which to get or manage permissions. :param access_control_list: List[:class:`ExperimentAccessControlRequest`] (optional)  :returns: :class:`ExperimentPermissions`,experiment_permissions,update,update,
ml.json,/api/2.0/mlflow/artifacts/list,experiments_list_artifacts,get,ListArtifactsResponse,"ml, experiments","page_token, path, run_id, run_uuid","List artifacts for a run. Takes an optional `artifact_path` prefix which if specified, the response","List artifacts for a run. Takes an optional `artifact_path` prefix which if specified, the response contains only artifacts with the specified prefix. A maximum of 1000 artifacts will be retrieved for UC Volumes. Please call `/api/2.0/fs/directories{directory_path}` for listing artifacts in UC Volumes, which supports pagination. See [List directory contents | Files API](/api/workspace/files/listdirectorycontents).  :param page_token: str (optional)   The token indicating the page of artifact results to fetch. `page_token` is not supported when   listing artifacts in UC Volumes. A maximum of 1000 artifacts will be retrieved for UC Volumes.   Please call `/api/2.0/fs/directories{directory_path}` for listing artifacts in UC Volumes, which   supports pagination. See [List directory contents | Files   API](/api/workspace/files/listdirectorycontents). :param path: str (optional)   Filter artifacts matching this path (a relative path from the root artifact directory). :param run_id: str (optional)   ID of the run whose artifacts to list. Must be provided. :param run_uuid: str (optional)   [Deprecated, use `run_id` instead] ID of the run whose artifacts to list. This field will be removed   in a future MLflow version.  :returns: Iterator over :class:`FileInfo`",experiment_run_artifacts,list,select,$.files
ml.json,/api/2.0/mlflow/metrics/get-history,experiments_get_history,get,GetMetricHistoryResponse,"ml, experiments","metric_key, max_results, page_token, run_id, run_uuid",Gets a list of all values for the specified metric for a given run.,"Gets a list of all values for the specified metric for a given run.  :param metric_key: str   Name of the metric. :param max_results: int (optional)   Maximum number of Metric records to return per paginated request. Default is set to 25,000. If set   higher than 25,000, a request Exception will be raised. :param page_token: str (optional)   Token indicating the page of metric histories to fetch. :param run_id: str (optional)   ID of the run from which to fetch metric values. Must be provided. :param run_uuid: str (optional)   [Deprecated, use `run_id` instead] ID of the run from which to fetch metric values. This field will   be removed in a future MLflow version.  :returns: Iterator over :class:`Metric`",experiment_run_metrics,get,select,$.metrics
ml.json,/api/2.0/mlflow/runs/create,experiments_create_run,post,CreateRunResponse,"ml, experiments","experiment_id, run_name, start_time, tags, user_id",Creates a new run within an experiment. A run is usually a single execution of a machine learning or,"Creates a new run within an experiment. A run is usually a single execution of a machine learning or data ETL pipeline. MLflow uses runs to track the `mlflowParam`, `mlflowMetric`, and `mlflowRunTag` associated with a single execution.  :param experiment_id: str (optional)   ID of the associated experiment. :param run_name: str (optional)   The name of the run. :param start_time: int (optional)   Unix timestamp in milliseconds of when the run started. :param tags: List[:class:`RunTag`] (optional)   Additional metadata for run. :param user_id: str (optional)   ID of the user executing the run. This field is deprecated as of MLflow 1.0, and will be removed in   a future MLflow release. Use 'mlflow.user' tag instead.  :returns: :class:`CreateRunResponse`",experiment_runs,create,insert,
ml.json,/api/2.0/mlflow/runs/delete,experiments_delete_run,post,,"ml, experiments",run_id,Marks a run for deletion.,Marks a run for deletion.  :param run_id: str   ID of the run to delete.,experiment_runs,delete,exec,
ml.json,/api/2.0/mlflow/databricks/runs/delete-runs,experiments_delete_runs,post,DeleteRunsResponse,"ml, experiments","experiment_id, max_timestamp_millis, max_runs",Bulk delete runs in an experiment that were created prior to or at the specified timestamp. Deletes at,"Bulk delete runs in an experiment that were created prior to or at the specified timestamp. Deletes at most max_runs per request. To call this API from a Databricks Notebook in Python, you can use the client code snippet on  :param experiment_id: str   The ID of the experiment containing the runs to delete. :param max_timestamp_millis: int   The maximum creation timestamp in milliseconds since the UNIX epoch for deleting runs. Only runs   created prior to or at this timestamp are deleted. :param max_runs: int (optional)   An optional positive integer indicating the maximum number of runs to delete. The maximum allowed   value for max_runs is 10000.  :returns: :class:`DeleteRunsResponse`",experiment_runs,delete_bulk,exec,
ml.json,/api/2.0/mlflow/runs/delete-tag,experiments_delete_tag,post,,"ml, experiments","run_id, key",Deletes a tag on a run. Tags are run metadata that can be updated during a run and after a run,Deletes a tag on a run. Tags are run metadata that can be updated during a run and after a run completes.  :param run_id: str   ID of the run that the tag was logged under. Must be provided. :param key: str   Name of the tag. Maximum size is 255 bytes. Must be provided.,experiment_runs,delete_tag,exec,
ml.json,/api/2.0/mlflow/runs/get,experiments_get_run,get,GetRunResponse,"ml, experiments","run_id, run_uuid","Gets the metadata, metrics, params, and tags for a run. In the case where multiple metrics with the","Gets the metadata, metrics, params, and tags for a run. In the case where multiple metrics with the same key are logged for a run, return only the value with the latest timestamp.  If there are multiple values with the latest timestamp, return the maximum of these values.  :param run_id: str   ID of the run to fetch. Must be provided. :param run_uuid: str (optional)   [Deprecated, use `run_id` instead] ID of the run to fetch. This field will be removed in a future   MLflow version.  :returns: :class:`GetRunResponse`",experiment_runs,get,select,
ml.json,/api/2.0/mlflow/runs/log-batch,experiments_log_batch,post,,"ml, experiments","metrics, params, run_id, tags","Logs a batch of metrics, params, and tags for a run. If any data failed to be persisted, the server","Logs a batch of metrics, params, and tags for a run. If any data failed to be persisted, the server will respond with an error (non-200 status code).  In case of error (due to internal server error or an invalid request), partial data may be written.  You can write metrics, params, and tags in interleaving fashion, but within a given entity type are guaranteed to follow the order specified in the request body.  The overwrite behavior for metrics, params, and tags is as follows:  * Metrics: metric values are never overwritten. Logging a metric (key, value, timestamp) appends to the set of values for the metric with the provided key.  * Tags: tag values can be overwritten by successive writes to the same tag key. That is, if multiple tag values with the same key are provided in the same API request, the last-provided tag value is written. Logging the same tag (key, value) is permitted. Specifically, logging a tag is idempotent.  * Parameters: once written, param values cannot be changed (attempting to overwrite a param value will result in an error). However, logging the same param (key, value) is permitted. Specifically, logging a param is idempotent.  Request Limits ------------------------------- A single JSON-serialized API request may be up to 1 MB in size and contain:  * No more than 1000 metrics, params, and tags in total  * Up to 1000 metrics  * Up to 100 params  * Up to 100 tags  For example, a valid request might contain 900 metrics, 50 params, and 50 tags, but logging 900 metrics, 50 params, and 51 tags is invalid.  The following limits also apply to metric, param, and tag keys and values:  * Metric keys, param keys, and tag keys can be up to 250 characters in length  * Parameter and tag values can be up to 250 characters in length  :param metrics: List[:class:`Metric`] (optional)   Metrics to log. A single request can contain up to 1000 metrics, and up to 1000 metrics, params, and   tags in total. :param params: List[:class:`Param`] (optional)   Params to log. A single request can contain up to 100 params, and up to 1000 metrics, params, and   tags in total. :param run_id: str (optional)   ID of the run to log under :param tags: List[:class:`RunTag`] (optional)   Tags to log. A single request can contain up to 100 tags, and up to 1000 metrics, params, and tags   in total.",experiment_runs,log_batch,exec,
ml.json,/api/2.0/mlflow/runs/log-inputs,experiments_log_inputs,post,,"ml, experiments","run_id, datasets, models","Logs inputs, such as datasets and models, to an MLflow Run.","Logs inputs, such as datasets and models, to an MLflow Run.  :param run_id: str   ID of the run to log under :param datasets: List[:class:`DatasetInput`] (optional)   Dataset inputs :param models: List[:class:`ModelInput`] (optional)   Model inputs",experiment_runs,log_inputs,exec,
ml.json,/api/2.0/mlflow/runs/log-metric,experiments_log_metric,post,,"ml, experiments","key, value, timestamp, dataset_digest, dataset_name, model_id, run_id, run_uuid, step","Log a metric for a run. A metric is a key-value pair (string key, float value) with an associated","Log a metric for a run. A metric is a key-value pair (string key, float value) with an associated timestamp. Examples include the various metrics that represent ML model accuracy. A metric can be logged multiple times.  :param key: str   Name of the metric. :param value: float   Double value of the metric being logged. :param timestamp: int   Unix timestamp in milliseconds at the time metric was logged. :param dataset_digest: str (optional)   Dataset digest of the dataset associated with the metric, e.g. an md5 hash of the dataset that   uniquely identifies it within datasets of the same name. :param dataset_name: str (optional)   The name of the dataset associated with the metric. E.g. “my.uc.table@2” “nyc-taxi-dataset”,   “fantastic-elk-3” :param model_id: str (optional)   ID of the logged model associated with the metric, if applicable :param run_id: str (optional)   ID of the run under which to log the metric. Must be provided. :param run_uuid: str (optional)   [Deprecated, use `run_id` instead] ID of the run under which to log the metric. This field will be   removed in a future MLflow version. :param step: int (optional)   Step at which to log the metric",experiment_runs,log_metric,exec,
ml.json,/api/2.0/mlflow/runs/log-model,experiments_log_model,post,,"ml, experiments","model_json, run_id",**Note:** the [Create a logged model](/api/workspace/experiments/createloggedmodel) API replaces this,**Note:** the [Create a logged model](/api/workspace/experiments/createloggedmodel) API replaces this endpoint.  Log a model to an MLflow Run.  :param model_json: str (optional)   MLmodel file in json format. :param run_id: str (optional)   ID of the run to log under,experiment_runs,log_model,exec,
ml.json,/api/2.0/mlflow/runs/outputs,experiments_log_outputs,post,,"ml, experiments","run_id, models","Logs outputs, such as models, from an MLflow Run.","Logs outputs, such as models, from an MLflow Run.  :param run_id: str   The ID of the Run from which to log outputs. :param models: List[:class:`ModelOutput`] (optional)   The model outputs from the Run.",experiment_runs,log_outputs,exec,
ml.json,/api/2.0/mlflow/runs/log-parameter,experiments_log_param,post,,"ml, experiments","key, value, run_id, run_uuid","Logs a param used for a run. A param is a key-value pair (string key, string value). Examples include","Logs a param used for a run. A param is a key-value pair (string key, string value). Examples include hyperparameters used for ML model training and constant dates and values used in an ETL pipeline. A param can be logged only once for a run.  :param key: str   Name of the param. Maximum size is 255 bytes. :param value: str   String value of the param being logged. Maximum size is 500 bytes. :param run_id: str (optional)   ID of the run under which to log the param. Must be provided. :param run_uuid: str (optional)   [Deprecated, use `run_id` instead] ID of the run under which to log the param. This field will be   removed in a future MLflow version.",experiment_runs,log_param,exec,
ml.json,/api/2.0/mlflow/runs/restore,experiments_restore_run,post,,"ml, experiments",run_id,"Restores a deleted run. This also restores associated metadata, runs, metrics, params, and tags.","Restores a deleted run. This also restores associated metadata, runs, metrics, params, and tags.  Throws `RESOURCE_DOES_NOT_EXIST` if the run was never created or was permanently deleted.  :param run_id: str   ID of the run to restore.",experiment_runs,restore,exec,
ml.json,/api/2.0/mlflow/databricks/runs/restore-runs,experiments_restore_runs,post,RestoreRunsResponse,"ml, experiments","experiment_id, min_timestamp_millis, max_runs",Bulk restore runs in an experiment that were deleted no earlier than the specified timestamp. Restores,"Bulk restore runs in an experiment that were deleted no earlier than the specified timestamp. Restores at most max_runs per request. To call this API from a Databricks Notebook in Python, you can use the client code snippet on  :param experiment_id: str   The ID of the experiment containing the runs to restore. :param min_timestamp_millis: int   The minimum deletion timestamp in milliseconds since the UNIX epoch for restoring runs. Only runs   deleted no earlier than this timestamp are restored. :param max_runs: int (optional)   An optional positive integer indicating the maximum number of runs to restore. The maximum allowed   value for max_runs is 10000.  :returns: :class:`RestoreRunsResponse`",experiment_runs,restore_bulk,exec,
ml.json,/api/2.0/mlflow/runs/search,experiments_search_runs,post,SearchRunsResponse,"ml, experiments","experiment_ids, filter, max_results, order_by, page_token, run_view_type",Searches for runs that satisfy expressions.,"Searches for runs that satisfy expressions.  Search expressions can use `mlflowMetric` and `mlflowParam` keys.  :param experiment_ids: List[str] (optional)   List of experiment IDs to search over. :param filter: str (optional)   A filter expression over params, metrics, and tags, that allows returning a subset of runs. The   syntax is a subset of SQL that supports ANDing together binary operations between a param, metric,   or tag and a constant.    Example: `metrics.rmse < 1 and params.model_class = 'LogisticRegression'`    You can select columns with special characters (hyphen, space, period, etc.) by using double quotes:   `metrics.""model class"" = 'LinearRegression' and tags.""user-name"" = 'Tomas'`    Supported operators are `=`, `!=`, `>`, `>=`, `<`, and `<=`. :param max_results: int (optional)   Maximum number of runs desired. Max threshold is 50000 :param order_by: List[str] (optional)   List of columns to be ordered by, including attributes, params, metrics, and tags with an optional   `""DESC""` or `""ASC""` annotation, where `""ASC""` is the default. Example: `[""params.input DESC"",   ""metrics.alpha ASC"", ""metrics.rmse""]`. Tiebreaks are done by start_time `DESC` followed by `run_id`   for runs with the same start time (and this is the default ordering criterion if order_by is not   provided). :param page_token: str (optional)   Token for the current page of runs. :param run_view_type: :class:`ViewType` (optional)   Whether to display only active, only deleted, or all runs. Defaults to only active runs.  :returns: Iterator over :class:`Run`",experiment_runs,search,exec,$.runs
ml.json,/api/2.0/mlflow/runs/set-tag,experiments_set_tag,post,,"ml, experiments","key, value, run_id, run_uuid",Sets a tag on a run. Tags are run metadata that can be updated during a run and after a run completes.,"Sets a tag on a run. Tags are run metadata that can be updated during a run and after a run completes.  :param key: str   Name of the tag. Keys up to 250 bytes in size are supported. :param value: str   String value of the tag being logged. Values up to 64KB in size are supported. :param run_id: str (optional)   ID of the run under which to log the tag. Must be provided. :param run_uuid: str (optional)   [Deprecated, use `run_id` instead] ID of the run under which to log the tag. This field will be   removed in a future MLflow version.",experiment_runs,set_tag,exec,
ml.json,/api/2.0/mlflow/runs/update,experiments_update_run,post,UpdateRunResponse,"ml, experiments","end_time, run_id, run_name, run_uuid, status",Updates run metadata.,"Updates run metadata.  :param end_time: int (optional)   Unix timestamp in milliseconds of when the run ended. :param run_id: str (optional)   ID of the run to update. Must be provided. :param run_name: str (optional)   Updated name of the run. :param run_uuid: str (optional)   [Deprecated, use `run_id` instead] ID of the run to update. This field will be removed in a future   MLflow version. :param status: :class:`UpdateRunStatus` (optional)   Updated status of the run.  :returns: :class:`UpdateRunResponse`",experiment_runs,update,exec,
ml.json,/api/2.0/mlflow/experiments/create,experiments_create_experiment,post,CreateExperimentResponse,"ml, experiments","name, artifact_location, tags",Creates an experiment with a name. Returns the ID of the newly created experiment. Validates that,"Creates an experiment with a name. Returns the ID of the newly created experiment. Validates that another experiment with the same name does not already exist and fails if another experiment with the same name already exists.  Throws `RESOURCE_ALREADY_EXISTS` if an experiment with the given name exists.  :param name: str   Experiment name. :param artifact_location: str (optional)   Location where all artifacts for the experiment are stored. If not provided, the remote server will   select an appropriate default. :param tags: List[:class:`ExperimentTag`] (optional)   A collection of tags to set on the experiment. Maximum tag size and number of tags per request   depends on the storage backend. All storage backends are guaranteed to support tag keys up to 250   bytes in size and tag values up to 5000 bytes in size. All storage backends are also guaranteed to   support up to 20 tags per request.  :returns: :class:`CreateExperimentResponse`",experiments,create,insert,
ml.json,/api/2.0/mlflow/experiments/delete,experiments_delete_experiment,post,,"ml, experiments",experiment_id,"Marks an experiment and associated metadata, runs, metrics, params, and tags for deletion. If the","Marks an experiment and associated metadata, runs, metrics, params, and tags for deletion. If the experiment uses FileStore, artifacts associated with the experiment are also deleted.  :param experiment_id: str   ID of the associated experiment.",experiments,delete,exec,
ml.json,/api/2.0/mlflow/experiments/get-by-name,experiments_get_by_name,get,GetExperimentByNameResponse,"ml, experiments",experiment_name,Gets metadata for an experiment.,"Gets metadata for an experiment.  This endpoint will return deleted experiments, but prefers the active experiment if an active and deleted experiment share the same name. If multiple deleted experiments share the same name, the API will return one of them.  Throws `RESOURCE_DOES_NOT_EXIST` if no experiment with the specified name exists.  :param experiment_name: str   Name of the associated experiment.  :returns: :class:`GetExperimentByNameResponse`",experiments,get_by_name,select,
ml.json,/api/2.0/mlflow/experiments/get,experiments_get_experiment,get,GetExperimentResponse,"ml, experiments",experiment_id,Gets metadata for an experiment. This method works on deleted experiments.,Gets metadata for an experiment. This method works on deleted experiments.  :param experiment_id: str   ID of the associated experiment.  :returns: :class:`GetExperimentResponse`,experiments,get,select,
ml.json,/api/2.0/mlflow/experiments/list,experiments_list_experiments,get,ListExperimentsResponse,"ml, experiments","max_results, page_token, view_type",Gets a list of all experiments.,"Gets a list of all experiments.  :param max_results: int (optional)   Maximum number of experiments desired. If `max_results` is unspecified, return all experiments. If   `max_results` is too large, it'll be automatically capped at 1000. Callers of this endpoint are   encouraged to pass max_results explicitly and leverage page_token to iterate through experiments. :param page_token: str (optional)   Token indicating the page of experiments to fetch :param view_type: :class:`ViewType` (optional)   Qualifier for type of experiments to be returned. If unspecified, return only active experiments.  :returns: Iterator over :class:`Experiment`",experiments,list,select,$.experiments
ml.json,/api/2.0/mlflow/experiments/restore,experiments_restore_experiment,post,,"ml, experiments",experiment_id,"Restore an experiment marked for deletion. This also restores associated metadata, runs, metrics,","Restore an experiment marked for deletion. This also restores associated metadata, runs, metrics, params, and tags. If experiment uses FileStore, underlying artifacts associated with experiment are also restored.  Throws `RESOURCE_DOES_NOT_EXIST` if experiment was never created or was permanently deleted.  :param experiment_id: str   ID of the associated experiment.",experiments,restore,exec,
ml.json,/api/2.0/mlflow/experiments/search,experiments_search_experiments,post,ListExperimentsResponse,"ml, experiments","filter, max_results, order_by, page_token, view_type",Searches for experiments that satisfy specified search criteria.,"Searches for experiments that satisfy specified search criteria.  :param filter: str (optional)   String representing a SQL filter condition (e.g. ""name ILIKE 'my-experiment%'"") :param max_results: int (optional)   Maximum number of experiments desired. Max threshold is 3000. :param order_by: List[str] (optional)   List of columns for ordering search results, which can include experiment name and last updated   timestamp with an optional ""DESC"" or ""ASC"" annotation, where ""ASC"" is the default. Tiebreaks are   done by experiment id DESC. :param page_token: str (optional)   Token indicating the page of experiments to fetch :param view_type: :class:`ViewType` (optional)   Qualifier for type of experiments to be returned. If unspecified, return only active experiments.  :returns: Iterator over :class:`Experiment`",experiments,search,exec,$.experiments
ml.json,/api/2.0/mlflow/experiments/set-experiment-tag,experiments_set_experiment_tag,post,,"ml, experiments","experiment_id, key, value",Sets a tag on an experiment. Experiment tags are metadata that can be updated.,Sets a tag on an experiment. Experiment tags are metadata that can be updated.  :param experiment_id: str   ID of the experiment under which to log the tag. Must be provided. :param key: str   Name of the tag. Keys up to 250 bytes in size are supported. :param value: str   String value of the tag being logged. Values up to 64KB in size are supported.,experiments,set_tag,exec,
ml.json,/api/2.0/mlflow/experiments/update,experiments_update_experiment,post,,"ml, experiments","experiment_id, new_name",Updates experiment metadata.,"Updates experiment metadata.  :param experiment_id: str   ID of the associated experiment. :param new_name: str (optional)   If provided, the experiment's name is changed to the new name. The new name must be unique.",experiments,update,exec,
ml.json,/api/2.0/feature-engineering/features,feature_engineering_create_feature,post,Feature,"ml, feature_engineering",feature,Create a Feature.,Create a Feature.  :param feature: :class:`Feature`   Feature to create.  :returns: :class:`Feature`,feature_engineering,create,insert,
ml.json,/api/2.0/feature-engineering/features,feature_engineering_list_features,get,ListFeaturesResponse,"ml, feature_engineering","page_size, page_token",List Features.,List Features.  :param page_size: int (optional)   The maximum number of results to return. :param page_token: str (optional)   Pagination token to go to the next page based on a previous query.  :returns: Iterator over :class:`Feature`,feature_engineering,list,select,$.features
ml.json,/api/2.0/feature-engineering/features/{full_name},feature_engineering_delete_feature,delete,,"ml, feature_engineering",full_name,Delete a Feature.,Delete a Feature.  :param full_name: str   Name of the feature to delete.,feature_engineering,delete,delete,
ml.json,/api/2.0/feature-engineering/features/{full_name},feature_engineering_get_feature,get,Feature,"ml, feature_engineering",full_name,Get a Feature.,Get a Feature.  :param full_name: str   Name of the feature to get.  :returns: :class:`Feature`,feature_engineering,get,select,
ml.json,/api/2.0/feature-engineering/features/{full_name},feature_engineering_update_feature,patch,Feature,"ml, feature_engineering","full_name, update_mask, feature",Update a Feature.,"Update a Feature.  :param full_name: str   The full three-part name (catalog, schema, name) of the feature. :param feature: :class:`Feature`   Feature to update. :param update_mask: str   The list of fields to update.  :returns: :class:`Feature`",feature_engineering,update,update,
ml.json,/api/2.0/feature-engineering/features/kafka-configs,feature_engineering_create_kafka_config,post,KafkaConfig,"ml, feature_engineering",kafka_config,"Create a Kafka config. During PrPr, Kafka configs can be read and used when creating features under","Create a Kafka config. During PrPr, Kafka configs can be read and used when creating features under the entire metastore. Only the creator of the Kafka config can delete it.  :param kafka_config: :class:`KafkaConfig`  :returns: :class:`KafkaConfig`",feature_kafka_configs,create,insert,
ml.json,/api/2.0/feature-engineering/features/kafka-configs,feature_engineering_list_kafka_configs,get,ListKafkaConfigsResponse,"ml, feature_engineering","page_size, page_token","List Kafka configs. During PrPr, Kafka configs can be read and used when creating features under the","List Kafka configs. During PrPr, Kafka configs can be read and used when creating features under the entire metastore. Only the creator of the Kafka config can delete it.  :param page_size: int (optional)   The maximum number of results to return. :param page_token: str (optional)   Pagination token to go to the next page based on a previous query.  :returns: Iterator over :class:`KafkaConfig`",feature_kafka_configs,list,select,$.kafka_configs
ml.json,/api/2.0/feature-engineering/features/kafka-configs/{name},feature_engineering_delete_kafka_config,delete,,"ml, feature_engineering",name,"Delete a Kafka config. During PrPr, Kafka configs can be read and used when creating features under","Delete a Kafka config. During PrPr, Kafka configs can be read and used when creating features under the entire metastore. Only the creator of the Kafka config can delete it.  :param name: str   Name of the Kafka config to delete.",feature_kafka_configs,delete,delete,
ml.json,/api/2.0/feature-engineering/features/kafka-configs/{name},feature_engineering_get_kafka_config,get,KafkaConfig,"ml, feature_engineering",name,"Get a Kafka config. During PrPr, Kafka configs can be read and used when creating features under the","Get a Kafka config. During PrPr, Kafka configs can be read and used when creating features under the entire metastore. Only the creator of the Kafka config can delete it.  :param name: str   Name of the Kafka config to get.  :returns: :class:`KafkaConfig`",feature_kafka_configs,get,select,
ml.json,/api/2.0/feature-engineering/features/kafka-configs/{name},feature_engineering_update_kafka_config,patch,KafkaConfig,"ml, feature_engineering","name, update_mask, kafka_config","Update a Kafka config. During PrPr, Kafka configs can be read and used when creating features under","Update a Kafka config. During PrPr, Kafka configs can be read and used when creating features under the entire metastore. Only the creator of the Kafka config can delete it.  :param name: str   Name that uniquely identifies this Kafka config within the metastore. This will be the identifier   used from the Feature object to reference these configs for a feature. Can be distinct from topic   name. :param kafka_config: :class:`KafkaConfig`   The Kafka config to update. :param update_mask: FieldMask   The list of fields to update.  :returns: :class:`KafkaConfig`",feature_kafka_configs,update,update,
ml.json,/api/2.0/feature-store/feature-tables/{table_name}/features/{feature_name}/lineage,materialized_features_get_feature_lineage,get,FeatureLineage,"ml, materialized_features","table_name, feature_name",Get Feature Lineage.,Get Feature Lineage.  :param table_name: str   The full name of the feature table in Unity Catalog. :param feature_name: str   The name of the feature.  :returns: :class:`FeatureLineage`,feature_lineage,get,select,
ml.json,/api/2.0/feature-engineering/materialized-features:batchCreate,feature_engineering_batch_create_materialized_features,post,BatchCreateMaterializedFeaturesResponse,"ml, feature_engineering",requests,Batch create materialized features.,Batch create materialized features.  :param requests: List[:class:`CreateMaterializedFeatureRequest`]   The requests to create materialized features.  :returns: :class:`BatchCreateMaterializedFeaturesResponse`,feature_materialized,batch_create,exec,
ml.json,/api/2.0/feature-engineering/materialized-features,feature_engineering_create_materialized_feature,post,MaterializedFeature,"ml, feature_engineering",materialized_feature,Create a materialized feature.,Create a materialized feature.  :param materialized_feature: :class:`MaterializedFeature`   The materialized feature to create.  :returns: :class:`MaterializedFeature`,feature_materialized,create,insert,
ml.json,/api/2.0/feature-engineering/materialized-features,feature_engineering_list_materialized_features,get,BatchCreateMaterializedFeaturesResponse,"ml, feature_engineering","feature_name, page_size, page_token",List materialized features.,"List materialized features.  :param feature_name: str (optional)   Filter by feature name. If specified, only materialized features materialized from this feature will   be returned. :param page_size: int (optional)   The maximum number of results to return. Defaults to 100 if not specified. Cannot be greater than   1000. :param page_token: str (optional)   Pagination token to go to the next page based on a previous query.  :returns: Iterator over :class:`MaterializedFeature`",feature_materialized,list,select,$.materialized_features
ml.json,/api/2.0/feature-engineering/materialized-features/{materialized_feature_id},feature_engineering_delete_materialized_feature,delete,,"ml, feature_engineering",materialized_feature_id,Delete a materialized feature.,Delete a materialized feature.  :param materialized_feature_id: str   The ID of the materialized feature to delete.,feature_materialized,delete,delete,
ml.json,/api/2.0/feature-engineering/materialized-features/{materialized_feature_id},feature_engineering_get_materialized_feature,get,MaterializedFeature,"ml, feature_engineering",materialized_feature_id,Get a materialized feature.,Get a materialized feature.  :param materialized_feature_id: str   The ID of the materialized feature.  :returns: :class:`MaterializedFeature`,feature_materialized,get,select,
ml.json,/api/2.0/feature-engineering/materialized-features/{materialized_feature_id},feature_engineering_update_materialized_feature,patch,MaterializedFeature,"ml, feature_engineering","materialized_feature_id, update_mask, materialized_feature",Update a materialized feature (pause/resume).,"Update a materialized feature (pause/resume).  :param materialized_feature_id: str   Unique identifier for the materialized feature. :param materialized_feature: :class:`MaterializedFeature`   The materialized feature to update. :param update_mask: str   Provide the materialization feature fields which should be updated. Currently, only the   pipeline_state field can be updated.  :returns: :class:`MaterializedFeature`",feature_materialized,update,update,
ml.json,/api/2.0/feature-store/online-stores,feature_store_create_online_store,post,OnlineStore,"ml, feature_store",online_store,Create an Online Feature Store.,Create an Online Feature Store.  :param online_store: :class:`OnlineStore`   Online store to create.  :returns: :class:`OnlineStore`,feature_store,create,insert,
ml.json,/api/2.0/feature-store/online-stores,feature_store_list_online_stores,get,ListOnlineStoresResponse,"ml, feature_store","page_size, page_token",List Online Feature Stores.,List Online Feature Stores.  :param page_size: int (optional)   The maximum number of results to return. Defaults to 100 if not specified. :param page_token: str (optional)   Pagination token to go to the next page based on a previous query.  :returns: Iterator over :class:`OnlineStore`,feature_store,list,select,$.online_stores
ml.json,/api/2.0/feature-store/online-stores/{name},feature_store_delete_online_store,delete,,"ml, feature_store",name,Delete an Online Feature Store.,Delete an Online Feature Store.  :param name: str   Name of the online store to delete.,feature_store,delete,delete,
ml.json,/api/2.0/feature-store/online-stores/{name},feature_store_get_online_store,get,OnlineStore,"ml, feature_store",name,Get an Online Feature Store.,Get an Online Feature Store.  :param name: str   Name of the online store to get.  :returns: :class:`OnlineStore`,feature_store,get,select,
ml.json,/api/2.0/feature-store/online-stores/{name},feature_store_update_online_store,patch,OnlineStore,"ml, feature_store","name, update_mask, online_store",Update an Online Feature Store.,Update an Online Feature Store.  :param name: str   The name of the online store. This is the unique identifier for the online store. :param online_store: :class:`OnlineStore`   Online store to update. :param update_mask: str   The list of fields to update.  :returns: :class:`OnlineStore`,feature_store,update,update,
ml.json,/api/2.0/feature-store/online-tables/{online_table_name},feature_store_delete_online_table,delete,,"ml, feature_store",online_table_name,Delete online table.,"Delete online table.  :param online_table_name: str   The full three-part (catalog, schema, table) name of the online table.",feature_store,delete_table,delete,
ml.json,/api/2.0/feature-store/tables/{source_table_name}/publish,feature_store_publish_table,post,PublishTableResponse,"ml, feature_store","source_table_name, publish_spec",Publish features.,"Publish features.  :param source_table_name: str   The full three-part (catalog, schema, table) name of the source table. :param publish_spec: :class:`PublishSpec`   The specification for publishing the online table from the source table.  :returns: :class:`PublishTableResponse`",feature_store,publish_table,insert,
ml.json,/api/2.0/automl/create-forecasting-experiment,forecasting_create_experiment,post,ForecastingExperiment,"ml, forecasting","train_data_path, target_column, time_column, forecast_granularity, forecast_horizon, custom_weights_column, experiment_path, future_feature_data_path, holiday_regions, include_features, max_runtime, prediction_data_path, primary_metric, register_to, split_column, timeseries_identifier_columns, training_frameworks",Creates a serverless forecasting experiment. Returns the experiment ID.,"Creates a serverless forecasting experiment. Returns the experiment ID.  :param train_data_path: str   The fully qualified path of a Unity Catalog table, formatted as catalog_name.schema_name.table_name,   used as training data for the forecasting model. :param target_column: str   The column in the input training table used as the prediction target for model training. The values   in this column are used as the ground truth for model training. :param time_column: str   The column in the input training table that represents each row's timestamp. :param forecast_granularity: str   The time interval between consecutive rows in the time series data. Possible values include: '1   second', '1 minute', '5 minutes', '10 minutes', '15 minutes', '30 minutes', 'Hourly', 'Daily',   'Weekly', 'Monthly', 'Quarterly', 'Yearly'. :param forecast_horizon: int   The number of time steps into the future to make predictions, calculated as a multiple of   forecast_granularity. This value represents how far ahead the model should forecast. :param custom_weights_column: str (optional)   The column in the training table used to customize weights for each time series. :param experiment_path: str (optional)   The path in the workspace to store the created experiment. :param future_feature_data_path: str (optional)   The fully qualified path of a Unity Catalog table, formatted as catalog_name.schema_name.table_name,   used to store future feature data for predictions. :param holiday_regions: List[str] (optional)   The region code(s) to automatically add holiday features. Currently supports only one region. :param include_features: List[str] (optional)   Specifies the list of feature columns to include in model training. These columns must exist in the   training data and be of type string, numerical, or boolean. If not specified, no additional features   will be included. Note: Certain columns are automatically handled: - Automatically excluded:   split_column, target_column, custom_weights_column. - Automatically included: time_column. :param max_runtime: int (optional)   The maximum duration for the experiment in minutes. The experiment stops automatically if it exceeds   this limit. :param prediction_data_path: str (optional)   The fully qualified path of a Unity Catalog table, formatted as catalog_name.schema_name.table_name,   used to store predictions. :param primary_metric: str (optional)   The evaluation metric used to optimize the forecasting model. :param register_to: str (optional)   The fully qualified path of a Unity Catalog model, formatted as catalog_name.schema_name.model_name,   used to store the best model. :param split_column: str (optional)   // The column in the training table used for custom data splits. Values must be 'train', 'validate',   or 'test'. :param timeseries_identifier_columns: List[str] (optional)   The column in the training table used to group the dataset for predicting individual time series. :param training_frameworks: List[str] (optional)   List of frameworks to include for model tuning. Possible values are 'Prophet', 'ARIMA', 'DeepAR'. An   empty list includes all supported frameworks.  :returns:   Long-running operation waiter for :class:`ForecastingExperiment`.   See :method:wait_get_experiment_forecasting_succeeded for more details.",forecasting,create,insert,
ml.json,/api/2.0/automl/get-forecasting-experiment/{experiment_id},forecasting_get_experiment,get,ForecastingExperiment,"ml, forecasting",experiment_id,Public RPC to get forecasting experiment,Public RPC to get forecasting experiment  :param experiment_id: str   The unique ID of a forecasting experiment  :returns: :class:`ForecastingExperiment`,forecasting,get,select,
ml.json,/api/2.0/mlflow/logged-models,experiments_create_logged_model,post,CreateLoggedModelResponse,"ml, experiments","experiment_id, model_type, name, params, source_run_id, tags",Create a logged model.,"Create a logged model.  :param experiment_id: str   The ID of the experiment that owns the model. :param model_type: str (optional)   The type of the model, such as ``""Agent""``, ``""Classifier""``, ``""LLM""``. :param name: str (optional)   The name of the model (optional). If not specified one will be generated. :param params: List[:class:`LoggedModelParameter`] (optional)   Parameters attached to the model. :param source_run_id: str (optional)   The ID of the run that created the model. :param tags: List[:class:`LoggedModelTag`] (optional)   Tags attached to the model.  :returns: :class:`CreateLoggedModelResponse`",logged_models,create,insert,
ml.json,/api/2.0/mlflow/logged-models/{model_id},experiments_delete_logged_model,delete,,"ml, experiments",model_id,Delete a logged model.,Delete a logged model.  :param model_id: str   The ID of the logged model to delete.,logged_models,delete,delete,
ml.json,/api/2.0/mlflow/logged-models/{model_id},experiments_finalize_logged_model,patch,FinalizeLoggedModelResponse,"ml, experiments","model_id, status",Finalize a logged model.,"Finalize a logged model.  :param model_id: str   The ID of the logged model to finalize. :param status: :class:`LoggedModelStatus`   Whether or not the model is ready for use. ``""LOGGED_MODEL_UPLOAD_FAILED""`` indicates that something   went wrong when logging the model weights / agent code.  :returns: :class:`FinalizeLoggedModelResponse`",logged_models,finalize,exec,
ml.json,/api/2.0/mlflow/logged-models/{model_id},experiments_get_logged_model,get,GetLoggedModelResponse,"ml, experiments",model_id,Get a logged model.,Get a logged model.  :param model_id: str   The ID of the logged model to retrieve.  :returns: :class:`GetLoggedModelResponse`,logged_models,get,select,
ml.json,/api/2.0/mlflow/logged-models/{model_id}/tags/{tag_key},experiments_delete_logged_model_tag,delete,,"ml, experiments","model_id, tag_key",Delete a tag on a logged model.,Delete a tag on a logged model.  :param model_id: str   The ID of the logged model to delete the tag from. :param tag_key: str   The tag key.,logged_models,delete_tag,delete,
ml.json,/api/2.0/mlflow/logged-models/{model_id}/params,experiments_log_logged_model_params,post,,"ml, experiments","model_id, params","Logs params for a logged model. A param is a key-value pair (string key, string value). Examples","Logs params for a logged model. A param is a key-value pair (string key, string value). Examples include hyperparameters used for ML model training. A param can be logged only once for a logged model, and attempting to overwrite an existing param with a different value will result in an error  :param model_id: str   The ID of the logged model to log params for. :param params: List[:class:`LoggedModelParameter`] (optional)   Parameters to attach to the model.",logged_models,log_params,exec,
ml.json,/api/2.0/mlflow/logged-models/search,experiments_search_logged_models,post,SearchLoggedModelsResponse,"ml, experiments","datasets, experiment_ids, filter, max_results, order_by, page_token",Search for Logged Models that satisfy specified search criteria.,"Search for Logged Models that satisfy specified search criteria.  :param datasets: List[:class:`SearchLoggedModelsDataset`] (optional)   List of datasets on which to apply the metrics filter clauses. For example, a filter with   `metrics.accuracy > 0.9` and dataset info with name ""test_dataset"" means we will return all logged   models with accuracy > 0.9 on the test_dataset. Metric values from ANY dataset matching the criteria   are considered. If no datasets are specified, then metrics across all datasets are considered in the   filter. :param experiment_ids: List[str] (optional)   The IDs of the experiments in which to search for logged models. :param filter: str (optional)   A filter expression over logged model info and data that allows returning a subset of logged models.   The syntax is a subset of SQL that supports AND'ing together binary operations.    Example: ``params.alpha < 0.3 AND metrics.accuracy > 0.9``. :param max_results: int (optional)   The maximum number of Logged Models to return. The maximum limit is 50. :param order_by: List[:class:`SearchLoggedModelsOrderBy`] (optional)   The list of columns for ordering the results, with additional fields for sorting criteria. :param page_token: str (optional)   The token indicating the page of logged models to fetch.  :returns: :class:`SearchLoggedModelsResponse`",logged_models,search,exec,
ml.json,/api/2.0/mlflow/logged-models/{model_id}/tags,experiments_set_logged_model_tags,patch,,"ml, experiments","model_id, tags",Set tags for a logged model.,Set tags for a logged model.  :param model_id: str   The ID of the logged model to set the tags on. :param tags: List[:class:`LoggedModelTag`] (optional)   The tags to set on the logged model.,logged_models,set_tags,exec,
ml.json,/api/2.0/feature-store/feature-tables/{table_name}/features/{feature_name}/tags,materialized_features_create_feature_tag,post,FeatureTag,"ml, materialized_features","table_name, feature_name, feature_tag",Creates a FeatureTag.,Creates a FeatureTag.  :param table_name: str :param feature_name: str :param feature_tag: :class:`FeatureTag`  :returns: :class:`FeatureTag`,materialized_features,create,insert,
ml.json,/api/2.0/feature-store/feature-tables/{table_name}/features/{feature_name}/tags,materialized_features_list_feature_tags,get,ListFeatureTagsResponse,"ml, materialized_features","table_name, feature_name, page_size, page_token",Lists FeatureTags.,Lists FeatureTags.  :param table_name: str :param feature_name: str :param page_size: int (optional)   The maximum number of results to return. :param page_token: str (optional)   Pagination token to go to the next page based on a previous query.  :returns: Iterator over :class:`FeatureTag`,materialized_features,list,select,$.feature_tags
ml.json,/api/2.0/feature-store/feature-tables/{table_name}/features/{feature_name}/tags/{key},materialized_features_delete_feature_tag,delete,,"ml, materialized_features","table_name, feature_name, key",Deletes a FeatureTag.,Deletes a FeatureTag.  :param table_name: str   The name of the feature table. :param feature_name: str   The name of the feature within the feature table. :param key: str   The key of the tag to delete.,materialized_features,delete,delete,
ml.json,/api/2.0/feature-store/feature-tables/{table_name}/features/{feature_name}/tags/{key},materialized_features_get_feature_tag,get,FeatureTag,"ml, materialized_features","table_name, feature_name, key",Gets a FeatureTag.,Gets a FeatureTag.  :param table_name: str :param feature_name: str :param key: str  :returns: :class:`FeatureTag`,materialized_features,get,select,
ml.json,/api/2.0/feature-store/feature-tables/{table_name}/features/{feature_name}/tags/{key},materialized_features_update_feature_tag,patch,FeatureTag,"ml, materialized_features","table_name, feature_name, key, update_mask, feature_tag",Updates a FeatureTag.,Updates a FeatureTag.  :param table_name: str :param feature_name: str :param key: str :param feature_tag: :class:`FeatureTag` :param update_mask: str (optional)   The list of fields to update.  :returns: :class:`FeatureTag`,materialized_features,update,update,
ml.json,/api/2.0/mlflow/registered-models/create,model_registry_create_model,post,CreateModelResponse,"ml, model_registry","name, description, tags",Creates a new registered model with the name specified in the request body. Throws,Creates a new registered model with the name specified in the request body. Throws `RESOURCE_ALREADY_EXISTS` if a registered model with the given name exists.  :param name: str   Register models under this name :param description: str (optional)   Optional description for registered model. :param tags: List[:class:`ModelTag`] (optional)   Additional metadata for registered model.  :returns: :class:`CreateModelResponse`,model_registry,create,insert,
ml.json,/api/2.0/mlflow/registered-models/delete,model_registry_delete_model,delete,,"ml, model_registry",name,Deletes a registered model.,Deletes a registered model.  :param name: str   Registered model unique name identifier.,model_registry,delete,delete,
ml.json,/api/2.0/mlflow/registered-models/delete-tag,model_registry_delete_model_tag,delete,,"ml, model_registry","name, key",Deletes the tag for a registered model.,Deletes the tag for a registered model.  :param name: str   Name of the registered model that the tag was logged under. :param key: str   Name of the tag. The name must be an exact match; wild-card deletion is not supported. Maximum size   is 250 bytes.,model_registry,delete_tag,exec,
ml.json,/api/2.0/mlflow/databricks/registered-models/get,model_registry_get_model,get,GetModelResponse,"ml, model_registry",name,Get the details of a model. This is a Databricks workspace version of the [MLflow endpoint] that also,Get the details of a model. This is a Databricks workspace version of the [MLflow endpoint] that also returns the model's Databricks workspace ID and the permission level of the requesting user on the model.  [MLflow endpoint]: https://www.mlflow.org/docs/latest/rest-api.html#get-registeredmodel  :param name: str   Registered model unique name identifier.  :returns: :class:`GetModelResponse`,model_registry,get,select,
ml.json,/api/2.0/mlflow/registered-models/list,model_registry_list_models,get,ListModelsResponse,"ml, model_registry","max_results, page_token","Lists all available registered models, up to the limit specified in __max_results__.","Lists all available registered models, up to the limit specified in __max_results__.  :param max_results: int (optional)   Maximum number of registered models desired. Max threshold is 1000. :param page_token: str (optional)   Pagination token to go to the next page based on a previous query.  :returns: Iterator over :class:`Model`",model_registry,list,select,$.registered_models
ml.json,/api/2.0/mlflow/registered-models/rename,model_registry_rename_model,post,RenameModelResponse,"ml, model_registry","name, new_name",Renames a registered model.,"Renames a registered model.  :param name: str   Registered model unique name identifier. :param new_name: str (optional)   If provided, updates the name for this `registered_model`.  :returns: :class:`RenameModelResponse`",model_registry,rename,exec,
ml.json,/api/2.0/mlflow/registered-models/search,model_registry_search_models,get,ListModelsResponse,"ml, model_registry","filter, max_results, order_by, page_token",Search for registered models based on the specified __filter__.,"Search for registered models based on the specified __filter__.  :param filter: str (optional)   String filter condition, like ""name LIKE 'my-model-name'"". Interpreted in the backend automatically   as ""name LIKE '%my-model-name%'"". Single boolean condition, with string values wrapped in single   quotes. :param max_results: int (optional)   Maximum number of models desired. Default is 100. Max threshold is 1000. :param order_by: List[str] (optional)   List of columns for ordering search results, which can include model name and last updated timestamp   with an optional ""DESC"" or ""ASC"" annotation, where ""ASC"" is the default. Tiebreaks are done by model   name ASC. :param page_token: str (optional)   Pagination token to go to the next page based on a previous search query.  :returns: Iterator over :class:`Model`",model_registry,search,select,$.registered_models
ml.json,/api/2.0/mlflow/registered-models/set-tag,model_registry_set_model_tag,post,,"ml, model_registry","name, key, value",Sets a tag on a registered model.,"Sets a tag on a registered model.  :param name: str   Unique name of the model. :param key: str   Name of the tag. Maximum size depends on storage backend. If a tag with this name already exists,   its preexisting value will be replaced by the specified `value`. All storage backends are guaranteed   to support key values up to 250 bytes in size. :param value: str   String value of the tag being logged. Maximum size depends on storage backend. All storage backends   are guaranteed to support key values up to 5000 bytes in size.",model_registry,set_tag,exec,
ml.json,/api/2.0/mlflow/registered-models/update,model_registry_update_model,patch,UpdateModelResponse,"ml, model_registry","name, description",Updates a registered model.,"Updates a registered model.  :param name: str   Registered model unique name identifier. :param description: str (optional)   If provided, updates the description for this `registered_model`.  :returns: :class:`UpdateModelResponse`",model_registry,update,update,
ml.json,/api/2.0/mlflow/comments/create,model_registry_create_comment,post,CreateCommentResponse,"ml, model_registry","name, version, comment",Posts a comment on a model version. A comment can be submitted either by a user or programmatically to,"Posts a comment on a model version. A comment can be submitted either by a user or programmatically to display relevant information about the model. For example, test results or deployment errors.  :param name: str   Name of the model. :param version: str   Version of the model. :param comment: str   User-provided comment on the action.  :returns: :class:`CreateCommentResponse`",model_registry_comments,create,insert,
ml.json,/api/2.0/mlflow/comments/delete,model_registry_delete_comment,delete,,"ml, model_registry",id,Deletes a comment on a model version.,Deletes a comment on a model version.  :param id: str   Unique identifier of an activity,model_registry_comments,delete,exec,
ml.json,/api/2.0/mlflow/comments/update,model_registry_update_comment,patch,UpdateCommentResponse,"ml, model_registry","id, comment",Post an edit to a comment on a model version.,Post an edit to a comment on a model version.  :param id: str   Unique identifier of an activity :param comment: str   User-provided comment on the action.  :returns: :class:`UpdateCommentResponse`,model_registry_comments,update,update,
ml.json,/api/2.0/mlflow/model-versions/create,model_registry_create_model_version,post,CreateModelVersionResponse,"ml, model_registry","name, source, description, run_id, run_link, tags",Creates a model version.,"Creates a model version.  :param name: str   Register model under this name :param source: str   URI indicating the location of the model artifacts. :param description: str (optional)   Optional description for model version. :param run_id: str (optional)   MLflow run ID for correlation, if `source` was generated by an experiment run in MLflow tracking   server :param run_link: str (optional)   MLflow run link - this is the exact link of the run that generated this model version, potentially   hosted at another instance of MLflow. :param tags: List[:class:`ModelVersionTag`] (optional)   Additional metadata for model version.  :returns: :class:`CreateModelVersionResponse`",model_registry_model_versions,create,insert,
ml.json,/api/2.0/mlflow/model-versions/delete,model_registry_delete_model_version,delete,,"ml, model_registry","name, version",Deletes a model version.,Deletes a model version.  :param name: str   Name of the registered model :param version: str   Model version number,model_registry_model_versions,delete,exec,
ml.json,/api/2.0/mlflow/model-versions/delete-tag,model_registry_delete_model_version_tag,delete,,"ml, model_registry","name, version, key",Deletes a model version tag.,Deletes a model version tag.  :param name: str   Name of the registered model that the tag was logged under. :param version: str   Model version number that the tag was logged under. :param key: str   Name of the tag. The name must be an exact match; wild-card deletion is not supported. Maximum size   is 250 bytes.,model_registry_model_versions,delete_tag,exec,
ml.json,/api/2.0/mlflow/registered-models/get-latest-versions,model_registry_get_latest_versions,post,GetLatestVersionsResponse,"ml, model_registry","name, stages",Gets the latest version of a registered model.,Gets the latest version of a registered model.  :param name: str   Registered model unique name identifier. :param stages: List[str] (optional)   List of stages.  :returns: Iterator over :class:`ModelVersion`,model_registry_model_versions,get_latest,exec,$.model_versions
ml.json,/api/2.0/mlflow/model-versions/get,model_registry_get_model_version,get,GetModelVersionResponse,"ml, model_registry","name, version",Get a model version.,Get a model version.  :param name: str   Name of the registered model :param version: str   Model version number  :returns: :class:`GetModelVersionResponse`,model_registry_model_versions,get,select,
ml.json,/api/2.0/mlflow/model-versions/get-download-uri,model_registry_get_model_version_download_uri,get,GetModelVersionDownloadUriResponse,"ml, model_registry","name, version",Gets a URI to download the model version.,Gets a URI to download the model version.  :param name: str   Name of the registered model :param version: str   Model version number  :returns: :class:`GetModelVersionDownloadUriResponse`,model_registry_model_version_uri,get_download_uri,select,
ml.json,/api/2.0/mlflow/model-versions/search,model_registry_search_model_versions,get,GetLatestVersionsResponse,"ml, model_registry","filter, max_results, order_by, page_token",Searches for specific model versions based on the supplied __filter__.,"Searches for specific model versions based on the supplied __filter__.  :param filter: str (optional)   String filter condition, like ""name='my-model-name'"". Must be a single boolean condition, with   string values wrapped in single quotes. :param max_results: int (optional)   Maximum number of models desired. Max threshold is 10K. :param order_by: List[str] (optional)   List of columns to be ordered by including model name, version, stage with an optional ""DESC"" or   ""ASC"" annotation, where ""ASC"" is the default. Tiebreaks are done by latest stage transition   timestamp, followed by name ASC, followed by version DESC. :param page_token: str (optional)   Pagination token to go to next page based on previous search query.  :returns: Iterator over :class:`ModelVersion`",model_registry_model_versions,search,select,$.model_versions
ml.json,/api/2.0/mlflow/model-versions/set-tag,model_registry_set_model_version_tag,post,,"ml, model_registry","name, version, key, value",Sets a model version tag.,"Sets a model version tag.  :param name: str   Unique name of the model. :param version: str   Model version number. :param key: str   Name of the tag. Maximum size depends on storage backend. If a tag with this name already exists,   its preexisting value will be replaced by the specified `value`. All storage backends are guaranteed   to support key values up to 250 bytes in size. :param value: str   String value of the tag being logged. Maximum size depends on storage backend. All storage backends   are guaranteed to support key values up to 5000 bytes in size.",model_registry_model_versions,set_tag,exec,
ml.json,/api/2.0/mlflow/model-versions/update,model_registry_update_model_version,patch,UpdateModelVersionResponse,"ml, model_registry","name, version, description",Updates the model version.,"Updates the model version.  :param name: str   Name of the registered model :param version: str   Model version number :param description: str (optional)   If provided, updates the description for this `registered_model`.  :returns: :class:`UpdateModelVersionResponse`",model_registry_model_versions,update,update,
ml.json,/api/2.0/permissions/registered-models/{registered_model_id}/permissionLevels,model_registry_get_permission_levels,get,GetRegisteredModelPermissionLevelsResponse,"ml, model_registry",registered_model_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param registered_model_id: str   The registered model for which to get or manage permissions.  :returns: :class:`GetRegisteredModelPermissionLevelsResponse`,model_registry_permission_levels,get,select,
ml.json,/api/2.0/permissions/registered-models/{registered_model_id},model_registry_get_permissions,get,RegisteredModelPermissions,"ml, model_registry",registered_model_id,Gets the permissions of a registered model. Registered models can inherit permissions from their root,Gets the permissions of a registered model. Registered models can inherit permissions from their root object.  :param registered_model_id: str   The registered model for which to get or manage permissions.  :returns: :class:`RegisteredModelPermissions`,model_registry_permissions,get,select,
ml.json,/api/2.0/permissions/registered-models/{registered_model_id},model_registry_set_permissions,put,RegisteredModelPermissions,"ml, model_registry","registered_model_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param registered_model_id: str   The registered model for which to get or manage permissions. :param access_control_list: List[:class:`RegisteredModelAccessControlRequest`] (optional)  :returns: :class:`RegisteredModelPermissions`",model_registry_permissions,set,replace,
ml.json,/api/2.0/permissions/registered-models/{registered_model_id},model_registry_update_permissions,patch,RegisteredModelPermissions,"ml, model_registry","registered_model_id, access_control_list",Updates the permissions on a registered model. Registered models can inherit permissions from their,Updates the permissions on a registered model. Registered models can inherit permissions from their root object.  :param registered_model_id: str   The registered model for which to get or manage permissions. :param access_control_list: List[:class:`RegisteredModelAccessControlRequest`] (optional)  :returns: :class:`RegisteredModelPermissions`,model_registry_permissions,update,update,
ml.json,/api/2.0/mlflow/transition-requests/approve,model_registry_approve_transition_request,post,ApproveTransitionRequestResponse,"ml, model_registry","name, version, stage, archive_existing_versions, comment",Approves a model version stage transition request.,Approves a model version stage transition request.  :param name: str   Name of the model. :param version: str   Version of the model. :param stage: str   Target stage of the transition. Valid values are:    * `None`: The initial stage of a model version.    * `Staging`: Staging or pre-production stage.    * `Production`: Production stage.    * `Archived`: Archived stage. :param archive_existing_versions: bool   Specifies whether to archive all current model versions in the target stage. :param comment: str (optional)   User-provided comment on the action.  :returns: :class:`ApproveTransitionRequestResponse`,model_registry_transitions,approve,exec,
ml.json,/api/2.0/mlflow/transition-requests/create,model_registry_create_transition_request,post,CreateTransitionRequestResponse,"ml, model_registry","name, version, stage, comment",Creates a model version stage transition request.,Creates a model version stage transition request.  :param name: str   Name of the model. :param version: str   Version of the model. :param stage: str   Target stage of the transition. Valid values are:    * `None`: The initial stage of a model version.    * `Staging`: Staging or pre-production stage.    * `Production`: Production stage.    * `Archived`: Archived stage. :param comment: str (optional)   User-provided comment on the action.  :returns: :class:`CreateTransitionRequestResponse`,model_registry_transitions,create,insert,
ml.json,/api/2.0/mlflow/transition-requests/delete,model_registry_delete_transition_request,delete,DeleteTransitionRequestResponse,"ml, model_registry","name, version, stage, creator, comment",Cancels a model version stage transition request.,"Cancels a model version stage transition request.  :param name: str   Name of the model. :param version: str   Version of the model. :param stage: str   Target stage of the transition request. Valid values are:    * `None`: The initial stage of a model version.    * `Staging`: Staging or pre-production stage.    * `Production`: Production stage.    * `Archived`: Archived stage. :param creator: str   Username of the user who created this request. Of the transition requests matching the specified   details, only the one transition created by this user will be deleted. :param comment: str (optional)   User-provided comment on the action.  :returns: :class:`DeleteTransitionRequestResponse`",model_registry_transitions,delete,exec,
ml.json,/api/2.0/mlflow/transition-requests/list,model_registry_list_transition_requests,get,ListTransitionRequestsResponse,"ml, model_registry","name, version",Gets a list of all open stage transition requests for the model version.,Gets a list of all open stage transition requests for the model version.  :param name: str   Name of the registered model. :param version: str   Version of the model.  :returns: Iterator over :class:`Activity`,model_registry_transitions,list,select,$.requests
ml.json,/api/2.0/mlflow/transition-requests/reject,model_registry_reject_transition_request,post,RejectTransitionRequestResponse,"ml, model_registry","name, version, stage, comment",Rejects a model version stage transition request.,Rejects a model version stage transition request.  :param name: str   Name of the model. :param version: str   Version of the model. :param stage: str   Target stage of the transition. Valid values are:    * `None`: The initial stage of a model version.    * `Staging`: Staging or pre-production stage.    * `Production`: Production stage.    * `Archived`: Archived stage. :param comment: str (optional)   User-provided comment on the action.  :returns: :class:`RejectTransitionRequestResponse`,model_registry_transitions,reject,exec,
ml.json,/api/2.0/mlflow/databricks/model-versions/transition-stage,model_registry_transition_stage,post,TransitionStageResponse,"ml, model_registry","name, version, stage, archive_existing_versions, comment",Transition a model version's stage. This is a Databricks workspace version of the [MLflow endpoint],Transition a model version's stage. This is a Databricks workspace version of the [MLflow endpoint] that also accepts a comment associated with the transition to be recorded.  [MLflow endpoint]: https://www.mlflow.org/docs/latest/rest-api.html#transition-modelversion-stage  :param name: str   Name of the model. :param version: str   Version of the model. :param stage: str   Target stage of the transition. Valid values are:    * `None`: The initial stage of a model version.    * `Staging`: Staging or pre-production stage.    * `Production`: Production stage.    * `Archived`: Archived stage. :param archive_existing_versions: bool   Specifies whether to archive all current model versions in the target stage. :param comment: str (optional)   User-provided comment on the action.  :returns: :class:`TransitionStageResponse`,model_registry_transitions,transition,exec,
ml.json,/api/2.0/mlflow/registry-webhooks/create,model_registry_create_webhook,post,CreateWebhookResponse,"ml, model_registry","events, description, http_url_spec, job_spec, model_name, status",**NOTE:** This endpoint is in Public Preview. Creates a registry webhook.,"**NOTE:** This endpoint is in Public Preview. Creates a registry webhook.  :param events: List[:class:`RegistryWebhookEvent`]   Events that can trigger a registry webhook: * `MODEL_VERSION_CREATED`: A new model version was   created for the associated model.    * `MODEL_VERSION_TRANSITIONED_STAGE`: A model version’s stage was changed.    * `TRANSITION_REQUEST_CREATED`: A user requested a model version’s stage be transitioned.    * `COMMENT_CREATED`: A user wrote a comment on a registered model.    * `REGISTERED_MODEL_CREATED`: A new registered model was created. This event type can only be   specified for a registry-wide webhook, which can be created by not specifying a model name in the   create request.    * `MODEL_VERSION_TAG_SET`: A user set a tag on the model version.    * `MODEL_VERSION_TRANSITIONED_TO_STAGING`: A model version was transitioned to staging.    * `MODEL_VERSION_TRANSITIONED_TO_PRODUCTION`: A model version was transitioned to production.    * `MODEL_VERSION_TRANSITIONED_TO_ARCHIVED`: A model version was archived.    * `TRANSITION_REQUEST_TO_STAGING_CREATED`: A user requested a model version be transitioned to   staging.    * `TRANSITION_REQUEST_TO_PRODUCTION_CREATED`: A user requested a model version be transitioned to   production.    * `TRANSITION_REQUEST_TO_ARCHIVED_CREATED`: A user requested a model version be archived. :param description: str (optional)   User-specified description for the webhook. :param http_url_spec: :class:`HttpUrlSpec` (optional)   External HTTPS URL called on event trigger (by using a POST request). :param job_spec: :class:`JobSpec` (optional)   ID of the job that the webhook runs. :param model_name: str (optional)   If model name is not specified, a registry-wide webhook is created that listens for the specified   events across all versions of all registered models. :param status: :class:`RegistryWebhookStatus` (optional)   Enable or disable triggering the webhook, or put the webhook into test mode. The default is   `ACTIVE`: * `ACTIVE`: Webhook is triggered when an associated event happens.    * `DISABLED`: Webhook is not triggered.    * `TEST_MODE`: Webhook can be triggered through the test endpoint, but is not triggered on a real   event.  :returns: :class:`CreateWebhookResponse`",model_registry_webhooks,create,insert,
ml.json,/api/2.0/mlflow/registry-webhooks/delete,model_registry_delete_webhook,delete,,"ml, model_registry",id,**NOTE:** This endpoint is in Public Preview. Deletes a registry webhook.,**NOTE:** This endpoint is in Public Preview. Deletes a registry webhook.  :param id: str   Webhook ID required to delete a registry webhook.,model_registry_webhooks,delete,exec,
ml.json,/api/2.0/mlflow/registry-webhooks/list,model_registry_list_webhooks,get,ListRegistryWebhooks,"ml, model_registry","events, max_results, model_name, page_token",**NOTE:** This endpoint is in Public Preview. Lists all registry webhooks.,"**NOTE:** This endpoint is in Public Preview. Lists all registry webhooks.  :param events: List[:class:`RegistryWebhookEvent`] (optional)   Events that trigger the webhook. * `MODEL_VERSION_CREATED`: A new model version was created for the   associated model.    * `MODEL_VERSION_TRANSITIONED_STAGE`: A model version’s stage was changed.    * `TRANSITION_REQUEST_CREATED`: A user requested a model version’s stage be transitioned.    * `COMMENT_CREATED`: A user wrote a comment on a registered model.    * `REGISTERED_MODEL_CREATED`: A new registered model was created. This event type can only be   specified for a registry-wide webhook, which can be created by not specifying a model name in the   create request.    * `MODEL_VERSION_TAG_SET`: A user set a tag on the model version.    * `MODEL_VERSION_TRANSITIONED_TO_STAGING`: A model version was transitioned to staging.    * `MODEL_VERSION_TRANSITIONED_TO_PRODUCTION`: A model version was transitioned to production.    * `MODEL_VERSION_TRANSITIONED_TO_ARCHIVED`: A model version was archived.    * `TRANSITION_REQUEST_TO_STAGING_CREATED`: A user requested a model version be transitioned to   staging.    * `TRANSITION_REQUEST_TO_PRODUCTION_CREATED`: A user requested a model version be transitioned to   production.    * `TRANSITION_REQUEST_TO_ARCHIVED_CREATED`: A user requested a model version be archived.    If `events` is specified, any webhook with one or more of the specified trigger events is included   in the output. If `events` is not specified, webhooks of all event types are included in the output. :param max_results: int (optional) :param model_name: str (optional)   Registered model name If not specified, all webhooks associated with the specified events are   listed, regardless of their associated model. :param page_token: str (optional)   Token indicating the page of artifact results to fetch  :returns: Iterator over :class:`RegistryWebhook`",model_registry_webhooks,list,select,$.webhooks
ml.json,/api/2.0/mlflow/registry-webhooks/test,model_registry_test_registry_webhook,post,TestRegistryWebhookResponse,"ml, model_registry","id, event",**NOTE:** This endpoint is in Public Preview. Tests a registry webhook.,"**NOTE:** This endpoint is in Public Preview. Tests a registry webhook.  :param id: str   Webhook ID :param event: :class:`RegistryWebhookEvent` (optional)   If `event` is specified, the test trigger uses the specified event. If `event` is not specified, the   test trigger uses a randomly chosen event associated with the webhook.  :returns: :class:`TestRegistryWebhookResponse`",model_registry_webhooks,test,exec,
ml.json,/api/2.0/mlflow/registry-webhooks/update,model_registry_update_webhook,patch,UpdateWebhookResponse,"ml, model_registry","id, description, events, http_url_spec, job_spec, status",**NOTE:** This endpoint is in Public Preview. Updates a registry webhook.,"**NOTE:** This endpoint is in Public Preview. Updates a registry webhook.  :param id: str   Webhook ID :param description: str (optional)   User-specified description for the webhook. :param events: List[:class:`RegistryWebhookEvent`] (optional)   Events that can trigger a registry webhook: * `MODEL_VERSION_CREATED`: A new model version was   created for the associated model.    * `MODEL_VERSION_TRANSITIONED_STAGE`: A model version’s stage was changed.    * `TRANSITION_REQUEST_CREATED`: A user requested a model version’s stage be transitioned.    * `COMMENT_CREATED`: A user wrote a comment on a registered model.    * `REGISTERED_MODEL_CREATED`: A new registered model was created. This event type can only be   specified for a registry-wide webhook, which can be created by not specifying a model name in the   create request.    * `MODEL_VERSION_TAG_SET`: A user set a tag on the model version.    * `MODEL_VERSION_TRANSITIONED_TO_STAGING`: A model version was transitioned to staging.    * `MODEL_VERSION_TRANSITIONED_TO_PRODUCTION`: A model version was transitioned to production.    * `MODEL_VERSION_TRANSITIONED_TO_ARCHIVED`: A model version was archived.    * `TRANSITION_REQUEST_TO_STAGING_CREATED`: A user requested a model version be transitioned to   staging.    * `TRANSITION_REQUEST_TO_PRODUCTION_CREATED`: A user requested a model version be transitioned to   production.    * `TRANSITION_REQUEST_TO_ARCHIVED_CREATED`: A user requested a model version be archived. :param http_url_spec: :class:`HttpUrlSpec` (optional) :param job_spec: :class:`JobSpec` (optional) :param status: :class:`RegistryWebhookStatus` (optional)  :returns: :class:`UpdateWebhookResponse`",model_registry_webhooks,update,update,
oauth2.json,/api/2.0/accounts/servicePrincipals/{service_principal_id}/credentials/secrets,service_principal_secrets_proxy_create,post,CreateServicePrincipalSecretResponse,"oauth2, service_principal_secrets_proxy","service_principal_id, lifetime",Create a secret for the given service principal.,"Create a secret for the given service principal.  :param service_principal_id: str   The service principal ID. :param lifetime: str (optional)   The lifetime of the secret in seconds. If this parameter is not provided, the secret will have a   default lifetime of 730 days (63072000s).  :returns: :class:`CreateServicePrincipalSecretResponse`",service_principal_secrets,create,insert,
oauth2.json,/api/2.0/accounts/servicePrincipals/{service_principal_id}/credentials/secrets,service_principal_secrets_proxy_list,get,ListServicePrincipalSecretsResponse,"oauth2, service_principal_secrets_proxy","service_principal_id, page_size, page_token",List all secrets associated with the given service principal. This operation only returns information,"List all secrets associated with the given service principal. This operation only returns information about the secrets themselves and does not include the secret values.  :param service_principal_id: str   The service principal ID. :param page_size: int (optional) :param page_token: str (optional)   An opaque page token which was the `next_page_token` in the response of the previous request to list   the secrets for this service principal. Provide this token to retrieve the next page of secret   entries. When providing a `page_token`, all other parameters provided to the request must match the   previous request. To list all of the secrets for a service principal, it is necessary to continue   requesting pages of entries until the response contains no `next_page_token`. Note that the number   of entries returned must not be used to determine when the listing is complete.  :returns: Iterator over :class:`SecretInfo`",service_principal_secrets,list,select,$.secrets
oauth2.json,/api/2.0/accounts/servicePrincipals/{service_principal_id}/credentials/secrets/{secret_id},service_principal_secrets_proxy_delete,delete,,"oauth2, service_principal_secrets_proxy","service_principal_id, secret_id",Delete a secret from the given service principal.,Delete a secret from the given service principal.  :param service_principal_id: str   The service principal ID. :param secret_id: str   The secret ID.,service_principal_secrets,delete,delete,
pipelines.json,/api/2.0/pipelines/{pipeline_id}/clone,pipelines_clone,post,ClonePipelineResponse,pipelines,"pipeline_id, allow_duplicate_names, budget_policy_id, catalog, channel, clone_mode, clusters, configuration, continuous, deployment, development, edition, environment, event_log, expected_last_modified, filters, gateway_definition, id, ingestion_definition, libraries, name, notifications, photon, restart_window, root_path, schema, serverless, storage, tags, target, trigger, usage_policy_id",Creates a new pipeline using Unity Catalog from a pipeline using Hive Metastore. This method returns,"Creates a new pipeline using Unity Catalog from a pipeline using Hive Metastore. This method returns the ID of the newly created clone. Additionally, this method starts an update for the newly created pipeline.  :param pipeline_id: str   Source pipeline to clone from :param allow_duplicate_names: bool (optional)   If false, deployment will fail if name conflicts with that of another pipeline. :param budget_policy_id: str (optional)   Budget policy of this pipeline. :param catalog: str (optional)   A catalog in Unity Catalog to publish data from this pipeline to. If `target` is specified, tables   in this pipeline are published to a `target` schema inside `catalog` (for example,   `catalog`.`target`.`table`). If `target` is not specified, no data is published to Unity Catalog. :param channel: str (optional)   DLT Release Channel that specifies which version to use. :param clone_mode: :class:`CloneMode` (optional)   The type of clone to perform. Currently, only deep copies are supported :param clusters: List[:class:`PipelineCluster`] (optional)   Cluster settings for this pipeline deployment. :param configuration: Dict[str,str] (optional)   String-String configuration for this pipeline execution. :param continuous: bool (optional)   Whether the pipeline is continuous or triggered. This replaces `trigger`. :param deployment: :class:`PipelineDeployment` (optional)   Deployment type of this pipeline. :param development: bool (optional)   Whether the pipeline is in Development mode. Defaults to false. :param edition: str (optional)   Pipeline product edition. :param environment: :class:`PipelinesEnvironment` (optional)   Environment specification for this pipeline used to install dependencies. :param event_log: :class:`EventLogSpec` (optional)   Event log configuration for this pipeline :param expected_last_modified: int (optional)   If present, the last-modified time of the pipeline settings before the clone. If the settings were   modified after that time, then the request will fail with a conflict. :param filters: :class:`Filters` (optional)   Filters on which Pipeline packages to include in the deployed graph. :param gateway_definition: :class:`IngestionGatewayPipelineDefinition` (optional)   The definition of a gateway pipeline to support change data capture. :param id: str (optional)   Unique identifier for this pipeline. :param ingestion_definition: :class:`IngestionPipelineDefinition` (optional)   The configuration for a managed ingestion pipeline. These settings cannot be used with the   'libraries', 'schema', 'target', or 'catalog' settings. :param libraries: List[:class:`PipelineLibrary`] (optional)   Libraries or code needed by this deployment. :param name: str (optional)   Friendly identifier for this pipeline. :param notifications: List[:class:`Notifications`] (optional)   List of notification settings for this pipeline. :param photon: bool (optional)   Whether Photon is enabled for this pipeline. :param restart_window: :class:`RestartWindow` (optional)   Restart window of this pipeline. :param root_path: str (optional)   Root path for this pipeline. This is used as the root directory when editing the pipeline in the   Databricks user interface and it is added to sys.path when executing Python sources during pipeline   execution. :param schema: str (optional)   The default schema (database) where tables are read from or published to. :param serverless: bool (optional)   Whether serverless compute is enabled for this pipeline. :param storage: str (optional)   DBFS root directory for storing checkpoints and tables. :param tags: Dict[str,str] (optional)   A map of tags associated with the pipeline. These are forwarded to the cluster as cluster tags, and   are therefore subject to the same limitations. A maximum of 25 tags can be added to the pipeline. :param target: str (optional)   Target schema (database) to add tables in this pipeline to. Exactly one of `schema` or `target` must   be specified. To publish to Unity Catalog, also specify `catalog`. This legacy field is deprecated   for pipeline creation in favor of the `schema` field. :param trigger: :class:`PipelineTrigger` (optional)   Which pipeline trigger to use. Deprecated: Use `continuous` instead. :param usage_policy_id: str (optional)   Usage policy of this pipeline.  :returns: :class:`ClonePipelineResponse`",pipelines,clone,exec,
pipelines.json,/api/2.0/pipelines,pipelines_create,post,CreatePipelineResponse,pipelines,"allow_duplicate_names, budget_policy_id, catalog, channel, clusters, configuration, continuous, deployment, development, dry_run, edition, environment, event_log, filters, gateway_definition, id, ingestion_definition, libraries, name, notifications, photon, restart_window, root_path, run_as, schema, serverless, storage, tags, target, trigger, usage_policy_id","Creates a new data processing pipeline based on the requested configuration. If successful, this","Creates a new data processing pipeline based on the requested configuration. If successful, this method returns the ID of the new pipeline.  :param allow_duplicate_names: bool (optional)   If false, deployment will fail if name conflicts with that of another pipeline. :param budget_policy_id: str (optional)   Budget policy of this pipeline. :param catalog: str (optional)   A catalog in Unity Catalog to publish data from this pipeline to. If `target` is specified, tables   in this pipeline are published to a `target` schema inside `catalog` (for example,   `catalog`.`target`.`table`). If `target` is not specified, no data is published to Unity Catalog. :param channel: str (optional)   DLT Release Channel that specifies which version to use. :param clusters: List[:class:`PipelineCluster`] (optional)   Cluster settings for this pipeline deployment. :param configuration: Dict[str,str] (optional)   String-String configuration for this pipeline execution. :param continuous: bool (optional)   Whether the pipeline is continuous or triggered. This replaces `trigger`. :param deployment: :class:`PipelineDeployment` (optional)   Deployment type of this pipeline. :param development: bool (optional)   Whether the pipeline is in Development mode. Defaults to false. :param dry_run: bool (optional) :param edition: str (optional)   Pipeline product edition. :param environment: :class:`PipelinesEnvironment` (optional)   Environment specification for this pipeline used to install dependencies. :param event_log: :class:`EventLogSpec` (optional)   Event log configuration for this pipeline :param filters: :class:`Filters` (optional)   Filters on which Pipeline packages to include in the deployed graph. :param gateway_definition: :class:`IngestionGatewayPipelineDefinition` (optional)   The definition of a gateway pipeline to support change data capture. :param id: str (optional)   Unique identifier for this pipeline. :param ingestion_definition: :class:`IngestionPipelineDefinition` (optional)   The configuration for a managed ingestion pipeline. These settings cannot be used with the   'libraries', 'schema', 'target', or 'catalog' settings. :param libraries: List[:class:`PipelineLibrary`] (optional)   Libraries or code needed by this deployment. :param name: str (optional)   Friendly identifier for this pipeline. :param notifications: List[:class:`Notifications`] (optional)   List of notification settings for this pipeline. :param photon: bool (optional)   Whether Photon is enabled for this pipeline. :param restart_window: :class:`RestartWindow` (optional)   Restart window of this pipeline. :param root_path: str (optional)   Root path for this pipeline. This is used as the root directory when editing the pipeline in the   Databricks user interface and it is added to sys.path when executing Python sources during pipeline   execution. :param run_as: :class:`RunAs` (optional) :param schema: str (optional)   The default schema (database) where tables are read from or published to. :param serverless: bool (optional)   Whether serverless compute is enabled for this pipeline. :param storage: str (optional)   DBFS root directory for storing checkpoints and tables. :param tags: Dict[str,str] (optional)   A map of tags associated with the pipeline. These are forwarded to the cluster as cluster tags, and   are therefore subject to the same limitations. A maximum of 25 tags can be added to the pipeline. :param target: str (optional)   Target schema (database) to add tables in this pipeline to. Exactly one of `schema` or `target` must   be specified. To publish to Unity Catalog, also specify `catalog`. This legacy field is deprecated   for pipeline creation in favor of the `schema` field. :param trigger: :class:`PipelineTrigger` (optional)   Which pipeline trigger to use. Deprecated: Use `continuous` instead. :param usage_policy_id: str (optional)   Usage policy of this pipeline.  :returns: :class:`CreatePipelineResponse`",pipelines,create,insert,
pipelines.json,/api/2.0/pipelines,pipelines_list_pipelines,get,ListPipelinesResponse,pipelines,"filter, max_results, order_by, page_token",Lists pipelines defined in the Spark Declarative Pipelines system.,"Lists pipelines defined in the Spark Declarative Pipelines system.  :param filter: str (optional)   Select a subset of results based on the specified criteria. The supported filters are:    * `notebook='<path>'` to select pipelines that reference the provided notebook path. * `name LIKE   '[pattern]'` to select pipelines with a name that matches pattern. Wildcards are supported, for   example: `name LIKE '%shopping%'`    Composite filters are not supported. This field is optional. :param max_results: int (optional)   The maximum number of entries to return in a single page. The system may return fewer than   max_results events in a response, even if there are more events available. This field is optional.   The default value is 25. The maximum value is 100. An error is returned if the value of max_results   is greater than 100. :param order_by: List[str] (optional)   A list of strings specifying the order of results. Supported order_by fields are id and name. The   default is id asc. This field is optional. :param page_token: str (optional)   Page token returned by previous call  :returns: Iterator over :class:`PipelineStateInfo`",pipelines,list,select,$.statuses
pipelines.json,/api/2.0/pipelines/{pipeline_id},pipelines_delete,delete,,pipelines,"pipeline_id, force","Deletes a pipeline. If the pipeline publishes to Unity Catalog, pipeline deletion will cascade to all","Deletes a pipeline. If the pipeline publishes to Unity Catalog, pipeline deletion will cascade to all pipeline tables. Please reach out to Databricks support for assistance to undo this action.  :param pipeline_id: str :param force: bool (optional)   If true, deletion will proceed even if resource cleanup fails. By default, deletion will fail if   resources cleanup is required but fails.",pipelines,delete,delete,
pipelines.json,/api/2.0/pipelines/{pipeline_id},pipelines_get,get,GetPipelineResponse,pipelines,pipeline_id,Get a pipeline.,Get a pipeline.  :param pipeline_id: str  :returns: :class:`GetPipelineResponse`,pipelines,get,select,
pipelines.json,/api/2.0/pipelines/{pipeline_id},pipelines_update,put,,pipelines,"pipeline_id, allow_duplicate_names, budget_policy_id, catalog, channel, clusters, configuration, continuous, deployment, development, edition, environment, event_log, expected_last_modified, filters, gateway_definition, id, ingestion_definition, libraries, name, notifications, photon, restart_window, root_path, run_as, schema, serverless, storage, tags, target, trigger, usage_policy_id",Updates a pipeline with the supplied configuration.,"Updates a pipeline with the supplied configuration.  :param pipeline_id: str   Unique identifier for this pipeline. :param allow_duplicate_names: bool (optional)   If false, deployment will fail if name has changed and conflicts the name of another pipeline. :param budget_policy_id: str (optional)   Budget policy of this pipeline. :param catalog: str (optional)   A catalog in Unity Catalog to publish data from this pipeline to. If `target` is specified, tables   in this pipeline are published to a `target` schema inside `catalog` (for example,   `catalog`.`target`.`table`). If `target` is not specified, no data is published to Unity Catalog. :param channel: str (optional)   DLT Release Channel that specifies which version to use. :param clusters: List[:class:`PipelineCluster`] (optional)   Cluster settings for this pipeline deployment. :param configuration: Dict[str,str] (optional)   String-String configuration for this pipeline execution. :param continuous: bool (optional)   Whether the pipeline is continuous or triggered. This replaces `trigger`. :param deployment: :class:`PipelineDeployment` (optional)   Deployment type of this pipeline. :param development: bool (optional)   Whether the pipeline is in Development mode. Defaults to false. :param edition: str (optional)   Pipeline product edition. :param environment: :class:`PipelinesEnvironment` (optional)   Environment specification for this pipeline used to install dependencies. :param event_log: :class:`EventLogSpec` (optional)   Event log configuration for this pipeline :param expected_last_modified: int (optional)   If present, the last-modified time of the pipeline settings before the edit. If the settings were   modified after that time, then the request will fail with a conflict. :param filters: :class:`Filters` (optional)   Filters on which Pipeline packages to include in the deployed graph. :param gateway_definition: :class:`IngestionGatewayPipelineDefinition` (optional)   The definition of a gateway pipeline to support change data capture. :param id: str (optional)   Unique identifier for this pipeline. :param ingestion_definition: :class:`IngestionPipelineDefinition` (optional)   The configuration for a managed ingestion pipeline. These settings cannot be used with the   'libraries', 'schema', 'target', or 'catalog' settings. :param libraries: List[:class:`PipelineLibrary`] (optional)   Libraries or code needed by this deployment. :param name: str (optional)   Friendly identifier for this pipeline. :param notifications: List[:class:`Notifications`] (optional)   List of notification settings for this pipeline. :param photon: bool (optional)   Whether Photon is enabled for this pipeline. :param restart_window: :class:`RestartWindow` (optional)   Restart window of this pipeline. :param root_path: str (optional)   Root path for this pipeline. This is used as the root directory when editing the pipeline in the   Databricks user interface and it is added to sys.path when executing Python sources during pipeline   execution. :param run_as: :class:`RunAs` (optional) :param schema: str (optional)   The default schema (database) where tables are read from or published to. :param serverless: bool (optional)   Whether serverless compute is enabled for this pipeline. :param storage: str (optional)   DBFS root directory for storing checkpoints and tables. :param tags: Dict[str,str] (optional)   A map of tags associated with the pipeline. These are forwarded to the cluster as cluster tags, and   are therefore subject to the same limitations. A maximum of 25 tags can be added to the pipeline. :param target: str (optional)   Target schema (database) to add tables in this pipeline to. Exactly one of `schema` or `target` must   be specified. To publish to Unity Catalog, also specify `catalog`. This legacy field is deprecated   for pipeline creation in favor of the `schema` field. :param trigger: :class:`PipelineTrigger` (optional)   Which pipeline trigger to use. Deprecated: Use `continuous` instead. :param usage_policy_id: str (optional)   Usage policy of this pipeline.",pipelines,update,replace,
pipelines.json,/api/2.0/permissions/pipelines/{pipeline_id}/permissionLevels,pipelines_get_permission_levels,get,GetPipelinePermissionLevelsResponse,pipelines,pipeline_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param pipeline_id: str   The pipeline for which to get or manage permissions.  :returns: :class:`GetPipelinePermissionLevelsResponse`,pipeline_permission_levels,get,select,
pipelines.json,/api/2.0/permissions/pipelines/{pipeline_id},pipelines_get_permissions,get,PipelinePermissions,pipelines,pipeline_id,Gets the permissions of a pipeline. Pipelines can inherit permissions from their root object.,Gets the permissions of a pipeline. Pipelines can inherit permissions from their root object.  :param pipeline_id: str   The pipeline for which to get or manage permissions.  :returns: :class:`PipelinePermissions`,pipeline_permissions,get,select,
pipelines.json,/api/2.0/permissions/pipelines/{pipeline_id},pipelines_set_permissions,put,PipelinePermissions,pipelines,"pipeline_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param pipeline_id: str   The pipeline for which to get or manage permissions. :param access_control_list: List[:class:`PipelineAccessControlRequest`] (optional)  :returns: :class:`PipelinePermissions`",pipeline_permissions,set,replace,
pipelines.json,/api/2.0/permissions/pipelines/{pipeline_id},pipelines_update_permissions,patch,PipelinePermissions,pipelines,"pipeline_id, access_control_list",Updates the permissions on a pipeline. Pipelines can inherit permissions from their root object.,Updates the permissions on a pipeline. Pipelines can inherit permissions from their root object.  :param pipeline_id: str   The pipeline for which to get or manage permissions. :param access_control_list: List[:class:`PipelineAccessControlRequest`] (optional)  :returns: :class:`PipelinePermissions`,pipeline_permissions,update,update,
pipelines.json,/api/2.0/pipelines/{pipeline_id}/updates/{update_id},pipelines_get_update,get,GetUpdateResponse,pipelines,"pipeline_id, update_id",Gets an update from an active pipeline.,Gets an update from an active pipeline.  :param pipeline_id: str   The ID of the pipeline. :param update_id: str   The ID of the update.  :returns: :class:`GetUpdateResponse`,pipeline_updates,get,select,
pipelines.json,/api/2.0/pipelines/{pipeline_id}/events,pipelines_list_pipeline_events,get,ListPipelineEventsResponse,pipelines,"pipeline_id, filter, max_results, order_by, page_token",Retrieves events for a pipeline.,"Retrieves events for a pipeline.  :param pipeline_id: str   The pipeline to return events for. :param filter: str (optional)   Criteria to select a subset of results, expressed using a SQL-like syntax. The supported filters   are: 1. level='INFO' (or WARN or ERROR) 2. level in ('INFO', 'WARN') 3. id='[event-id]' 4. timestamp   > 'TIMESTAMP' (or >=,<,<=,=)    Composite expressions are supported, for example: level in ('ERROR', 'WARN') AND timestamp>   '2021-07-22T06:37:33.083Z' :param max_results: int (optional)   Max number of entries to return in a single page. The system may return fewer than max_results   events in a response, even if there are more events available. :param order_by: List[str] (optional)   A string indicating a sort order by timestamp for the results, for example, [""timestamp asc""]. The   sort order can be ascending or descending. By default, events are returned in descending order by   timestamp. :param page_token: str (optional)   Page token returned by previous call. This field is mutually exclusive with all fields in this   request except max_results. An error is returned if any fields other than max_results are set when   this field is set.  :returns: Iterator over :class:`PipelineEvent`",pipeline_events,list,select,$.events
pipelines.json,/api/2.0/pipelines/{pipeline_id}/updates,pipelines_list_updates,get,ListUpdatesResponse,pipelines,"pipeline_id, max_results, page_token, until_update_id",List updates for an active pipeline.,"List updates for an active pipeline.  :param pipeline_id: str   The pipeline to return updates for. :param max_results: int (optional)   Max number of entries to return in a single page. :param page_token: str (optional)   Page token returned by previous call :param until_update_id: str (optional)   If present, returns updates until and including this update_id.  :returns: :class:`ListUpdatesResponse`",pipeline_updates,list,select,
pipelines.json,/api/2.0/pipelines/{pipeline_id}/updates,pipelines_start_update,post,StartUpdateResponse,pipelines,"pipeline_id, cause, full_refresh, full_refresh_selection, refresh_selection, rewind_spec, validate_only","Starts a new update for the pipeline. If there is already an active update for the pipeline, the","Starts a new update for the pipeline. If there is already an active update for the pipeline, the request will fail and the active update will remain running.  :param pipeline_id: str :param cause: :class:`StartUpdateCause` (optional) :param full_refresh: bool (optional)   If true, this update will reset all tables before running. :param full_refresh_selection: List[str] (optional)   A list of tables to update with fullRefresh. If both refresh_selection and full_refresh_selection   are empty, this is a full graph update. Full Refresh on a table means that the states of the table   will be reset before the refresh. :param refresh_selection: List[str] (optional)   A list of tables to update without fullRefresh. If both refresh_selection and full_refresh_selection   are empty, this is a full graph update. Full Refresh on a table means that the states of the table   will be reset before the refresh. :param rewind_spec: :class:`RewindSpec` (optional)   The information about the requested rewind operation. If specified this is a rewind mode update. :param validate_only: bool (optional)   If true, this update only validates the correctness of pipeline source code but does not materialize   or publish any datasets.  :returns: :class:`StartUpdateResponse`",pipeline_updates,start,exec,
pipelines.json,/api/2.0/pipelines/{pipeline_id}/stop,pipelines_stop,post,GetPipelineResponse,pipelines,pipeline_id,"Stops the pipeline by canceling the active update. If there is no active update for the pipeline, this","Stops the pipeline by canceling the active update. If there is no active update for the pipeline, this request is a no-op.  :param pipeline_id: str  :returns:   Long-running operation waiter for :class:`GetPipelineResponse`.   See :method:wait_get_pipeline_idle for more details.",pipelines,stop,exec,
postgres.json,/api/2.0/postgres/{parent}/branches,postgres_create_branch,post,,postgres,"parent, branch_id, branch",Creates a new database branch in the project.,"Creates a new database branch in the project.  :param parent: str   The Project where this Branch will be created. Format: projects/{project_id} :param branch: :class:`Branch`   The Branch to create. :param branch_id: str   The ID to use for the Branch. This becomes the final component of the branch's resource name. The ID   is required and must be 1-63 characters long, start with a lowercase letter, and contain only   lowercase letters, numbers, and hyphens. For example, `development` becomes   `projects/my-app/branches/development`.  :returns: :class:`Operation`",postgres_branches,create,insert,
postgres.json,/api/2.0/postgres/{parent}/branches,postgres_list_branches,get,ListBranchesResponse,postgres,"parent, page_size, page_token",Returns a paginated list of database branches in the project.,"Returns a paginated list of database branches in the project.  :param parent: str   The Project that owns this collection of branches. Format: projects/{project_id} :param page_size: int (optional)   Upper bound for items returned. Cannot be negative. :param page_token: str (optional)   Page token from a previous response. If not provided, returns the first page.  :returns: Iterator over :class:`Branch`",postgres_branches,list,select,$.branches
postgres.json,/api/2.0/postgres/{parent}/endpoints,postgres_create_endpoint,post,,postgres,"parent, endpoint_id, endpoint",Creates a new compute endpoint in the branch.,"Creates a new compute endpoint in the branch.  :param parent: str   The Branch where this Endpoint will be created. Format: projects/{project_id}/branches/{branch_id} :param endpoint: :class:`Endpoint`   The Endpoint to create. :param endpoint_id: str   The ID to use for the Endpoint. This becomes the final component of the endpoint's resource name.   The ID is required and must be 1-63 characters long, start with a lowercase letter, and contain only   lowercase letters, numbers, and hyphens. For example, `primary` becomes   `projects/my-app/branches/development/endpoints/primary`.  :returns: :class:`Operation`",postgres_endpoints,create,insert,
postgres.json,/api/2.0/postgres/{parent}/endpoints,postgres_list_endpoints,get,ListEndpointsResponse,postgres,"parent, page_size, page_token",Returns a paginated list of compute endpoints in the branch.,"Returns a paginated list of compute endpoints in the branch.  :param parent: str   The Branch that owns this collection of endpoints. Format:   projects/{project_id}/branches/{branch_id} :param page_size: int (optional)   Upper bound for items returned. Cannot be negative. :param page_token: str (optional)   Page token from a previous response. If not provided, returns the first page.  :returns: Iterator over :class:`Endpoint`",postgres_endpoints,list,select,$.endpoints
postgres.json,/api/2.0/postgres/projects,postgres_create_project,post,,postgres,"project_id, project","Creates a new Lakebase Autoscaling Postgres database project, which contains branches and compute","Creates a new Lakebase Autoscaling Postgres database project, which contains branches and compute endpoints.  :param project: :class:`Project`   The Project to create. :param project_id: str   The ID to use for the Project. This becomes the final component of the project's resource name. The   ID is required and must be 1-63 characters long, start with a lowercase letter, and contain only   lowercase letters, numbers, and hyphens. For example, `my-app` becomes `projects/my-app`.  :returns: :class:`Operation`",postgres_projects,create,insert,
postgres.json,/api/2.0/postgres/projects,postgres_list_projects,get,ListProjectsResponse,postgres,"page_size, page_token",Returns a paginated list of database projects in the workspace that the user has permission to access.,"Returns a paginated list of database projects in the workspace that the user has permission to access.  :param page_size: int (optional)   Upper bound for items returned. Cannot be negative. :param page_token: str (optional)   Page token from a previous response. If not provided, returns the first page.  :returns: Iterator over :class:`Project`",postgres_projects,list,select,$.projects
postgres.json,/api/2.0/postgres/{parent}/roles,postgres_create_role,post,,postgres,"parent, role_id, role",Creates a new Postgres role in the branch.,"Creates a new Postgres role in the branch.  :param parent: str   The Branch where this Role is created. Format: projects/{project_id}/branches/{branch_id} :param role: :class:`Role`   The desired specification of a Role. :param role_id: str (optional)   The ID to use for the Role, which will become the final component of the role's resource name. This   ID becomes the role in Postgres.    This value should be 4-63 characters, and valid characters are lowercase letters, numbers, and   hyphens, as defined by RFC 1123.    If role_id is not specified in the request, it is generated automatically.  :returns: :class:`Operation`",postgres_roles,create,insert,
postgres.json,/api/2.0/postgres/{parent}/roles,postgres_list_roles,get,ListRolesResponse,postgres,"parent, page_size, page_token",Returns a paginated list of Postgres roles in the branch.,"Returns a paginated list of Postgres roles in the branch.  :param parent: str   The Branch that owns this collection of roles. Format: projects/{project_id}/branches/{branch_id} :param page_size: int (optional)   Upper bound for items returned. Cannot be negative. :param page_token: str (optional)   Page token from a previous response. If not provided, returns the first page.  :returns: Iterator over :class:`Role`",postgres_roles,list,select,$.roles
postgres.json,/api/2.0/postgres/{name},postgres_delete_role,delete,,postgres,"name, reassign_owned_to",Deletes the specified Postgres role.,"Deletes the specified Postgres role.  :param name: str   The full resource path of the role to delete. Format:   projects/{project_id}/branches/{branch_id}/roles/{role_id} :param reassign_owned_to: str (optional)   Reassign objects. If this is set, all objects owned by the role are reassigned to the role specified   in this parameter.    NOTE: setting this requires spinning up a compute to succeed, since it involves running SQL queries.    TODO: #LKB-7187 implement reassign_owned_to on LBM side. This might end-up being a synchronous query   when this parameter is used.  :returns: :class:`Operation`",postgres_roles,delete,delete,
postgres.json,/api/2.0/postgres/{name},postgres_get_role,get,Role,postgres,name,"Retrieves information about the specified Postgres role, including its authentication method and","Retrieves information about the specified Postgres role, including its authentication method and permissions.  :param name: str   The full resource path of the role to retrieve. Format:   projects/{project_id}/branches/{branch_id}/roles/{role_id}  :returns: :class:`Role`",postgres_roles,get,select,
postgres.json,/api/2.0/postgres/{name},postgres_update_project,patch,,postgres,"name, update_mask, project",Updates the specified database project.,"Updates the specified database project.  :param name: str   Output only. The full resource path of the project. Format: projects/{project_id} :param project: :class:`Project`   The Project to update.    The project's `name` field is used to identify the project to update. Format: projects/{project_id} :param update_mask: FieldMask   The list of fields to update. If unspecified, all fields will be updated when possible.  :returns: :class:`Operation`",postgres_projects,update,update,
postgres.json,/api/2.0/postgres/credentials,postgres_generate_database_credential,post,DatabaseCredential,postgres,"endpoint, claims",Generate OAuth credentials for a Postgres database.,Generate OAuth credentials for a Postgres database.  :param endpoint: str   This field is not yet supported. The endpoint for which this credential will be generated. Format:   projects/{project_id}/branches/{branch_id}/endpoints/{endpoint_id} :param claims: List[:class:`RequestedClaims`] (optional)   The returned token will be scoped to UC tables with the specified permissions.  :returns: :class:`DatabaseCredential`,postgres_credentials,generate,exec,
qualitymonitorv2.json,/api/2.0/quality-monitors,quality_monitor_v2_create_quality_monitor,post,QualityMonitor,"qualitymonitorv2, quality_monitor_v2",quality_monitor,[DEPRECATED] Create a quality monitor on UC object. Use Data Quality Monitoring API instead.,[DEPRECATED] Create a quality monitor on UC object. Use Data Quality Monitoring API instead.  :param quality_monitor: :class:`QualityMonitor`  :returns: :class:`QualityMonitor`,quality_monitor_v2,create,insert,
qualitymonitorv2.json,/api/2.0/quality-monitors,quality_monitor_v2_list_quality_monitor,get,ListQualityMonitorResponse,"qualitymonitorv2, quality_monitor_v2","page_size, page_token",[DEPRECATED] (Unimplemented) List quality monitors. Use Data Quality Monitoring API instead.,[DEPRECATED] (Unimplemented) List quality monitors. Use Data Quality Monitoring API instead.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`QualityMonitor`,quality_monitor_v2,list,select,$.quality_monitors
qualitymonitorv2.json,/api/2.0/quality-monitors/{object_type}/{object_id},quality_monitor_v2_delete_quality_monitor,delete,,"qualitymonitorv2, quality_monitor_v2","object_type, object_id",[DEPRECATED] Delete a quality monitor on UC object. Use Data Quality Monitoring API instead.,"[DEPRECATED] Delete a quality monitor on UC object. Use Data Quality Monitoring API instead.  :param object_type: str   The type of the monitored object. Can be one of the following: schema. :param object_id: str   The uuid of the request object. For example, schema id.",quality_monitor_v2,delete,delete,
qualitymonitorv2.json,/api/2.0/quality-monitors/{object_type}/{object_id},quality_monitor_v2_get_quality_monitor,get,QualityMonitor,"qualitymonitorv2, quality_monitor_v2","object_type, object_id",[DEPRECATED] Read a quality monitor on UC object. Use Data Quality Monitoring API instead.,"[DEPRECATED] Read a quality monitor on UC object. Use Data Quality Monitoring API instead.  :param object_type: str   The type of the monitored object. Can be one of the following: schema. :param object_id: str   The uuid of the request object. For example, schema id.  :returns: :class:`QualityMonitor`",quality_monitor_v2,get,select,
qualitymonitorv2.json,/api/2.0/quality-monitors/{object_type}/{object_id},quality_monitor_v2_update_quality_monitor,put,QualityMonitor,"qualitymonitorv2, quality_monitor_v2","object_type, object_id, quality_monitor",[DEPRECATED] (Unimplemented) Update a quality monitor on UC object. Use Data Quality Monitoring API,"[DEPRECATED] (Unimplemented) Update a quality monitor on UC object. Use Data Quality Monitoring API instead.  :param object_type: str   The type of the monitored object. Can be one of the following: schema. :param object_id: str   The uuid of the request object. For example, schema id. :param quality_monitor: :class:`QualityMonitor`  :returns: :class:`QualityMonitor`",quality_monitor_v2,update,replace,
serving.json,/api/2.0/serving-endpoints/{name}/served-models/{served_model_name}/build-logs,serving_endpoints_build_logs,get,BuildLogsResponse,"serving, serving_endpoints","name, served_model_name",Retrieves the build logs associated with the provided served model.,Retrieves the build logs associated with the provided served model.  :param name: str   The name of the serving endpoint that the served model belongs to. This field is required. :param served_model_name: str   The name of the served model that build logs will be retrieved for. This field is required.  :returns: :class:`BuildLogsResponse`,serving_endpoint_build_logs,get,select,
serving.json,/api/2.0/serving-endpoints,serving_endpoints_create,post,ServingEndpointDetailed,"serving, serving_endpoints","name, ai_gateway, budget_policy_id, config, description, email_notifications, rate_limits, route_optimized, tags",Create a new serving endpoint.,"Create a new serving endpoint.  :param name: str   The name of the serving endpoint. This field is required and must be unique across a Databricks   workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. :param ai_gateway: :class:`AiGatewayConfig` (optional)   The AI Gateway configuration for the serving endpoint. NOTE: External model, provisioned throughput,   and pay-per-token endpoints are fully supported; agent endpoints currently only support inference   tables. :param budget_policy_id: str (optional)   The budget policy to be applied to the serving endpoint. :param config: :class:`EndpointCoreConfigInput` (optional)   The core config of the serving endpoint. :param description: str (optional) :param email_notifications: :class:`EmailNotifications` (optional)   Email notification settings. :param rate_limits: List[:class:`RateLimit`] (optional)   Rate limits to be applied to the serving endpoint. NOTE: this field is deprecated, please use AI   Gateway to manage rate limits. :param route_optimized: bool (optional)   Enable route optimization for the serving endpoint. :param tags: List[:class:`EndpointTag`] (optional)   Tags to be attached to the serving endpoint and automatically propagated to billing logs.  :returns:   Long-running operation waiter for :class:`ServingEndpointDetailed`.   See :method:wait_get_serving_endpoint_not_updating for more details.",serving_endpoints,create,insert,
serving.json,/api/2.0/serving-endpoints,serving_endpoints_list,get,ListEndpointsResponse,"serving, serving_endpoints",,Get all serving endpoints.,Get all serving endpoints.   :returns: Iterator over :class:`ServingEndpoint`,serving_endpoints,list,select,$.endpoints
serving.json,/api/2.0/serving-endpoints/pt,serving_endpoints_create_provisioned_throughput_endpoint,post,ServingEndpointDetailed,"serving, serving_endpoints","name, config, ai_gateway, budget_policy_id, email_notifications, tags",Create a new PT serving endpoint.,"Create a new PT serving endpoint.  :param name: str   The name of the serving endpoint. This field is required and must be unique across a Databricks   workspace. An endpoint name can consist of alphanumeric characters, dashes, and underscores. :param config: :class:`PtEndpointCoreConfig`   The core config of the serving endpoint. :param ai_gateway: :class:`AiGatewayConfig` (optional)   The AI Gateway configuration for the serving endpoint. :param budget_policy_id: str (optional)   The budget policy associated with the endpoint. :param email_notifications: :class:`EmailNotifications` (optional)   Email notification settings. :param tags: List[:class:`EndpointTag`] (optional)   Tags to be attached to the serving endpoint and automatically propagated to billing logs.  :returns:   Long-running operation waiter for :class:`ServingEndpointDetailed`.   See :method:wait_get_serving_endpoint_not_updating for more details.",serving_endpoints_pt,create,insert,
serving.json,/api/2.0/serving-endpoints/{name},serving_endpoints_delete,delete,,"serving, serving_endpoints",name,Delete a serving endpoint.,Delete a serving endpoint.  :param name: str,serving_endpoints,delete,delete,
serving.json,/api/2.0/serving-endpoints/{name},serving_endpoints_get,get,ServingEndpointDetailed,"serving, serving_endpoints",name,Retrieves the details for a single serving endpoint.,Retrieves the details for a single serving endpoint.  :param name: str   The name of the serving endpoint. This field is required.  :returns: :class:`ServingEndpointDetailed`,serving_endpoints,get,select,
serving.json,/api/2.0/serving-endpoints/{name}/metrics,serving_endpoints_export_metrics,get,ExportMetricsResponse,"serving, serving_endpoints",name,Retrieves the metrics associated with the provided serving endpoint in either Prometheus or,Retrieves the metrics associated with the provided serving endpoint in either Prometheus or OpenMetrics exposition format.  :param name: str   The name of the serving endpoint to retrieve metrics for. This field is required.  :returns: :class:`ExportMetricsResponse`,serving_endpoint_metrics,get,select,
serving.json,/api/2.0/serving-endpoints/{name}/openapi,serving_endpoints_get_open_api,get,GetOpenApiResponse,"serving, serving_endpoints",name,Get the query schema of the serving endpoint in OpenAPI format. The schema contains information for,"Get the query schema of the serving endpoint in OpenAPI format. The schema contains information for the supported paths, input and output format and datatypes.  :param name: str   The name of the serving endpoint that the served model belongs to. This field is required.  :returns: :class:`GetOpenApiResponse`",serving_endpoint_openapi,get,select,
serving.json,/api/2.0/permissions/serving-endpoints/{serving_endpoint_id}/permissionLevels,serving_endpoints_get_permission_levels,get,GetServingEndpointPermissionLevelsResponse,"serving, serving_endpoints",serving_endpoint_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param serving_endpoint_id: str   The serving endpoint for which to get or manage permissions.  :returns: :class:`GetServingEndpointPermissionLevelsResponse`,serving_endpoint_permission_levels,get,select,
serving.json,/api/2.0/permissions/serving-endpoints/{serving_endpoint_id},serving_endpoints_get_permissions,get,ServingEndpointPermissions,"serving, serving_endpoints",serving_endpoint_id,Gets the permissions of a serving endpoint. Serving endpoints can inherit permissions from their root,Gets the permissions of a serving endpoint. Serving endpoints can inherit permissions from their root object.  :param serving_endpoint_id: str   The serving endpoint for which to get or manage permissions.  :returns: :class:`ServingEndpointPermissions`,serving_endpoint_permissions,get,select,
serving.json,/api/2.0/permissions/serving-endpoints/{serving_endpoint_id},serving_endpoints_set_permissions,put,ServingEndpointPermissions,"serving, serving_endpoints","serving_endpoint_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param serving_endpoint_id: str   The serving endpoint for which to get or manage permissions. :param access_control_list: List[:class:`ServingEndpointAccessControlRequest`] (optional)  :returns: :class:`ServingEndpointPermissions`",serving_endpoint_permissions,set,replace,
serving.json,/api/2.0/permissions/serving-endpoints/{serving_endpoint_id},serving_endpoints_update_permissions,patch,ServingEndpointPermissions,"serving, serving_endpoints","serving_endpoint_id, access_control_list",Updates the permissions on a serving endpoint. Serving endpoints can inherit permissions from their,Updates the permissions on a serving endpoint. Serving endpoints can inherit permissions from their root object.  :param serving_endpoint_id: str   The serving endpoint for which to get or manage permissions. :param access_control_list: List[:class:`ServingEndpointAccessControlRequest`] (optional)  :returns: :class:`ServingEndpointPermissions`,serving_endpoint_permissions,update,update,
serving.json,/api/2.0/external-function,serving_endpoints_http_request,post,HttpRequestResponse,"serving, serving_endpoints","connection_name, method, path, json, params",Make external services call using the credentials stored in UC Connection.,"Make external services call using the credentials stored in UC Connection.  :param connection_name: str   The connection name to use. This is required to identify the external connection. :param method: :class:`ExternalFunctionRequestHttpMethod`   The HTTP method to use (e.g., 'GET', 'POST'). :param path: str   The relative path for the API endpoint. This is required. :param headers: str (optional)   Additional headers for the request. If not provided, only auth headers from connections would be   passed. :param json: str (optional)   The JSON payload to send in the request body. :param params: str (optional)   Query parameters for the request.  :returns: :class:`HttpRequestResponse`",external_functions,http_request,exec,
serving.json,/api/2.0/serving-endpoints/{name}/served-models/{served_model_name}/logs,serving_endpoints_logs,get,ServerLogsResponse,"serving, serving_endpoints","name, served_model_name",Retrieves the service logs associated with the provided served model.,Retrieves the service logs associated with the provided served model.  :param name: str   The name of the serving endpoint that the served model belongs to. This field is required. :param served_model_name: str   The name of the served model that logs will be retrieved for. This field is required.  :returns: :class:`ServerLogsResponse`,serving_endpoint_logs,get,select,
serving.json,/api/2.0/serving-endpoints/{name}/tags,serving_endpoints_patch,patch,EndpointTags,"serving, serving_endpoints","name, add_tags, delete_tags",Used to batch add and delete tags from a serving endpoint with a single API call.,Used to batch add and delete tags from a serving endpoint with a single API call.  :param name: str   The name of the serving endpoint who's tags to patch. This field is required. :param add_tags: List[:class:`EndpointTag`] (optional)   List of endpoint tags to add :param delete_tags: List[str] (optional)   List of tag keys to delete  :returns: :class:`EndpointTags`,serving_endpoints,update,update,
serving.json,/api/2.0/serving-endpoints/{name}/rate-limits,serving_endpoints_put,put,PutResponse,"serving, serving_endpoints","name, rate_limits",Deprecated: Please use AI Gateway to manage rate limits instead.,Deprecated: Please use AI Gateway to manage rate limits instead.  :param name: str   The name of the serving endpoint whose rate limits are being updated. This field is required. :param rate_limits: List[:class:`RateLimit`] (optional)   The list of endpoint rate limits.  :returns: :class:`PutResponse`,serving_endpoint_rate_limits,update,replace,
serving.json,/api/2.0/serving-endpoints/{name}/ai-gateway,serving_endpoints_put_ai_gateway,put,PutAiGatewayResponse,"serving, serving_endpoints","name, fallback_config, guardrails, inference_table_config, rate_limits, usage_tracking_config","Used to update the AI Gateway of a serving endpoint. NOTE: External model, provisioned throughput, and","Used to update the AI Gateway of a serving endpoint. NOTE: External model, provisioned throughput, and pay-per-token endpoints are fully supported; agent endpoints currently only support inference tables.  :param name: str   The name of the serving endpoint whose AI Gateway is being updated. This field is required. :param fallback_config: :class:`FallbackConfig` (optional)   Configuration for traffic fallback which auto fallbacks to other served entities if the request to a   served entity fails with certain error codes, to increase availability. :param guardrails: :class:`AiGatewayGuardrails` (optional)   Configuration for AI Guardrails to prevent unwanted data and unsafe data in requests and responses. :param inference_table_config: :class:`AiGatewayInferenceTableConfig` (optional)   Configuration for payload logging using inference tables. Use these tables to monitor and audit data   being sent to and received from model APIs and to improve model quality. :param rate_limits: List[:class:`AiGatewayRateLimit`] (optional)   Configuration for rate limits which can be set to limit endpoint traffic. :param usage_tracking_config: :class:`AiGatewayUsageTrackingConfig` (optional)   Configuration to enable usage tracking using system tables. These tables allow you to monitor   operational usage on endpoints and their associated costs.  :returns: :class:`PutAiGatewayResponse`",serving_endpoint_ai_gateway,update,replace,
serving.json,/serving-endpoints/{name}/invocations,serving_endpoints_query,post,QueryEndpointResponse,"serving, serving_endpoints","name, client_request_id, dataframe_records, dataframe_split, extra_params, input, inputs, instances, max_tokens, messages, n, prompt, stop, stream, temperature, usage_context",Query a serving endpoint,"Query a serving endpoint  :param name: str   The name of the serving endpoint. This field is required and is provided via the path parameter. :param client_request_id: str (optional)   Optional user-provided request identifier that will be recorded in the inference table and the usage   tracking table. :param dataframe_records: List[Any] (optional)   Pandas Dataframe input in the records orientation. :param dataframe_split: :class:`DataframeSplitInput` (optional)   Pandas Dataframe input in the split orientation. :param extra_params: Dict[str,str] (optional)   The extra parameters field used ONLY for __completions, chat,__ and __embeddings external &   foundation model__ serving endpoints. This is a map of strings and should only be used with other   external/foundation model query fields. :param input: Any (optional)   The input string (or array of strings) field used ONLY for __embeddings external & foundation   model__ serving endpoints and is the only field (along with extra_params if needed) used by   embeddings queries. :param inputs: Any (optional)   Tensor-based input in columnar format. :param instances: List[Any] (optional)   Tensor-based input in row format. :param max_tokens: int (optional)   The max tokens field used ONLY for __completions__ and __chat external & foundation model__ serving   endpoints. This is an integer and should only be used with other chat/completions query fields. :param messages: List[:class:`ChatMessage`] (optional)   The messages field used ONLY for __chat external & foundation model__ serving endpoints. This is an   array of ChatMessage objects and should only be used with other chat query fields. :param n: int (optional)   The n (number of candidates) field used ONLY for __completions__ and __chat external & foundation   model__ serving endpoints. This is an integer between 1 and 5 with a default of 1 and should only be   used with other chat/completions query fields. :param prompt: Any (optional)   The prompt string (or array of strings) field used ONLY for __completions external & foundation   model__ serving endpoints and should only be used with other completions query fields. :param stop: List[str] (optional)   The stop sequences field used ONLY for __completions__ and __chat external & foundation model__   serving endpoints. This is a list of strings and should only be used with other chat/completions   query fields. :param stream: bool (optional)   The stream field used ONLY for __completions__ and __chat external & foundation model__ serving   endpoints. This is a boolean defaulting to false and should only be used with other chat/completions   query fields. :param temperature: float (optional)   The temperature field used ONLY for __completions__ and __chat external & foundation model__ serving   endpoints. This is a float between 0.0 and 2.0 with a default of 1.0 and should only be used with   other chat/completions query fields. :param usage_context: Dict[str,str] (optional)   Optional user-provided context that will be recorded in the usage tracking table.  :returns: :class:`QueryEndpointResponse`",serving_endpoints,query,exec,
serving.json,/api/2.0/serving-endpoints/{name}/config,serving_endpoints_update_config,put,ServingEndpointDetailed,"serving, serving_endpoints","name, auto_capture_config, served_entities, served_models, traffic_config","Updates any combination of the serving endpoint's served entities, the compute configuration of those","Updates any combination of the serving endpoint's served entities, the compute configuration of those served entities, and the endpoint's traffic config. An endpoint that already has an update in progress can not be updated until the current update completes or fails.  :param name: str   The name of the serving endpoint to update. This field is required. :param auto_capture_config: :class:`AutoCaptureConfigInput` (optional)   Configuration for Inference Tables which automatically logs requests and responses to Unity Catalog.   Note: this field is deprecated for creating new provisioned throughput endpoints, or updating   existing provisioned throughput endpoints that never have inference table configured; in these cases   please use AI Gateway to manage inference tables. :param served_entities: List[:class:`ServedEntityInput`] (optional)   The list of served entities under the serving endpoint config. :param served_models: List[:class:`ServedModelInput`] (optional)   (Deprecated, use served_entities instead) The list of served models under the serving endpoint   config. :param traffic_config: :class:`TrafficConfig` (optional)   The traffic configuration associated with the serving endpoint config.  :returns:   Long-running operation waiter for :class:`ServingEndpointDetailed`.   See :method:wait_get_serving_endpoint_not_updating for more details.",serving_endpoints,update_config,replace,
serving.json,/api/2.0/serving-endpoints/{name}/notifications,serving_endpoints_update_notifications,patch,UpdateInferenceEndpointNotificationsResponse,"serving, serving_endpoints","name, email_notifications",Updates the email and webhook notification settings for an endpoint.,Updates the email and webhook notification settings for an endpoint.  :param name: str   The name of the serving endpoint whose notifications are being updated. This field is required. :param email_notifications: :class:`EmailNotifications` (optional)   The email notification settings to update. Specify email addresses to notify when endpoint state   changes occur.  :returns: :class:`UpdateInferenceEndpointNotificationsResponse`,serving_endpoint_notifications,update,update,
serving.json,/api/2.0/serving-endpoints/pt/{name}/config,serving_endpoints_update_provisioned_throughput_endpoint_config,put,ServingEndpointDetailed,"serving, serving_endpoints","name, config","Updates any combination of the pt endpoint's served entities, the compute configuration of those","Updates any combination of the pt endpoint's served entities, the compute configuration of those served entities, and the endpoint's traffic config. Updates are instantaneous and endpoint should be updated instantly  :param name: str   The name of the pt endpoint to update. This field is required. :param config: :class:`PtEndpointCoreConfig`  :returns:   Long-running operation waiter for :class:`ServingEndpointDetailed`.   See :method:wait_get_serving_endpoint_not_updating for more details.",serving_endpoints_pt,update_config,replace,
settings.json,/api/2.0/settings/types/aibi_dash_embed_ws_acc_policy/names/default,aibi_dashboard_embedding_access_policy_delete,delete,DeleteAibiDashboardEmbeddingAccessPolicySettingResponse,"settings, aibi_dashboard_embedding_access_policy",etag,"Delete the AI/BI dashboard embedding access policy, reverting back to the default.","Delete the AI/BI dashboard embedding access policy, reverting back to the default.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteAibiDashboardEmbeddingAccessPolicySettingResponse`",aibi_dashboard_embedding_access_policy,delete,delete,
settings.json,/api/2.0/settings/types/aibi_dash_embed_ws_acc_policy/names/default,aibi_dashboard_embedding_access_policy_get,get,AibiDashboardEmbeddingAccessPolicySetting,"settings, aibi_dashboard_embedding_access_policy",etag,"Retrieves the AI/BI dashboard embedding access policy. The default setting is ALLOW_APPROVED_DOMAINS,","Retrieves the AI/BI dashboard embedding access policy. The default setting is ALLOW_APPROVED_DOMAINS, permitting AI/BI dashboards to be embedded on approved domains.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`AibiDashboardEmbeddingAccessPolicySetting`",aibi_dashboard_embedding_access_policy,get,select,
settings.json,/api/2.0/settings/types/aibi_dash_embed_ws_acc_policy/names/default,aibi_dashboard_embedding_access_policy_update,patch,AibiDashboardEmbeddingAccessPolicySetting,"settings, aibi_dashboard_embedding_access_policy","allow_missing, setting, field_mask",Updates the AI/BI dashboard embedding access policy at the workspace level.,"Updates the AI/BI dashboard embedding access policy at the workspace level.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`AibiDashboardEmbeddingAccessPolicySetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`AibiDashboardEmbeddingAccessPolicySetting`",aibi_dashboard_embedding_access_policy,update,update,
settings.json,/api/2.0/settings/types/aibi_dash_embed_ws_apprvd_domains/names/default,aibi_dashboard_embedding_approved_domains_delete,delete,DeleteAibiDashboardEmbeddingApprovedDomainsSettingResponse,"settings, aibi_dashboard_embedding_approved_domains",etag,"Delete the list of domains approved to host embedded AI/BI dashboards, reverting back to the default","Delete the list of domains approved to host embedded AI/BI dashboards, reverting back to the default empty list.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteAibiDashboardEmbeddingApprovedDomainsSettingResponse`",aibi_dashboard_embedding_approved_domains,delete,delete,
settings.json,/api/2.0/settings/types/aibi_dash_embed_ws_apprvd_domains/names/default,aibi_dashboard_embedding_approved_domains_get,get,AibiDashboardEmbeddingApprovedDomainsSetting,"settings, aibi_dashboard_embedding_approved_domains",etag,Retrieves the list of domains approved to host embedded AI/BI dashboards.,"Retrieves the list of domains approved to host embedded AI/BI dashboards.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`AibiDashboardEmbeddingApprovedDomainsSetting`",aibi_dashboard_embedding_approved_domains,get,select,
settings.json,/api/2.0/settings/types/aibi_dash_embed_ws_apprvd_domains/names/default,aibi_dashboard_embedding_approved_domains_update,patch,AibiDashboardEmbeddingApprovedDomainsSetting,"settings, aibi_dashboard_embedding_approved_domains","allow_missing, setting, field_mask",Updates the list of domains approved to host embedded AI/BI dashboards. This update will fail if the,"Updates the list of domains approved to host embedded AI/BI dashboards. This update will fail if the current workspace access policy is not ALLOW_APPROVED_DOMAINS.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`AibiDashboardEmbeddingApprovedDomainsSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`AibiDashboardEmbeddingApprovedDomainsSetting`",aibi_dashboard_embedding_approved_domains,update,update,
settings.json,/api/2.0/settings/types/automatic_cluster_update/names/default,automatic_cluster_update_get,get,AutomaticClusterUpdateSetting,"settings, automatic_cluster_update",etag,Gets the automatic cluster update setting.,"Gets the automatic cluster update setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`AutomaticClusterUpdateSetting`",automatic_cluster_update,get,select,
settings.json,/api/2.0/settings/types/automatic_cluster_update/names/default,automatic_cluster_update_update,patch,AutomaticClusterUpdateSetting,"settings, automatic_cluster_update","allow_missing, setting, field_mask",Updates the automatic cluster update setting for the workspace. A fresh etag needs to be provided in,"Updates the automatic cluster update setting for the workspace. A fresh etag needs to be provided in `PATCH` requests (as part of the setting field). The etag can be retrieved by making a `GET` request before the `PATCH` request. If the setting is updated concurrently, `PATCH` fails with 409 and the request must be retried by using the fresh etag in the 409 response.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`AutomaticClusterUpdateSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`AutomaticClusterUpdateSetting`",automatic_cluster_update,update,update,
settings.json,/api/2.0/settings/types/shield_csp_enablement_ws_db/names/default,compliance_security_profile_get,get,ComplianceSecurityProfileSetting,"settings, compliance_security_profile",etag,Gets the compliance security profile setting.,"Gets the compliance security profile setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`ComplianceSecurityProfileSetting`",compliance_security_profile,get,select,
settings.json,/api/2.0/settings/types/shield_csp_enablement_ws_db/names/default,compliance_security_profile_update,patch,ComplianceSecurityProfileSetting,"settings, compliance_security_profile","allow_missing, setting, field_mask",Updates the compliance security profile setting for the workspace. A fresh etag needs to be provided,"Updates the compliance security profile setting for the workspace. A fresh etag needs to be provided in `PATCH` requests (as part of the setting field). The etag can be retrieved by making a `GET` request before the `PATCH` request. If the setting is updated concurrently, `PATCH` fails with 409 and the request must be retried by using the fresh etag in the 409 response.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`ComplianceSecurityProfileSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`ComplianceSecurityProfileSetting`",compliance_security_profile,update,update,
settings.json,/api/2.0/credentials-manager/exchange-tokens/token,credentials_manager_exchange_token,post,ExchangeTokenResponse,"settings, credentials_manager","partition_id, token_type, scopes",Exchange tokens with an Identity Provider to get a new access token. It allows specifying scopes to,Exchange tokens with an Identity Provider to get a new access token. It allows specifying scopes to determine token permissions.  :param partition_id: :class:`PartitionId`   The partition of Credentials store :param token_type: List[:class:`TokenType`]   A list of token types being requested :param scopes: List[str]   Array of scopes for the token request.  :returns: :class:`ExchangeTokenResponse`,credentials_manager,exchange_token,insert,
settings.json,/api/2.0/accounts/{account_id}/settings/types/shield_csp_enablement_ac/names/default,csp_enablement_account_get,get,CspEnablementAccountSetting,"settings, csp_enablement_account",etag,Gets the compliance security profile setting for new workspaces.,"Gets the compliance security profile setting for new workspaces.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`CspEnablementAccountSetting`",csp_enablement_account,get,select,
settings.json,/api/2.0/accounts/{account_id}/settings/types/shield_csp_enablement_ac/names/default,csp_enablement_account_update,patch,CspEnablementAccountSetting,"settings, csp_enablement_account","allow_missing, setting, field_mask",Updates the value of the compliance security profile setting for new workspaces.,"Updates the value of the compliance security profile setting for new workspaces.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`CspEnablementAccountSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`CspEnablementAccountSetting`",csp_enablement_account,update,update,
settings.json,/api/2.0/settings/types/dashboard_email_subscriptions/names/default,dashboard_email_subscriptions_delete,delete,DeleteDashboardEmailSubscriptionsResponse,"settings, dashboard_email_subscriptions",etag,Reverts the Dashboard Email Subscriptions setting to its default value.,"Reverts the Dashboard Email Subscriptions setting to its default value.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteDashboardEmailSubscriptionsResponse`",dashboard_email_subscriptions,delete,delete,
settings.json,/api/2.0/settings/types/dashboard_email_subscriptions/names/default,dashboard_email_subscriptions_get,get,DashboardEmailSubscriptions,"settings, dashboard_email_subscriptions",etag,Gets the Dashboard Email Subscriptions setting.,"Gets the Dashboard Email Subscriptions setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DashboardEmailSubscriptions`",dashboard_email_subscriptions,get,select,
settings.json,/api/2.0/settings/types/dashboard_email_subscriptions/names/default,dashboard_email_subscriptions_update,patch,DashboardEmailSubscriptions,"settings, dashboard_email_subscriptions","allow_missing, setting, field_mask",Updates the Dashboard Email Subscriptions setting.,"Updates the Dashboard Email Subscriptions setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`DashboardEmailSubscriptions` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`DashboardEmailSubscriptions`",dashboard_email_subscriptions,update,update,
settings.json,/api/2.0/settings/types/default_namespace_ws/names/default,default_namespace_delete,delete,DeleteDefaultNamespaceSettingResponse,"settings, default_namespace",etag,Deletes the default namespace setting for the workspace. A fresh etag needs to be provided in `DELETE`,"Deletes the default namespace setting for the workspace. A fresh etag needs to be provided in `DELETE` requests (as a query parameter). The etag can be retrieved by making a `GET` request before the `DELETE` request. If the setting is updated/deleted concurrently, `DELETE` fails with 409 and the request must be retried by using the fresh etag in the 409 response.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteDefaultNamespaceSettingResponse`",default_namespace,delete,delete,
settings.json,/api/2.0/settings/types/default_namespace_ws/names/default,default_namespace_get,get,DefaultNamespaceSetting,"settings, default_namespace",etag,Gets the default namespace setting.,"Gets the default namespace setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DefaultNamespaceSetting`",default_namespace,get,select,
settings.json,/api/2.0/settings/types/default_namespace_ws/names/default,default_namespace_update,patch,DefaultNamespaceSetting,"settings, default_namespace","allow_missing, setting, field_mask",Updates the default namespace setting for the workspace. A fresh etag needs to be provided in `PATCH`,"Updates the default namespace setting for the workspace. A fresh etag needs to be provided in `PATCH` requests (as part of the setting field). The etag can be retrieved by making a `GET` request before the `PATCH` request. Note that if the setting does not exist, `GET` returns a NOT_FOUND error and the etag is present in the error response, which should be set in the `PATCH` request. If the setting is updated concurrently, `PATCH` fails with 409 and the request must be retried by using the fresh etag in the 409 response.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`DefaultNamespaceSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`DefaultNamespaceSetting`",default_namespace,update,update,
settings.json,/api/2.0/settings/types/default_warehouse_id/names/default,default_warehouse_id_delete,delete,DeleteDefaultWarehouseIdResponse,"settings, default_warehouse_id",etag,Reverts the Default Warehouse Id setting to its default value.,"Reverts the Default Warehouse Id setting to its default value.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteDefaultWarehouseIdResponse`",default_warehouse_id,delete,delete,
settings.json,/api/2.0/settings/types/default_warehouse_id/names/default,default_warehouse_id_get,get,DefaultWarehouseId,"settings, default_warehouse_id",etag,Gets the Default Warehouse Id setting.,"Gets the Default Warehouse Id setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DefaultWarehouseId`",default_warehouse_id,get,select,
settings.json,/api/2.0/settings/types/default_warehouse_id/names/default,default_warehouse_id_update,patch,DefaultWarehouseId,"settings, default_warehouse_id","allow_missing, setting, field_mask",Updates the Default Warehouse Id setting.,"Updates the Default Warehouse Id setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`DefaultWarehouseId` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`DefaultWarehouseId`",default_warehouse_id,update,update,
settings.json,/api/2.0/settings/types/disable_legacy_access/names/default,disable_legacy_access_delete,delete,DeleteDisableLegacyAccessResponse,"settings, disable_legacy_access",etag,Deletes legacy access disablement status.,"Deletes legacy access disablement status.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteDisableLegacyAccessResponse`",disable_legacy_access,delete,delete,
settings.json,/api/2.0/settings/types/disable_legacy_access/names/default,disable_legacy_access_get,get,DisableLegacyAccess,"settings, disable_legacy_access",etag,Retrieves legacy access disablement Status.,"Retrieves legacy access disablement Status.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DisableLegacyAccess`",disable_legacy_access,get,select,
settings.json,/api/2.0/settings/types/disable_legacy_access/names/default,disable_legacy_access_update,patch,DisableLegacyAccess,"settings, disable_legacy_access","allow_missing, setting, field_mask",Updates legacy access disablement status.,"Updates legacy access disablement status.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`DisableLegacyAccess` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`DisableLegacyAccess`",disable_legacy_access,update,update,
settings.json,/api/2.0/settings/types/disable_legacy_dbfs/names/default,disable_legacy_dbfs_delete,delete,DeleteDisableLegacyDbfsResponse,"settings, disable_legacy_dbfs",etag,"Deletes the disable legacy DBFS setting for a workspace, reverting back to the default.","Deletes the disable legacy DBFS setting for a workspace, reverting back to the default.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteDisableLegacyDbfsResponse`",disable_legacy_dbfs,delete,delete,
settings.json,/api/2.0/settings/types/disable_legacy_dbfs/names/default,disable_legacy_dbfs_get,get,DisableLegacyDbfs,"settings, disable_legacy_dbfs",etag,Gets the disable legacy DBFS setting.,"Gets the disable legacy DBFS setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DisableLegacyDbfs`",disable_legacy_dbfs,get,select,
settings.json,/api/2.0/settings/types/disable_legacy_dbfs/names/default,disable_legacy_dbfs_update,patch,DisableLegacyDbfs,"settings, disable_legacy_dbfs","allow_missing, setting, field_mask",Updates the disable legacy DBFS setting for the workspace.,"Updates the disable legacy DBFS setting for the workspace.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`DisableLegacyDbfs` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`DisableLegacyDbfs`",disable_legacy_dbfs,update,update,
settings.json,/api/2.0/accounts/{account_id}/settings/types/disable_legacy_features/names/default,disable_legacy_features_delete,delete,DeleteDisableLegacyFeaturesResponse,"settings, disable_legacy_features",etag,Deletes the disable legacy features setting.,"Deletes the disable legacy features setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteDisableLegacyFeaturesResponse`",disable_legacy_features,delete,delete,
settings.json,/api/2.0/accounts/{account_id}/settings/types/disable_legacy_features/names/default,disable_legacy_features_get,get,DisableLegacyFeatures,"settings, disable_legacy_features",etag,Gets the value of the disable legacy features setting.,"Gets the value of the disable legacy features setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DisableLegacyFeatures`",disable_legacy_features,get,select,
settings.json,/api/2.0/accounts/{account_id}/settings/types/disable_legacy_features/names/default,disable_legacy_features_update,patch,DisableLegacyFeatures,"settings, disable_legacy_features","allow_missing, setting, field_mask",Updates the value of the disable legacy features setting.,"Updates the value of the disable legacy features setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`DisableLegacyFeatures` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`DisableLegacyFeatures`",disable_legacy_features,update,update,
settings.json,/api/2.0/settings/types/enable-export-notebook/names/default,enable_export_notebook_get_enable_export_notebook,get,EnableExportNotebook,"settings, enable_export_notebook",,Gets the Notebook and File exporting setting.,Gets the Notebook and File exporting setting.   :returns: :class:`EnableExportNotebook`,enable_export_notebook,get,select,
settings.json,/api/2.0/settings/types/enable-export-notebook/names/default,enable_export_notebook_patch_enable_export_notebook,patch,EnableExportNotebook,"settings, enable_export_notebook","allow_missing, setting, field_mask","Updates the Notebook and File exporting setting. The model follows eventual consistency, which means","Updates the Notebook and File exporting setting. The model follows eventual consistency, which means the get after the update operation might receive stale values for some time.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`EnableExportNotebook` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`EnableExportNotebook`",enable_export_notebook,update,update,
settings.json,/api/2.0/accounts/{account_id}/settings/types/acct_ip_acl_enable/names/default,enable_ip_access_lists_delete,delete,DeleteAccountIpAccessEnableResponse,"settings, enable_ip_access_lists",etag,Reverts the value of the account IP access toggle setting to default (ON),"Reverts the value of the account IP access toggle setting to default (ON)  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteAccountIpAccessEnableResponse`",enable_ip_access_lists,delete,delete,
settings.json,/api/2.0/accounts/{account_id}/settings/types/acct_ip_acl_enable/names/default,enable_ip_access_lists_get,get,AccountIpAccessEnable,"settings, enable_ip_access_lists",etag,Gets the value of the account IP access toggle setting.,"Gets the value of the account IP access toggle setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`AccountIpAccessEnable`",enable_ip_access_lists,get,select,
settings.json,/api/2.0/accounts/{account_id}/settings/types/acct_ip_acl_enable/names/default,enable_ip_access_lists_update,patch,AccountIpAccessEnable,"settings, enable_ip_access_lists","allow_missing, setting, field_mask",Updates the value of the account IP access toggle setting.,"Updates the value of the account IP access toggle setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`AccountIpAccessEnable` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`AccountIpAccessEnable`",enable_ip_access_lists,update,update,
settings.json,/api/2.0/settings/types/enable-notebook-table-clipboard/names/default,enable_notebook_table_clipboard_get_enable_notebook_table_clipboard,get,EnableNotebookTableClipboard,"settings, enable_notebook_table_clipboard",,Gets the Results Table Clipboard features setting.,Gets the Results Table Clipboard features setting.   :returns: :class:`EnableNotebookTableClipboard`,enable_notebook_table_clipboard,get,select,
settings.json,/api/2.0/settings/types/enable-notebook-table-clipboard/names/default,enable_notebook_table_clipboard_patch_enable_notebook_table_clipboard,patch,EnableNotebookTableClipboard,"settings, enable_notebook_table_clipboard","allow_missing, setting, field_mask","Updates the Results Table Clipboard features setting. The model follows eventual consistency, which","Updates the Results Table Clipboard features setting. The model follows eventual consistency, which means the get after the update operation might receive stale values for some time.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`EnableNotebookTableClipboard` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`EnableNotebookTableClipboard`",enable_notebook_table_clipboard,update,update,
settings.json,/api/2.0/settings/types/enable-results-downloading/names/default,enable_results_downloading_get_enable_results_downloading,get,EnableResultsDownloading,"settings, enable_results_downloading",,Gets the Notebook results download setting.,Gets the Notebook results download setting.   :returns: :class:`EnableResultsDownloading`,enable_results_downloading,get,select,
settings.json,/api/2.0/settings/types/enable-results-downloading/names/default,enable_results_downloading_patch_enable_results_downloading,patch,EnableResultsDownloading,"settings, enable_results_downloading","allow_missing, setting, field_mask","Updates the Notebook results download setting. The model follows eventual consistency, which means the","Updates the Notebook results download setting. The model follows eventual consistency, which means the get after the update operation might receive stale values for some time.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`EnableResultsDownloading` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`EnableResultsDownloading`",enable_results_downloading,update,update,
settings.json,/api/2.0/settings/types/shield_esm_enablement_ws_db/names/default,enhanced_security_monitoring_get,get,EnhancedSecurityMonitoringSetting,"settings, enhanced_security_monitoring",etag,Gets the enhanced security monitoring setting.,"Gets the enhanced security monitoring setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`EnhancedSecurityMonitoringSetting`",enhanced_security_monitoring,get,select,
settings.json,/api/2.0/settings/types/shield_esm_enablement_ws_db/names/default,enhanced_security_monitoring_update,patch,EnhancedSecurityMonitoringSetting,"settings, enhanced_security_monitoring","allow_missing, setting, field_mask",Updates the enhanced security monitoring setting for the workspace. A fresh etag needs to be provided,"Updates the enhanced security monitoring setting for the workspace. A fresh etag needs to be provided in `PATCH` requests (as part of the setting field). The etag can be retrieved by making a `GET` request before the `PATCH` request. If the setting is updated concurrently, `PATCH` fails with 409 and the request must be retried by using the fresh etag in the 409 response.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`EnhancedSecurityMonitoringSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`EnhancedSecurityMonitoringSetting`",enhanced_security_monitoring,update,update,
settings.json,/api/2.0/accounts/{account_id}/settings/types/shield_esm_enablement_ac/names/default,esm_enablement_account_get,get,EsmEnablementAccountSetting,"settings, esm_enablement_account",etag,Gets the enhanced security monitoring setting for new workspaces.,"Gets the enhanced security monitoring setting for new workspaces.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`EsmEnablementAccountSetting`",esm_enablement_account,get,select,
settings.json,/api/2.0/accounts/{account_id}/settings/types/shield_esm_enablement_ac/names/default,esm_enablement_account_update,patch,EsmEnablementAccountSetting,"settings, esm_enablement_account","allow_missing, setting, field_mask",Updates the value of the enhanced security monitoring setting for new workspaces.,"Updates the value of the enhanced security monitoring setting for new workspaces.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`EsmEnablementAccountSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`EsmEnablementAccountSetting`",esm_enablement_account,update,update,
settings.json,/api/2.0/ip-access-lists,ip_access_lists_create,post,CreateIpAccessListResponse,"settings, ip_access_lists","label, list_type, ip_addresses",Creates an IP access list for this workspace.,"Creates an IP access list for this workspace.  A list can be an allow list or a block list. See the top of this file for a description of how the server treats allow lists and block lists at runtime.  When creating or updating an IP access list:  * For all allow lists and block lists combined, the API supports a maximum of 1000 IP/CIDR values, where one CIDR counts as a single value. Attempts to exceed that number return error 400 with `error_code` value `QUOTA_EXCEEDED`. * If the new list would block the calling user's current IP, error 400 is returned with `error_code` value `INVALID_STATE`.  It can take a few minutes for the changes to take effect. **Note**: Your new IP access list has no effect until you enable the feature. See :method:workspaceconf/setStatus  :param label: str   Label for the IP access list. This **cannot** be empty. :param list_type: :class:`ListType` :param ip_addresses: List[str] (optional)  :returns: :class:`CreateIpAccessListResponse`",ip_access_lists,create,insert,
settings.json,/api/2.0/ip-access-lists,ip_access_lists_list,get,GetIpAccessListsResponse,"settings, ip_access_lists",,Gets all IP access lists for the specified workspace.,Gets all IP access lists for the specified workspace.   :returns: Iterator over :class:`IpAccessListInfo`,ip_access_lists,list,select,$.ip_access_lists
settings.json,/api/2.0/ip-access-lists/{ip_access_list_id},ip_access_lists_delete,delete,,"settings, ip_access_lists",ip_access_list_id,"Deletes an IP access list, specified by its list ID.","Deletes an IP access list, specified by its list ID.  :param ip_access_list_id: str   The ID for the corresponding IP access list",ip_access_lists,delete,delete,
settings.json,/api/2.0/ip-access-lists/{ip_access_list_id},ip_access_lists_get,get,FetchIpAccessListResponse,"settings, ip_access_lists",ip_access_list_id,"Gets an IP access list, specified by its list ID.","Gets an IP access list, specified by its list ID.  :param ip_access_list_id: str   The ID for the corresponding IP access list  :returns: :class:`FetchIpAccessListResponse`",ip_access_lists,get,select,
settings.json,/api/2.0/ip-access-lists/{ip_access_list_id},ip_access_lists_replace,put,,"settings, ip_access_lists","ip_access_list_id, label, list_type, enabled, ip_addresses","Replaces an IP access list, specified by its ID.","Replaces an IP access list, specified by its ID.  A list can include allow lists and block lists. See the top of this file for a description of how the server treats allow lists and block lists at run time. When replacing an IP access list: * For all allow lists and block lists combined, the API supports a maximum of 1000 IP/CIDR values, where one CIDR counts as a single value. Attempts to exceed that number return error 400 with `error_code` value `QUOTA_EXCEEDED`. * If the resulting list would block the calling user's current IP, error 400 is returned with `error_code` value `INVALID_STATE`. It can take a few minutes for the changes to take effect. Note that your resulting IP access list has no effect until you enable the feature. See :method:workspaceconf/setStatus.  :param ip_access_list_id: str   The ID for the corresponding IP access list :param label: str   Label for the IP access list. This **cannot** be empty. :param list_type: :class:`ListType` :param enabled: bool   Specifies whether this IP access list is enabled. :param ip_addresses: List[str] (optional)",ip_access_lists,replace,replace,
settings.json,/api/2.0/ip-access-lists/{ip_access_list_id},ip_access_lists_update,patch,,"settings, ip_access_lists","ip_access_list_id, enabled, ip_addresses, label, list_type","Updates an existing IP access list, specified by its ID.","Updates an existing IP access list, specified by its ID.  A list can include allow lists and block lists. See the top of this file for a description of how the server treats allow lists and block lists at run time.  When updating an IP access list:  * For all allow lists and block lists combined, the API supports a maximum of 1000 IP/CIDR values, where one CIDR counts as a single value. Attempts to exceed that number return error 400 with `error_code` value `QUOTA_EXCEEDED`. * If the updated list would block the calling user's current IP, error 400 is returned with `error_code` value `INVALID_STATE`.  It can take a few minutes for the changes to take effect. Note that your resulting IP access list has no effect until you enable the feature. See :method:workspaceconf/setStatus.  :param ip_access_list_id: str   The ID for the corresponding IP access list :param enabled: bool (optional)   Specifies whether this IP access list is enabled. :param ip_addresses: List[str] (optional) :param label: str (optional)   Label for the IP access list. This **cannot** be empty. :param list_type: :class:`ListType` (optional)",ip_access_lists,update,update,
settings.json,/api/2.0/accounts/{account_id}/settings/types/llm_proxy_partner_powered/names/default,llm_proxy_partner_powered_account_get,get,LlmProxyPartnerPoweredAccount,"settings, llm_proxy_partner_powered_account",etag,Gets the enable partner powered AI features account setting.,"Gets the enable partner powered AI features account setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`LlmProxyPartnerPoweredAccount`",llm_proxy_partner_powered_account,get,select,
settings.json,/api/2.0/accounts/{account_id}/settings/types/llm_proxy_partner_powered/names/default,llm_proxy_partner_powered_account_update,patch,LlmProxyPartnerPoweredAccount,"settings, llm_proxy_partner_powered_account","allow_missing, setting, field_mask",Updates the enable partner powered AI features account setting.,"Updates the enable partner powered AI features account setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`LlmProxyPartnerPoweredAccount` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`LlmProxyPartnerPoweredAccount`",llm_proxy_partner_powered_account,update,update,
settings.json,/api/2.0/accounts/{account_id}/settings/types/llm_proxy_partner_powered_enforce/names/default,llm_proxy_partner_powered_enforce_get,get,LlmProxyPartnerPoweredEnforce,"settings, llm_proxy_partner_powered_enforce",etag,Gets the enforcement status of partner powered AI features account setting.,"Gets the enforcement status of partner powered AI features account setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`LlmProxyPartnerPoweredEnforce`",llm_proxy_partner_powered_enforce,get,select,
settings.json,/api/2.0/accounts/{account_id}/settings/types/llm_proxy_partner_powered_enforce/names/default,llm_proxy_partner_powered_enforce_update,patch,LlmProxyPartnerPoweredEnforce,"settings, llm_proxy_partner_powered_enforce","allow_missing, setting, field_mask",Updates the enable enforcement status of partner powered AI features account setting.,"Updates the enable enforcement status of partner powered AI features account setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`LlmProxyPartnerPoweredEnforce` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`LlmProxyPartnerPoweredEnforce`",llm_proxy_partner_powered_enforce,update,update,
settings.json,/api/2.0/settings/types/llm_proxy_partner_powered/names/default,llm_proxy_partner_powered_workspace_delete,delete,DeleteLlmProxyPartnerPoweredWorkspaceResponse,"settings, llm_proxy_partner_powered_workspace",etag,Reverts the enable partner powered AI features workspace setting to its default value.,"Reverts the enable partner powered AI features workspace setting to its default value.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteLlmProxyPartnerPoweredWorkspaceResponse`",llm_proxy_partner_powered_workspace,delete,delete,
settings.json,/api/2.0/settings/types/llm_proxy_partner_powered/names/default,llm_proxy_partner_powered_workspace_get,get,LlmProxyPartnerPoweredWorkspace,"settings, llm_proxy_partner_powered_workspace",etag,Gets the enable partner powered AI features workspace setting.,"Gets the enable partner powered AI features workspace setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`LlmProxyPartnerPoweredWorkspace`",llm_proxy_partner_powered_workspace,get,select,
settings.json,/api/2.0/settings/types/llm_proxy_partner_powered/names/default,llm_proxy_partner_powered_workspace_update,patch,LlmProxyPartnerPoweredWorkspace,"settings, llm_proxy_partner_powered_workspace","allow_missing, setting, field_mask",Updates the enable partner powered AI features workspace setting.,"Updates the enable partner powered AI features workspace setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`LlmProxyPartnerPoweredWorkspace` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`LlmProxyPartnerPoweredWorkspace`",llm_proxy_partner_powered_workspace,update,update,
settings.json,/api/2.0/notification-destinations,notification_destinations_create,post,NotificationDestination,"settings, notification_destinations","config, display_name",Creates a notification destination. Requires workspace admin permissions.,Creates a notification destination. Requires workspace admin permissions.  :param config: :class:`Config` (optional)   The configuration for the notification destination. Must wrap EXACTLY one of the nested configs. :param display_name: str (optional)   The display name for the notification destination.  :returns: :class:`NotificationDestination`,notification_destinations,create,insert,
settings.json,/api/2.0/notification-destinations,notification_destinations_list,get,ListNotificationDestinationsResponse,"settings, notification_destinations","page_size, page_token",Lists notification destinations.,Lists notification destinations.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ListNotificationDestinationsResult`,notification_destinations,list,select,$.results
settings.json,/api/2.0/notification-destinations/{id},notification_destinations_delete,delete,,"settings, notification_destinations",id,Deletes a notification destination. Requires workspace admin permissions.,Deletes a notification destination. Requires workspace admin permissions.  :param id: str,notification_destinations,delete,delete,
settings.json,/api/2.0/notification-destinations/{id},notification_destinations_get,get,NotificationDestination,"settings, notification_destinations",id,Gets a notification destination.,Gets a notification destination.  :param id: str  :returns: :class:`NotificationDestination`,notification_destinations,get,select,
settings.json,/api/2.0/notification-destinations/{id},notification_destinations_update,patch,NotificationDestination,"settings, notification_destinations","id, config, display_name",Updates a notification destination. Requires workspace admin permissions. At least one field is,Updates a notification destination. Requires workspace admin permissions. At least one field is required in the request body.  :param id: str   UUID identifying notification destination. :param config: :class:`Config` (optional)   The configuration for the notification destination. Must wrap EXACTLY one of the nested configs. :param display_name: str (optional)   The display name for the notification destination.  :returns: :class:`NotificationDestination`,notification_destinations,update,update,
settings.json,/api/2.0/accounts/{account_id}/settings/types/dcp_acct_enable/names/default,personal_compute_delete,delete,DeletePersonalComputeSettingResponse,"settings, personal_compute",etag,Reverts back the Personal Compute setting value to default (ON),"Reverts back the Personal Compute setting value to default (ON)  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeletePersonalComputeSettingResponse`",personal_compute,delete,delete,
settings.json,/api/2.0/accounts/{account_id}/settings/types/dcp_acct_enable/names/default,personal_compute_get,get,PersonalComputeSetting,"settings, personal_compute",etag,Gets the value of the Personal Compute setting.,"Gets the value of the Personal Compute setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`PersonalComputeSetting`",personal_compute,get,select,
settings.json,/api/2.0/accounts/{account_id}/settings/types/dcp_acct_enable/names/default,personal_compute_update,patch,PersonalComputeSetting,"settings, personal_compute","allow_missing, setting, field_mask",Updates the value of the Personal Compute setting.,"Updates the value of the Personal Compute setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`PersonalComputeSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`PersonalComputeSetting`",personal_compute,update,update,
settings.json,/api/2.0/settings/types/restrict_workspace_admins/names/default,restrict_workspace_admins_delete,delete,DeleteRestrictWorkspaceAdminsSettingResponse,"settings, restrict_workspace_admins",etag,Reverts the restrict workspace admins setting status for the workspace. A fresh etag needs to be,"Reverts the restrict workspace admins setting status for the workspace. A fresh etag needs to be provided in `DELETE` requests (as a query parameter). The etag can be retrieved by making a `GET` request before the DELETE request. If the setting is updated/deleted concurrently, `DELETE` fails with 409 and the request must be retried by using the fresh etag in the 409 response.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteRestrictWorkspaceAdminsSettingResponse`",restrict_workspace_admins,delete,delete,
settings.json,/api/2.0/settings/types/restrict_workspace_admins/names/default,restrict_workspace_admins_get,get,RestrictWorkspaceAdminsSetting,"settings, restrict_workspace_admins",etag,Gets the restrict workspace admins setting.,"Gets the restrict workspace admins setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`RestrictWorkspaceAdminsSetting`",restrict_workspace_admins,get,select,
settings.json,/api/2.0/settings/types/restrict_workspace_admins/names/default,restrict_workspace_admins_update,patch,RestrictWorkspaceAdminsSetting,"settings, restrict_workspace_admins","allow_missing, setting, field_mask",Updates the restrict workspace admins setting for the workspace. A fresh etag needs to be provided in,"Updates the restrict workspace admins setting for the workspace. A fresh etag needs to be provided in `PATCH` requests (as part of the setting field). The etag can be retrieved by making a GET request before the `PATCH` request. If the setting is updated concurrently, `PATCH` fails with 409 and the request must be retried by using the fresh etag in the 409 response.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`RestrictWorkspaceAdminsSetting` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`RestrictWorkspaceAdminsSetting`",restrict_workspace_admins,update,update,
settings.json,/api/2.0/settings/types/sql_results_download/names/default,sql_results_download_delete,delete,DeleteSqlResultsDownloadResponse,"settings, sql_results_download",etag,Reverts the SQL Results Download setting to its default value.,"Reverts the SQL Results Download setting to its default value.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`DeleteSqlResultsDownloadResponse`",sql_results_download,delete,delete,
settings.json,/api/2.0/settings/types/sql_results_download/names/default,sql_results_download_get,get,SqlResultsDownload,"settings, sql_results_download",etag,Gets the SQL Results Download setting.,"Gets the SQL Results Download setting.  :param etag: str (optional)   etag used for versioning. The response is at least as fresh as the eTag provided. This is used for   optimistic concurrency control as a way to help prevent simultaneous writes of a setting overwriting   each other. It is strongly suggested that systems make use of the etag in the read -> delete pattern   to perform setting deletions in order to avoid race conditions. That is, get an etag from a GET   request, and pass it with the DELETE request to identify the rule set version you are deleting.  :returns: :class:`SqlResultsDownload`",sql_results_download,get,select,
settings.json,/api/2.0/settings/types/sql_results_download/names/default,sql_results_download_update,patch,SqlResultsDownload,"settings, sql_results_download","allow_missing, setting, field_mask",Updates the SQL Results Download setting.,"Updates the SQL Results Download setting.  :param allow_missing: bool   This should always be set to true for Settings API. Added for AIP compliance. :param setting: :class:`SqlResultsDownload` :param field_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`SqlResultsDownload`",sql_results_download,update,update,
settings.json,/api/2.0/token-management/on-behalf-of/tokens,token_management_create_obo_token,post,CreateOboTokenResponse,"settings, token_management","application_id, comment, lifetime_seconds",Creates a token on behalf of a service principal.,Creates a token on behalf of a service principal.  :param application_id: str   Application ID of the service principal. :param comment: str (optional)   Comment that describes the purpose of the token. :param lifetime_seconds: int (optional)   The number of seconds before the token expires.  :returns: :class:`CreateOboTokenResponse`,token_management,create,insert,
settings.json,/api/2.0/token-management/tokens/{token_id},token_management_delete,delete,,"settings, token_management",token_id,"Deletes a token, specified by its ID.","Deletes a token, specified by its ID.  :param token_id: str   The ID of the token to revoke.",token_management,delete,delete,
settings.json,/api/2.0/token-management/tokens/{token_id},token_management_get,get,GetTokenResponse,"settings, token_management",token_id,"Gets information about a token, specified by its ID.","Gets information about a token, specified by its ID.  :param token_id: str   The ID of the token to get.  :returns: :class:`GetTokenResponse`",token_management,get,select,
settings.json,/api/2.0/token-management/tokens,token_management_list,get,ListTokensResponse,"settings, token_management","created_by_id, created_by_username",Lists all tokens associated with the specified workspace or user.,Lists all tokens associated with the specified workspace or user.  :param created_by_id: int (optional)   User ID of the user that created the token. :param created_by_username: str (optional)   Username of the user that created the token.  :returns: Iterator over :class:`TokenInfo`,token_management,list,select,$.token_infos
settings.json,/api/2.0/permissions/authorization/tokens/permissionLevels,token_management_get_permission_levels,get,GetTokenPermissionLevelsResponse,"settings, token_management",,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.   :returns: :class:`GetTokenPermissionLevelsResponse`,token_permission_levels,get,select,
settings.json,/api/2.0/permissions/authorization/tokens,token_management_get_permissions,get,TokenPermissions,"settings, token_management",,Gets the permissions of all tokens. Tokens can inherit permissions from their root object.,Gets the permissions of all tokens. Tokens can inherit permissions from their root object.   :returns: :class:`TokenPermissions`,token_permissions,get,select,
settings.json,/api/2.0/permissions/authorization/tokens,token_management_set_permissions,put,TokenPermissions,"settings, token_management",access_control_list,"Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param access_control_list: List[:class:`TokenAccessControlRequest`] (optional)  :returns: :class:`TokenPermissions`",token_permissions,set,replace,
settings.json,/api/2.0/permissions/authorization/tokens,token_management_update_permissions,patch,TokenPermissions,"settings, token_management",access_control_list,Updates the permissions on all tokens. Tokens can inherit permissions from their root object.,Updates the permissions on all tokens. Tokens can inherit permissions from their root object.  :param access_control_list: List[:class:`TokenAccessControlRequest`] (optional)  :returns: :class:`TokenPermissions`,token_permissions,update,update,
settings.json,/api/2.0/token/create,tokens_create,post,CreateTokenResponse,"settings, tokens","comment, lifetime_seconds","Creates and returns a token for a user. If this call is made through token authentication, it creates","Creates and returns a token for a user. If this call is made through token authentication, it creates a token with the same client ID as the authenticated token. If the user's token quota is exceeded, this call returns an error **QUOTA_EXCEEDED**.  :param comment: str (optional)   Optional description to attach to the token. :param lifetime_seconds: int (optional)   The lifetime of the token, in seconds.    If the lifetime is not specified, this token remains valid for 2 years.  :returns: :class:`CreateTokenResponse`",tokens,create,insert,
settings.json,/api/2.0/token/delete,tokens_delete,post,,"settings, tokens",token_id,Revokes an access token.,"Revokes an access token.  If a token with the specified ID is not valid, this call returns an error **RESOURCE_DOES_NOT_EXIST**.  :param token_id: str   The ID of the token to be revoked.",tokens,delete,exec,
settings.json,/api/2.0/token/list,tokens_list,get,ListPublicTokensResponse,"settings, tokens",,Lists all the valid tokens for a user-workspace pair.,Lists all the valid tokens for a user-workspace pair.   :returns: Iterator over :class:`PublicTokenInfo`,tokens,list,select,$.token_infos
settings.json,/api/2.0/workspace-conf,workspace_conf_get_status,get,,"settings, workspace_conf",keys,Gets the configuration status for a workspace.,"Gets the configuration status for a workspace.  :param keys: str  :returns: Dict[str,str]",workspace_config,get_workspace_config,exec,
settings.json,/api/2.0/workspace-conf,workspace_conf_set_status,patch,,"settings, workspace_conf",contents,"Sets the configuration status for a workspace, including enabling or disabling it.","Sets the configuration status for a workspace, including enabling or disabling it.",workspace_config,set_workspace_config,exec,
settingsv2.json,/api/2.1/settings/{name},workspace_settings_v2_get_public_workspace_setting,get,Setting,"settingsv2, workspace_settings_v2",name,Get a setting value at workspace level. See :method:settingsv2/listworkspacesettingsmetadata for list,Get a setting value at workspace level. See :method:settingsv2/listworkspacesettingsmetadata for list of setting available via public APIs.  :param name: str   Name of the setting  :returns: :class:`Setting`,workspace_settings_v2,get,select,
settingsv2.json,/api/2.1/settings/{name},workspace_settings_v2_patch_public_workspace_setting,patch,Setting,"settingsv2, workspace_settings_v2","name, setting",Patch a setting value at workspace level. See :method:settingsv2/listworkspacesettingsmetadata for,"Patch a setting value at workspace level. See :method:settingsv2/listworkspacesettingsmetadata for list of setting available via public APIs at workspace level. To determine the correct field to include in a patch request, refer to the type field of the setting returned in the :method:settingsv2/listworkspacesettingsmetadata response.  Note: Page refresh is required for changes to take effect in UI.  :param name: str   Name of the setting :param setting: :class:`Setting`  :returns: :class:`Setting`",workspace_settings_v2,patch,update,
settingsv2.json,/api/2.1/settings-metadata,workspace_settings_v2_list_workspace_settings_metadata,get,ListAccountSettingsMetadataResponse,"settingsv2, workspace_settings_v2","page_size, page_token",List valid setting keys and metadata. These settings are available to be referenced via GET,"List valid setting keys and metadata. These settings are available to be referenced via GET :method:settingsv2/getpublicworkspacesetting and PATCH :method:settingsv2/patchpublicworkspacesetting APIs  :param page_size: int (optional)   The maximum number of settings to return. The service may return fewer than this value. If   unspecified, at most 200 settings will be returned. The maximum value is 1000; values above 1000   will be coerced to 1000. :param page_token: str (optional)   A page token, received from a previous `ListWorkspaceSettingsMetadataRequest` call. Provide this to   retrieve the subsequent page.    When paginating, all other parameters provided to `ListWorkspaceSettingsMetadataRequest` must match   the call that provided the page token.  :returns: Iterator over :class:`SettingsMetadata`",workspace_settings_v2,list,select,$.settings_metadata
sharing.json,/api/2.1/data-sharing/providers/{provider_name}/shares/{share_name},providers_list_provider_share_assets,get,ListProviderShareAssetsResponse,"sharing, providers","provider_name, share_name, function_max_results, notebook_max_results, table_max_results, volume_max_results",Get arrays of assets associated with a specified provider's share. The caller is the recipient of the,Get arrays of assets associated with a specified provider's share. The caller is the recipient of the share.  :param provider_name: str   The name of the provider who owns the share. :param share_name: str   The name of the share. :param function_max_results: int (optional)   Maximum number of functions to return. :param notebook_max_results: int (optional)   Maximum number of notebooks to return. :param table_max_results: int (optional)   Maximum number of tables to return. :param volume_max_results: int (optional)   Maximum number of volumes to return.  :returns: :class:`ListProviderShareAssetsResponse`,provider_share_assets,list,select,
sharing.json,/api/2.1/unity-catalog/providers/{name}/shares,providers_list_shares,get,ListProviderSharesResponse,"sharing, providers","name, max_results, page_token",Gets an array of a specified provider's shares within the metastore where:,"Gets an array of a specified provider's shares within the metastore where:  * the caller is a metastore admin, or * the caller is the owner.  :param name: str   Name of the provider in which to list shares. :param max_results: int (optional)   Maximum number of shares to return. - when set to 0, the page length is set to a server configured   value (recommended); - when set to a value greater than 0, the page length is the minimum of this   value and a server configured value; - when set to a value less than 0, an invalid parameter error   is returned; - If not set, all valid shares are returned (not recommended). - Note: The number of   returned shares might be less than the specified max_results size, even zero. The only definitive   indication that no further shares can be fetched is when the next_page_token is unset from the   response. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`ProviderShare`",provider_shares,list_shares,select,$.shares
sharing.json,/api/2.1/unity-catalog/providers,providers_create,post,ProviderInfo,"sharing, providers","name, authentication_type, comment, recipient_profile_str",Creates a new authentication provider minimally based on a name and authentication type. The caller,"Creates a new authentication provider minimally based on a name and authentication type. The caller must be an admin on the metastore.  :param name: str   The name of the Provider. :param authentication_type: :class:`AuthenticationType` :param comment: str (optional)   Description about the provider. :param recipient_profile_str: str (optional)   This field is required when the __authentication_type__ is **TOKEN**, **OAUTH_CLIENT_CREDENTIALS**   or not provided.  :returns: :class:`ProviderInfo`",providers,create,insert,
sharing.json,/api/2.1/unity-catalog/providers,providers_list,get,ListProvidersResponse,"sharing, providers","data_provider_global_metastore_id, max_results, page_token","Gets an array of available authentication providers. The caller must either be a metastore admin, have","Gets an array of available authentication providers. The caller must either be a metastore admin, have the **USE_PROVIDER** privilege on the providers, or be the owner of the providers. Providers not owned by the caller and for which the caller does not have the **USE_PROVIDER** privilege are not included in the response. There is no guarantee of a specific ordering of the elements in the array.  :param data_provider_global_metastore_id: str (optional)   If not provided, all providers will be returned. If no providers exist with this ID, no results will   be returned. :param max_results: int (optional)   Maximum number of providers to return. - when set to 0, the page length is set to a server   configured value (recommended); - when set to a value greater than 0, the page length is the minimum   of this value and a server configured value; - when set to a value less than 0, an invalid parameter   error is returned; - If not set, all valid providers are returned (not recommended). - Note: The   number of returned providers might be less than the specified max_results size, even zero. The only   definitive indication that no further providers can be fetched is when the next_page_token is unset   from the response. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`ProviderInfo`",providers,list,select,$.providers
sharing.json,/api/2.1/unity-catalog/providers/{name},providers_delete,delete,,"sharing, providers",name,"Deletes an authentication provider, if the caller is a metastore admin or is the owner of the","Deletes an authentication provider, if the caller is a metastore admin or is the owner of the provider.  :param name: str   Name of the provider.",providers,delete,delete,
sharing.json,/api/2.1/unity-catalog/providers/{name},providers_get,get,ProviderInfo,"sharing, providers",name,"Gets a specific authentication provider. The caller must supply the name of the provider, and must","Gets a specific authentication provider. The caller must supply the name of the provider, and must either be a metastore admin or the owner of the provider.  :param name: str   Name of the provider.  :returns: :class:`ProviderInfo`",providers,get,select,
sharing.json,/api/2.1/unity-catalog/providers/{name},providers_update,patch,ProviderInfo,"sharing, providers","name, comment, new_name, owner, recipient_profile_str","Updates the information for an authentication provider, if the caller is a metastore admin or is the","Updates the information for an authentication provider, if the caller is a metastore admin or is the owner of the provider. If the update changes the provider name, the caller must be both a metastore admin and the owner of the provider.  :param name: str   Name of the provider. :param comment: str (optional)   Description about the provider. :param new_name: str (optional)   New name for the provider. :param owner: str (optional)   Username of Provider owner. :param recipient_profile_str: str (optional)   This field is required when the __authentication_type__ is **TOKEN**, **OAUTH_CLIENT_CREDENTIALS**   or not provided.  :returns: :class:`ProviderInfo`",providers,update,update,
sharing.json,/api/2.1/unity-catalog/public/data_sharing_activation_info/{activation_url},recipient_activation_get_activation_url_info,get,,"sharing, recipient_activation",activation_url,Gets an activation URL for a share.,Gets an activation URL for a share.  :param activation_url: str   The one time activation url. It also accepts activation token.,recipient_activation,get_url,exec,
sharing.json,/api/2.1/unity-catalog/public/data_sharing_activation/{activation_url},recipient_activation_retrieve_token,get,RetrieveTokenResponse,"sharing, recipient_activation",activation_url,Retrieve access token with an activation url. This is a public API without any authentication.,Retrieve access token with an activation url. This is a public API without any authentication.  :param activation_url: str   The one time activation url. It also accepts activation token.  :returns: :class:`RetrieveTokenResponse`,recipient_activation,retrieve_token,exec,
sharing.json,/api/2.0/data-sharing/recipients/{recipient_name}/federation-policies,recipient_federation_policies_create,post,FederationPolicy,"sharing, recipient_federation_policies","recipient_name, policy",Create a federation policy for an OIDC_FEDERATION recipient for sharing data from Databricks to,"Create a federation policy for an OIDC_FEDERATION recipient for sharing data from Databricks to non-Databricks recipients. The caller must be the owner of the recipient. When sharing data from Databricks to non-Databricks clients, you can define a federation policy to authenticate non-Databricks recipients. The federation policy validates OIDC claims in federated tokens and is defined at the recipient level. This enables secretless sharing clients to authenticate using OIDC tokens.  Supported scenarios for federation policies: 1. **User-to-Machine (U2M) flow** (e.g., PowerBI): A user accesses a resource using their own identity. 2. **Machine-to-Machine (M2M) flow** (e.g., OAuth App): An OAuth App accesses a resource using its own identity, typically for tasks like running nightly jobs.  For an overview, refer to: - Blog post: Overview of feature: https://www.databricks.com/blog/announcing-oidc-token-federation-enhanced-delta-sharing-security  For detailed configuration guides based on your use case: - Creating a Federation Policy as a provider: https://docs.databricks.com/en/delta-sharing/create-recipient-oidc-fed - Configuration and usage for Machine-to-Machine (M2M) applications (e.g., Python Delta Sharing Client): https://docs.databricks.com/aws/en/delta-sharing/sharing-over-oidc-m2m - Configuration and usage for User-to-Machine (U2M) applications (e.g., PowerBI): https://docs.databricks.com/aws/en/delta-sharing/sharing-over-oidc-u2m  :param recipient_name: str   Name of the recipient. This is the name of the recipient for which the policy is being created. :param policy: :class:`FederationPolicy`   Name of the policy. This is the name of the policy to be created.  :returns: :class:`FederationPolicy`",recipient_federation_policies,create,insert,
sharing.json,/api/2.0/data-sharing/recipients/{recipient_name}/federation-policies,recipient_federation_policies_list,get,ListFederationPoliciesResponse,"sharing, recipient_federation_policies","recipient_name, max_results, page_token",Lists federation policies for an OIDC_FEDERATION recipient for sharing data from Databricks to,Lists federation policies for an OIDC_FEDERATION recipient for sharing data from Databricks to non-Databricks recipients. The caller must have read access to the recipient.  :param recipient_name: str   Name of the recipient. This is the name of the recipient for which the policies are being listed. :param max_results: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`FederationPolicy`,recipient_federation_policies,list,select,$.policies
sharing.json,/api/2.0/data-sharing/recipients/{recipient_name}/federation-policies/{name},recipient_federation_policies_delete,delete,,"sharing, recipient_federation_policies","recipient_name, name",Deletes an existing federation policy for an OIDC_FEDERATION recipient. The caller must be the owner,Deletes an existing federation policy for an OIDC_FEDERATION recipient. The caller must be the owner of the recipient.  :param recipient_name: str   Name of the recipient. This is the name of the recipient for which the policy is being deleted. :param name: str   Name of the policy. This is the name of the policy to be deleted.,recipient_federation_policies,delete,delete,
sharing.json,/api/2.0/data-sharing/recipients/{recipient_name}/federation-policies/{name},recipient_federation_policies_get_federation_policy,get,FederationPolicy,"sharing, recipient_federation_policies","recipient_name, name",Reads an existing federation policy for an OIDC_FEDERATION recipient for sharing data from Databricks,Reads an existing federation policy for an OIDC_FEDERATION recipient for sharing data from Databricks to non-Databricks recipients. The caller must have read access to the recipient.  :param recipient_name: str   Name of the recipient. This is the name of the recipient for which the policy is being retrieved. :param name: str   Name of the policy. This is the name of the policy to be retrieved.  :returns: :class:`FederationPolicy`,recipient_federation_policies,get,select,
sharing.json,/api/2.1/unity-catalog/recipients/{name}/share-permissions,recipients_share_permissions,get,GetRecipientSharePermissionsResponse,"sharing, recipients","name, max_results, page_token",Gets the share permissions for the specified Recipient. The caller must have the **USE_RECIPIENT**,"Gets the share permissions for the specified Recipient. The caller must have the **USE_RECIPIENT** privilege on the metastore or be the owner of the Recipient.  :param name: str   The name of the Recipient. :param max_results: int (optional)   Maximum number of permissions to return. - when set to 0, the page length is set to a server   configured value (recommended); - when set to a value greater than 0, the page length is the minimum   of this value and a server configured value; - when set to a value less than 0, an invalid parameter   error is returned; - If not set, all valid permissions are returned (not recommended). - Note: The   number of returned permissions might be less than the specified max_results size, even zero. The   only definitive indication that no further permissions can be fetched is when the next_page_token is   unset from the response. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: :class:`GetRecipientSharePermissionsResponse`",recipient_share_permissions,list,select,
sharing.json,/api/2.1/unity-catalog/recipients,recipients_create,post,RecipientInfo,"sharing, recipients","name, authentication_type, comment, data_recipient_global_metastore_id, expiration_time, id, ip_access_list, owner, properties_kvpairs, sharing_code",Creates a new recipient with the delta sharing authentication type in the metastore. The caller must,"Creates a new recipient with the delta sharing authentication type in the metastore. The caller must be a metastore admin or have the **CREATE_RECIPIENT** privilege on the metastore.  :param name: str   Name of Recipient. :param authentication_type: :class:`AuthenticationType` :param comment: str (optional)   Description about the recipient. :param data_recipient_global_metastore_id: str (optional)   The global Unity Catalog metastore id provided by the data recipient. This field is only present   when the __authentication_type__ is **DATABRICKS**. The identifier is of format   __cloud__:__region__:__metastore-uuid__. :param expiration_time: int (optional)   Expiration timestamp of the token, in epoch milliseconds. :param id: str (optional)   [Create,Update:IGN] common - id of the recipient :param ip_access_list: :class:`IpAccessList` (optional)   IP Access List :param owner: str (optional)   Username of the recipient owner. :param properties_kvpairs: :class:`SecurablePropertiesKvPairs` (optional)   Recipient properties as map of string key-value pairs. When provided in update request, the   specified properties will override the existing properties. To add and remove properties, one would   need to perform a read-modify-write. :param sharing_code: str (optional)   The one-time sharing code provided by the data recipient. This field is only present when the   __authentication_type__ is **DATABRICKS**.  :returns: :class:`RecipientInfo`",recipients,create,insert,
sharing.json,/api/2.1/unity-catalog/recipients,recipients_list,get,ListRecipientsResponse,"sharing, recipients","data_recipient_global_metastore_id, max_results, page_token",Gets an array of all share recipients within the current metastore where:,"Gets an array of all share recipients within the current metastore where:  * the caller is a metastore admin, or * the caller is the owner. There is no guarantee of a specific ordering of the elements in the array.  :param data_recipient_global_metastore_id: str (optional)   If not provided, all recipients will be returned. If no recipients exist with this ID, no results   will be returned. :param max_results: int (optional)   Maximum number of recipients to return. - when set to 0, the page length is set to a server   configured value (recommended); - when set to a value greater than 0, the page length is the minimum   of this value and a server configured value; - when set to a value less than 0, an invalid parameter   error is returned; - If not set, all valid recipients are returned (not recommended). - Note: The   number of returned recipients might be less than the specified max_results size, even zero. The only   definitive indication that no further recipients can be fetched is when the next_page_token is unset   from the response. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`RecipientInfo`",recipients,list,select,$.recipients
sharing.json,/api/2.1/unity-catalog/recipients/{name},recipients_delete,delete,,"sharing, recipients",name,Deletes the specified recipient from the metastore. The caller must be the owner of the recipient.,Deletes the specified recipient from the metastore. The caller must be the owner of the recipient.  :param name: str   Name of the recipient.,recipients,delete,delete,
sharing.json,/api/2.1/unity-catalog/recipients/{name},recipients_get,get,RecipientInfo,"sharing, recipients",name,Gets a share recipient from the metastore. The caller must be one of: * A user with **USE_RECIPIENT**,Gets a share recipient from the metastore. The caller must be one of: * A user with **USE_RECIPIENT** privilege on the metastore * The owner of the share recipient * A metastore admin  :param name: str   Name of the recipient.  :returns: :class:`RecipientInfo`,recipients,get,select,
sharing.json,/api/2.1/unity-catalog/recipients/{name},recipients_update,patch,RecipientInfo,"sharing, recipients","name, comment, expiration_time, id, ip_access_list, new_name, owner, properties_kvpairs",Updates an existing recipient in the metastore. The caller must be a metastore admin or the owner of,"Updates an existing recipient in the metastore. The caller must be a metastore admin or the owner of the recipient. If the recipient name will be updated, the user must be both a metastore admin and the owner of the recipient.  :param name: str   Name of the recipient. :param comment: str (optional)   Description about the recipient. :param expiration_time: int (optional)   Expiration timestamp of the token, in epoch milliseconds. :param id: str (optional)   [Create,Update:IGN] common - id of the recipient :param ip_access_list: :class:`IpAccessList` (optional)   IP Access List :param new_name: str (optional)   New name for the recipient. . :param owner: str (optional)   Username of the recipient owner. :param properties_kvpairs: :class:`SecurablePropertiesKvPairs` (optional)   Recipient properties as map of string key-value pairs. When provided in update request, the   specified properties will override the existing properties. To add and remove properties, one would   need to perform a read-modify-write.  :returns: :class:`RecipientInfo`",recipients,update,update,
sharing.json,/api/2.1/unity-catalog/recipients/{name}/rotate-token,recipients_rotate_token,post,RecipientInfo,"sharing, recipients","name, existing_token_expire_in_seconds",Refreshes the specified recipient's delta sharing authentication token with the provided token info.,"Refreshes the specified recipient's delta sharing authentication token with the provided token info. The caller must be the owner of the recipient.  :param name: str   The name of the Recipient. :param existing_token_expire_in_seconds: int   The expiration time of the bearer token in ISO 8601 format. This will set the expiration_time of   existing token only to a smaller timestamp, it cannot extend the expiration_time. Use 0 to expire   the existing token immediately, negative number will return an error.  :returns: :class:`RecipientInfo`",recipients,rotate_token,insert,
sharing.json,/api/2.1/unity-catalog/shares/{name}/permissions,shares_share_permissions,get,GetSharePermissionsResponse,"sharing, shares","name, max_results, page_token",Gets the permissions for a data share from the metastore. The caller must have the USE_SHARE privilege,"Gets the permissions for a data share from the metastore. The caller must have the USE_SHARE privilege on the metastore or be the owner of the share.  :param name: str   The name of the Recipient. :param max_results: int (optional)   Maximum number of permissions to return. - when set to 0, the page length is set to a server   configured value (recommended); - when set to a value greater than 0, the page length is the minimum   of this value and a server configured value; - when set to a value less than 0, an invalid parameter   error is returned; - If not set, all valid permissions are returned (not recommended). - Note: The   number of returned permissions might be less than the specified max_results size, even zero. The   only definitive indication that no further permissions can be fetched is when the next_page_token is   unset from the response. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: :class:`GetSharePermissionsResponse`",share_permissions,list,select,
sharing.json,/api/2.1/unity-catalog/shares/{name}/permissions,shares_update_permissions,patch,UpdateSharePermissionsResponse,"sharing, shares","name, changes, omit_permissions_list",Updates the permissions for a data share in the metastore. The caller must have both the USE_SHARE and,"Updates the permissions for a data share in the metastore. The caller must have both the USE_SHARE and SET_SHARE_PERMISSION privileges on the metastore, or be the owner of the share.  For new recipient grants, the user must also be the owner of the recipients. recipient revocations do not require additional privileges.  :param name: str   The name of the share. :param changes: List[:class:`PermissionsChange`] (optional)   Array of permissions change objects. :param omit_permissions_list: bool (optional)   Optional. Whether to return the latest permissions list of the share in the response.  :returns: :class:`UpdateSharePermissionsResponse`",share_permissions,update,update,
sharing.json,/api/2.1/unity-catalog/shares,shares_create,post,ShareInfo,"sharing, shares","name, comment, storage_root",Creates a new share for data objects. Data objects can be added after creation with **update**. The,Creates a new share for data objects. Data objects can be added after creation with **update**. The caller must be a metastore admin or have the **CREATE_SHARE** privilege on the metastore.  :param name: str   Name of the share. :param comment: str (optional)   User-provided free-form text description. :param storage_root: str (optional)   Storage root URL for the share.  :returns: :class:`ShareInfo`,shares,create,insert,
sharing.json,/api/2.1/unity-catalog/shares,shares_list_shares,get,ListSharesResponse,"sharing, shares","max_results, page_token",Gets an array of data object shares from the metastore. If the caller has the USE_SHARE privilege on,"Gets an array of data object shares from the metastore. If the caller has the USE_SHARE privilege on the metastore, all shares are returned. Otherwise, only shares owned by the caller are returned. There is no guarantee of a specific ordering of the elements in the array.  :param max_results: int (optional)   Maximum number of shares to return. - when set to 0, the page length is set to a server configured   value (recommended); - when set to a value greater than 0, the page length is the minimum of this   value and a server configured value; - when set to a value less than 0, an invalid parameter error   is returned; - If not set, all valid shares are returned (not recommended). - Note: The number of   returned shares might be less than the specified max_results size, even zero. The only definitive   indication that no further shares can be fetched is when the next_page_token is unset from the   response. :param page_token: str (optional)   Opaque pagination token to go to next page based on previous query.  :returns: Iterator over :class:`ShareInfo`",shares,list,select,$.shares
sharing.json,/api/2.1/unity-catalog/shares/{name},shares_delete,delete,,"sharing, shares",name,Deletes a data object share from the metastore. The caller must be an owner of the share.,Deletes a data object share from the metastore. The caller must be an owner of the share.  :param name: str   The name of the share.,shares,delete,delete,
sharing.json,/api/2.1/unity-catalog/shares/{name},shares_get,get,ShareInfo,"sharing, shares","name, include_shared_data",Gets a data object share from the metastore. The caller must have the USE_SHARE privilege on the,Gets a data object share from the metastore. The caller must have the USE_SHARE privilege on the metastore or be the owner of the share.  :param name: str   The name of the share. :param include_shared_data: bool (optional)   Query for data to include in the share.  :returns: :class:`ShareInfo`,shares,get,select,
sharing.json,/api/2.1/unity-catalog/shares/{name},shares_update,patch,ShareInfo,"sharing, shares","name, comment, new_name, owner, storage_root, updates",Updates the share with the changes and data objects in the request. The caller must be the owner of,"Updates the share with the changes and data objects in the request. The caller must be the owner of the share or a metastore admin.  When the caller is a metastore admin, only the __owner__ field can be updated.  In the case the share name is changed, **updateShare** requires that the caller is the owner of the share and has the CREATE_SHARE privilege.  If there are notebook files in the share, the __storage_root__ field cannot be updated.  For each table that is added through this method, the share owner must also have **SELECT** privilege on the table. This privilege must be maintained indefinitely for recipients to be able to access the table. Typically, you should use a group as the share owner.  Table removals through **update** do not require additional privileges.  :param name: str   The name of the share. :param comment: str (optional)   User-provided free-form text description. :param new_name: str (optional)   New name for the share. :param owner: str (optional)   Username of current owner of share. :param storage_root: str (optional)   Storage root URL for the share. :param updates: List[:class:`SharedDataObjectUpdate`] (optional)   Array of shared data object updates.  :returns: :class:`ShareInfo`",shares,update,update,
sql.json,/api/2.0/sql/alerts,alerts_create,post,Alert,"sql, alerts","alert, auto_resolve_display_name",Creates an alert.,"Creates an alert.  :param alert: :class:`CreateAlertRequestAlert` (optional) :param auto_resolve_display_name: bool (optional)   If true, automatically resolve alert display name conflicts. Otherwise, fail the request if the   alert's display name conflicts with an existing alert's display name.  :returns: :class:`Alert`",alerts,create,insert,
sql.json,/api/2.0/sql/alerts,alerts_list,get,ListAlertsResponse,"sql, alerts","page_size, page_token","Gets a list of alerts accessible to the user, ordered by creation time. **Warning:** Calling this API","Gets a list of alerts accessible to the user, ordered by creation time. **Warning:** Calling this API concurrently 10 or more times could result in throttling, service degradation, or a temporary ban.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ListAlertsResponseAlert`",alerts,list,select,$.results
sql.json,/api/2.0/sql/alerts/{id},alerts_delete,delete,,"sql, alerts",id,"Moves an alert to the trash. Trashed alerts immediately disappear from searches and list views, and","Moves an alert to the trash. Trashed alerts immediately disappear from searches and list views, and can no longer trigger. You can restore a trashed alert through the UI. A trashed alert is permanently deleted after 30 days.  :param id: str",alerts,delete,delete,
sql.json,/api/2.0/sql/alerts/{id},alerts_get,get,Alert,"sql, alerts",id,Gets an alert.,Gets an alert.  :param id: str  :returns: :class:`Alert`,alerts,get,select,
sql.json,/api/2.0/sql/alerts/{id},alerts_update,patch,Alert,"sql, alerts","id, update_mask, alert, auto_resolve_display_name",Updates an alert.,"Updates an alert.  :param id: str :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future. :param alert: :class:`UpdateAlertRequestAlert` (optional) :param auto_resolve_display_name: bool (optional)   If true, automatically resolve alert display name conflicts. Otherwise, fail the request if the   alert's display name conflicts with an existing alert's display name.  :returns: :class:`Alert`",alerts,update,update,
sql.json,/api/2.0/preview/sql/alerts,alerts_legacy_create,post,LegacyAlert,"sql, alerts_legacy","name, options, query_id, parent, rearm","Creates an alert. An alert is a Databricks SQL object that periodically runs a query, evaluates a","Creates an alert. An alert is a Databricks SQL object that periodically runs a query, evaluates a condition of its result, and notifies users or notification destinations if the condition was met.  **Warning**: This API is deprecated. Please use :method:alerts/create instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param name: str   Name of the alert. :param options: :class:`AlertOptions`   Alert configuration options. :param query_id: str   Query ID. :param parent: str (optional)   The identifier of the workspace folder containing the object. :param rearm: int (optional)   Number of seconds after being triggered before the alert rearms itself and can be triggered again.   If `null`, alert will never be triggered again.  :returns: :class:`LegacyAlert`",alerts_legacy,create,insert,
sql.json,/api/2.0/preview/sql/alerts,alerts_legacy_list,get,LegacyAlert,"sql, alerts_legacy",,Gets a list of alerts.,Gets a list of alerts.  **Warning**: This API is deprecated. Please use :method:alerts/list instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html   :returns: Iterator over :class:`LegacyAlert`,alerts_legacy,list,select,
sql.json,/api/2.0/preview/sql/alerts/{alert_id},alerts_legacy_delete,delete,,"sql, alerts_legacy",alert_id,Deletes an alert. Deleted alerts are no longer accessible and cannot be restored. **Note**: Unlike,"Deletes an alert. Deleted alerts are no longer accessible and cannot be restored. **Note**: Unlike queries and dashboards, alerts cannot be moved to the trash.  **Warning**: This API is deprecated. Please use :method:alerts/delete instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param alert_id: str",alerts_legacy,delete,delete,
sql.json,/api/2.0/preview/sql/alerts/{alert_id},alerts_legacy_get,get,LegacyAlert,"sql, alerts_legacy",alert_id,Gets an alert.,Gets an alert.  **Warning**: This API is deprecated. Please use :method:alerts/get instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param alert_id: str  :returns: :class:`LegacyAlert`,alerts_legacy,get,select,
sql.json,/api/2.0/preview/sql/alerts/{alert_id},alerts_legacy_update,put,,"sql, alerts_legacy","alert_id, name, options, query_id, rearm",Updates an alert.,"Updates an alert.  **Warning**: This API is deprecated. Please use :method:alerts/update instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param alert_id: str :param name: str   Name of the alert. :param options: :class:`AlertOptions`   Alert configuration options. :param query_id: str   Query ID. :param rearm: int (optional)   Number of seconds after being triggered before the alert rearms itself and can be triggered again.   If `null`, alert will never be triggered again.",alerts_legacy,update,replace,
sql.json,/api/2.0/alerts,alerts_v2_create_alert,post,AlertV2,"sql, alerts_v2",alert,Create Alert,Create Alert  :param alert: :class:`AlertV2`  :returns: :class:`AlertV2`,alerts_v2,create,insert,
sql.json,/api/2.0/alerts,alerts_v2_list_alerts,get,ListAlertsV2Response,"sql, alerts_v2","page_size, page_token","Gets a list of alerts accessible to the user, ordered by creation time.","Gets a list of alerts accessible to the user, ordered by creation time.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`AlertV2`",alerts_v2,list,select,$.alerts
sql.json,/api/2.0/alerts/{id},alerts_v2_get_alert,get,AlertV2,"sql, alerts_v2",id,Gets an alert.,Gets an alert.  :param id: str  :returns: :class:`AlertV2`,alerts_v2,get,select,
sql.json,/api/2.0/alerts/{id},alerts_v2_trash_alert,delete,,"sql, alerts_v2","id, purge","Moves an alert to the trash. Trashed alerts immediately disappear from list views, and can no longer","Moves an alert to the trash. Trashed alerts immediately disappear from list views, and can no longer trigger. You can restore a trashed alert through the UI. A trashed alert is permanently deleted after 30 days.  :param id: str :param purge: bool (optional)   Whether to permanently delete the alert. If not set, the alert will only be soft deleted.",alerts_v2,delete,delete,
sql.json,/api/2.0/alerts/{id},alerts_v2_update_alert,patch,AlertV2,"sql, alerts_v2","id, update_mask, alert",Update alert,"Update alert  :param id: str   UUID identifying the alert. :param alert: :class:`AlertV2` :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`AlertV2`",alerts_v2,update,update,
sql.json,/api/2.0/preview/sql/widgets,dashboard_widgets_create,post,Widget,"sql, dashboard_widgets","dashboard_id, options, width, text, visualization_id",Adds a widget to a dashboard,"Adds a widget to a dashboard  :param dashboard_id: str   Dashboard ID returned by :method:dashboards/create. :param options: :class:`WidgetOptions` :param width: int   Width of a widget :param text: str (optional)   If this is a textbox widget, the application displays this text. This field is ignored if the widget   contains a visualization in the `visualization` field. :param visualization_id: str (optional)   Query Vizualization ID returned by :method:queryvisualizations/create.  :returns: :class:`Widget`",dashboard_widgets,create,insert,
sql.json,/api/2.0/preview/sql/widgets/{id},dashboard_widgets_delete,delete,,"sql, dashboard_widgets",id,Removes a widget from a dashboard,Removes a widget from a dashboard  :param id: str   Widget ID returned by :method:dashboardwidgets/create,dashboard_widgets,delete,delete,
sql.json,/api/2.0/preview/sql/widgets/{id},dashboard_widgets_update,post,Widget,"sql, dashboard_widgets","id, dashboard_id, options, width, text, visualization_id",Updates an existing widget,"Updates an existing widget  :param id: str   Widget ID returned by :method:dashboardwidgets/create :param dashboard_id: str   Dashboard ID returned by :method:dashboards/create. :param options: :class:`WidgetOptions` :param width: int   Width of a widget :param text: str (optional)   If this is a textbox widget, the application displays this text. This field is ignored if the widget   contains a visualization in the `visualization` field. :param visualization_id: str (optional)   Query Vizualization ID returned by :method:queryvisualizations/create.  :returns: :class:`Widget`",dashboard_widgets,update,insert,
sql.json,/api/2.0/preview/sql/dashboards/{dashboard_id},dashboards_delete,delete,,"sql, dashboards",dashboard_id,"Moves a dashboard to the trash. Trashed dashboards do not appear in list views or searches, and cannot","Moves a dashboard to the trash. Trashed dashboards do not appear in list views or searches, and cannot be shared.  :param dashboard_id: str",dashboards,delete,delete,
sql.json,/api/2.0/preview/sql/dashboards/{dashboard_id},dashboards_get,get,Dashboard,"sql, dashboards",dashboard_id,"Returns a JSON representation of a dashboard object, including its visualization and query objects.","Returns a JSON representation of a dashboard object, including its visualization and query objects.  :param dashboard_id: str  :returns: :class:`Dashboard`",dashboards,get,select,
sql.json,/api/2.0/preview/sql/dashboards/{dashboard_id},dashboards_update,post,Dashboard,"sql, dashboards","dashboard_id, name, run_as_role, tags",Modify this dashboard definition. This operation only affects attributes of the dashboard object. It,"Modify this dashboard definition. This operation only affects attributes of the dashboard object. It does not add, modify, or remove widgets.  **Note**: You cannot undo this operation.  :param dashboard_id: str :param name: str (optional)   The title of this dashboard that appears in list views and at the top of the dashboard page. :param run_as_role: :class:`RunAsRole` (optional)   Sets the **Run as** role for the object. Must be set to one of `""viewer""` (signifying ""run as   viewer"" behavior) or `""owner""` (signifying ""run as owner"" behavior) :param tags: List[str] (optional)  :returns: :class:`Dashboard`",dashboards,update,insert,
sql.json,/api/2.0/preview/sql/dashboards,dashboards_list,get,ListResponse,"sql, dashboards","order, page, page_size, q",Fetch a paginated list of dashboard objects.,"Fetch a paginated list of dashboard objects.  **Warning**: Calling this API concurrently 10 or more times could result in throttling, service degradation, or a temporary ban.  :param order: :class:`ListOrder` (optional)   Name of dashboard attribute to order by. :param page: int (optional)   Page number to retrieve. :param page_size: int (optional)   Number of dashboards to return per page. :param q: str (optional)   Full text search term.  :returns: Iterator over :class:`Dashboard`",dashboards,list,select,$.results
sql.json,/api/2.0/preview/sql/dashboards/trash/{dashboard_id},dashboards_restore,post,,"sql, dashboards",dashboard_id,A restored dashboard appears in list views and searches and can be shared.,A restored dashboard appears in list views and searches and can be shared.  :param dashboard_id: str,dashboards,restore,exec,
sql.json,/api/2.0/preview/sql/data_sources,data_sources_list,get,DataSource,"sql, data_sources",,Retrieves a full list of SQL warehouses available in this workspace. All fields that appear in this,"Retrieves a full list of SQL warehouses available in this workspace. All fields that appear in this API response are enumerated for clarity. However, you need only a SQL warehouse's `id` to create new queries against it.  **Warning**: This API is deprecated. Please use :method:warehouses/list instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html   :returns: Iterator over :class:`DataSource`",data_sources,list,select,
sql.json,/api/2.0/preview/sql/permissions/{object_type.value}/{object_id},dbsql_permissions_get,get,GetResponse,"sql, dbsql_permissions","object_type.value, object_id, object_type",Gets a JSON representation of the access control list (ACL) for a specified object.,Gets a JSON representation of the access control list (ACL) for a specified object.  **Warning**: This API is deprecated. Please use :method:workspace/getpermissions instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param object_type: :class:`ObjectTypePlural`   The type of object permissions to check. :param object_id: str   Object ID. An ACL is returned for the object with this UUID.  :returns: :class:`GetResponse`,dbsql_permissions,get,select,
sql.json,/api/2.0/preview/sql/permissions/{object_type.value}/{object_id},dbsql_permissions_set,post,SetResponse,"sql, dbsql_permissions","object_type.value, object_id, object_type, access_control_list",Sets the access control list (ACL) for a specified object. This operation will complete rewrite the,Sets the access control list (ACL) for a specified object. This operation will complete rewrite the ACL.  **Warning**: This API is deprecated. Please use :method:workspace/setpermissions instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param object_type: :class:`ObjectTypePlural`   The type of object permission to set. :param object_id: str   Object ID. The ACL for the object with this UUID is overwritten by this request's POST content. :param access_control_list: List[:class:`AccessControl`] (optional)  :returns: :class:`SetResponse`,dbsql_permissions,set,insert,
sql.json,/api/2.0/preview/sql/permissions/{object_type.value}/{object_id}/transfer,dbsql_permissions_transfer_ownership,post,Success,"sql, dbsql_permissions","object_type.value, object_id, object_type, new_owner","Transfers ownership of a dashboard, query, or alert to an active user. Requires an admin API key.","Transfers ownership of a dashboard, query, or alert to an active user. Requires an admin API key.  **Warning**: This API is deprecated. For queries and alerts, please use :method:queries/update and :method:alerts/update respectively instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param object_type: :class:`OwnableObjectType`   The type of object on which to change ownership. :param object_id: :class:`TransferOwnershipObjectId`   The ID of the object on which to change ownership. :param new_owner: str (optional)   Email address for the new owner, who must exist in the workspace.  :returns: :class:`Success`",dbsql_permissions,transfer_ownership,exec,
sql.json,/api/warehouses/v1/default-warehouse-overrides,warehouses_create_default_warehouse_override,post,DefaultWarehouseOverride,"sql, warehouses","default_warehouse_override_id, default_warehouse_override",Creates a new default warehouse override for a user. Users can create their own override. Admins can,"Creates a new default warehouse override for a user. Users can create their own override. Admins can create overrides for any user.  :param default_warehouse_override: :class:`DefaultWarehouseOverride`   Required. The default warehouse override to create. :param default_warehouse_override_id: str   Required. The ID to use for the override, which will become the final component of the override's   resource name. Can be a numeric user ID or the literal string ""me"" for the current user.  :returns: :class:`DefaultWarehouseOverride`",default_warehouse_overrides,create,insert,
sql.json,/api/warehouses/v1/default-warehouse-overrides,warehouses_list_default_warehouse_overrides,get,ListDefaultWarehouseOverridesResponse,"sql, warehouses","page_size, page_token",Lists all default warehouse overrides in the workspace. Only workspace administrators can list all,"Lists all default warehouse overrides in the workspace. Only workspace administrators can list all overrides.  :param page_size: int (optional)   The maximum number of overrides to return. The service may return fewer than this value. If   unspecified, at most 100 overrides will be returned. The maximum value is 1000; values above 1000   will be coerced to 1000. :param page_token: str (optional)   A page token, received from a previous `ListDefaultWarehouseOverrides` call. Provide this to   retrieve the subsequent page.    When paginating, all other parameters provided to `ListDefaultWarehouseOverrides` must match the   call that provided the page token.  :returns: Iterator over :class:`DefaultWarehouseOverride`",default_warehouse_overrides,list,select,$.default_warehouse_overrides
sql.json,/api/warehouses/v1/{name},warehouses_delete_default_warehouse_override,delete,,"sql, warehouses",name,Deletes the default warehouse override for a user. Users can delete their own override. Admins can,"Deletes the default warehouse override for a user. Users can delete their own override. Admins can delete overrides for any user. After deletion, the workspace default warehouse will be used.  :param name: str   Required. The resource name of the default warehouse override to delete. Format:   default-warehouse-overrides/{default_warehouse_override_id} The default_warehouse_override_id can be   a numeric user ID or the literal string ""me"" for the current user.",default_warehouse_overrides,delete,delete,
sql.json,/api/warehouses/v1/{name},warehouses_get_default_warehouse_override,get,DefaultWarehouseOverride,"sql, warehouses",name,Returns the default warehouse override for a user. Users can fetch their own override. Admins can,"Returns the default warehouse override for a user. Users can fetch their own override. Admins can fetch overrides for any user. If no override exists, the UI will fallback to the workspace default warehouse.  :param name: str   Required. The resource name of the default warehouse override to retrieve. Format:   default-warehouse-overrides/{default_warehouse_override_id} The default_warehouse_override_id can be   a numeric user ID or the literal string ""me"" for the current user.  :returns: :class:`DefaultWarehouseOverride`",default_warehouse_overrides,get,select,
sql.json,/api/warehouses/v1/{name},warehouses_update_default_warehouse_override,patch,DefaultWarehouseOverride,"sql, warehouses","name, update_mask, allow_missing, default_warehouse_override",Updates an existing default warehouse override for a user. Users can update their own override. Admins,"Updates an existing default warehouse override for a user. Users can update their own override. Admins can update overrides for any user.  :param name: str   The resource name of the default warehouse override. Format:   default-warehouse-overrides/{default_warehouse_override_id} :param default_warehouse_override: :class:`DefaultWarehouseOverride`   Required. The default warehouse override to update. The name field must be set in the format:   default-warehouse-overrides/{default_warehouse_override_id} The default_warehouse_override_id can be   a numeric user ID or the literal string ""me"" for the current user. :param update_mask: FieldMask   Required. Field mask specifying which fields to update. Only the fields specified in the mask will   be updated. Use ""*"" to update all fields. When allow_missing is true, this field is ignored and all   fields are applied. :param allow_missing: bool (optional)   If set to true, and the override is not found, a new override will be created. In this situation,   `update_mask` is ignored and all fields are applied. Defaults to false.  :returns: :class:`DefaultWarehouseOverride`",default_warehouse_overrides,update,update,
sql.json,/api/2.0/sql/queries,queries_create,post,Query,"sql, queries","auto_resolve_display_name, query",Creates a query.,"Creates a query.  :param auto_resolve_display_name: bool (optional)   If true, automatically resolve query display name conflicts. Otherwise, fail the request if the   query's display name conflicts with an existing query's display name. :param query: :class:`CreateQueryRequestQuery` (optional)  :returns: :class:`Query`",queries,create,insert,
sql.json,/api/2.0/sql/queries,queries_list,get,ListQueryObjectsResponse,"sql, queries","page_size, page_token","Gets a list of queries accessible to the user, ordered by creation time. **Warning:** Calling this API","Gets a list of queries accessible to the user, ordered by creation time. **Warning:** Calling this API concurrently 10 or more times could result in throttling, service degradation, or a temporary ban.  :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`ListQueryObjectsResponseQuery`",queries,list,select,$.results
sql.json,/api/2.0/sql/queries/{id},queries_delete,delete,,"sql, queries",id,"Moves a query to the trash. Trashed queries immediately disappear from searches and list views, and","Moves a query to the trash. Trashed queries immediately disappear from searches and list views, and cannot be used for alerts. You can restore a trashed query through the UI. A trashed query is permanently deleted after 30 days.  :param id: str",queries,delete,delete,
sql.json,/api/2.0/sql/queries/{id},queries_get,get,Query,"sql, queries",id,Gets a query.,Gets a query.  :param id: str  :returns: :class:`Query`,queries,get,select,
sql.json,/api/2.0/sql/queries/{id},queries_update,patch,Query,"sql, queries","id, update_mask, auto_resolve_display_name, query",Updates a query.,"Updates a query.  :param id: str :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future. :param auto_resolve_display_name: bool (optional)   If true, automatically resolve alert display name conflicts. Otherwise, fail the request if the   alert's display name conflicts with an existing alert's display name. :param query: :class:`UpdateQueryRequestQuery` (optional)  :returns: :class:`Query`",queries,update,update,
sql.json,/api/2.0/preview/sql/queries,queries_legacy_create,post,LegacyQuery,"sql, queries_legacy","data_source_id, description, name, options, parent, query, run_as_role, tags",Creates a new query definition. Queries created with this endpoint belong to the authenticated user,"Creates a new query definition. Queries created with this endpoint belong to the authenticated user making the request.  The `data_source_id` field specifies the ID of the SQL warehouse to run this query against. You can use the Data Sources API to see a complete list of available SQL warehouses. Or you can copy the `data_source_id` from an existing query.  **Note**: You cannot add a visualization until you create the query.  **Warning**: This API is deprecated. Please use :method:queries/create instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param data_source_id: str (optional)   Data source ID maps to the ID of the data source used by the resource and is distinct from the   warehouse ID. [Learn more]    [Learn more]: https://docs.databricks.com/api/workspace/datasources/list :param description: str (optional)   General description that conveys additional information about this query such as usage notes. :param name: str (optional)   The title of this query that appears in list views, widget headings, and on the query page. :param options: Any (optional)   Exclusively used for storing a list parameter definitions. A parameter is an object with `title`,   `name`, `type`, and `value` properties. The `value` field here is the default value. It can be   overridden at runtime. :param parent: str (optional)   The identifier of the workspace folder containing the object. :param query: str (optional)   The text of the query to be run. :param run_as_role: :class:`RunAsRole` (optional)   Sets the **Run as** role for the object. Must be set to one of `""viewer""` (signifying ""run as   viewer"" behavior) or `""owner""` (signifying ""run as owner"" behavior) :param tags: List[str] (optional)  :returns: :class:`LegacyQuery`",queries_legacy,create,insert,
sql.json,/api/2.0/preview/sql/queries,queries_legacy_list,get,QueryList,"sql, queries_legacy","order, page, page_size, q","Gets a list of queries. Optionally, this list can be filtered by a search term.","Gets a list of queries. Optionally, this list can be filtered by a search term.  **Warning**: Calling this API concurrently 10 or more times could result in throttling, service degradation, or a temporary ban.  **Warning**: This API is deprecated. Please use :method:queries/list instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param order: str (optional)   Name of query attribute to order by. Default sort order is ascending. Append a dash (`-`) to order   descending instead.    - `name`: The name of the query.    - `created_at`: The timestamp the query was created.    - `runtime`: The time it took to run this query. This is blank for parameterized queries. A blank   value is treated as the highest value for sorting.    - `executed_at`: The timestamp when the query was last run.    - `created_by`: The user name of the user that created the query. :param page: int (optional)   Page number to retrieve. :param page_size: int (optional)   Number of queries to return per page. :param q: str (optional)   Full text search term  :returns: Iterator over :class:`LegacyQuery`",queries_legacy,list,select,$.results
sql.json,/api/2.0/preview/sql/queries/{query_id},queries_legacy_delete,delete,,"sql, queries_legacy",query_id,"Moves a query to the trash. Trashed queries immediately disappear from searches and list views, and","Moves a query to the trash. Trashed queries immediately disappear from searches and list views, and they cannot be used for alerts. The trash is deleted after 30 days.  **Warning**: This API is deprecated. Please use :method:queries/delete instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param query_id: str",queries_legacy,delete,delete,
sql.json,/api/2.0/preview/sql/queries/{query_id},queries_legacy_get,get,LegacyQuery,"sql, queries_legacy",query_id,Retrieve a query object definition along with contextual permissions information about the currently,Retrieve a query object definition along with contextual permissions information about the currently authenticated user.  **Warning**: This API is deprecated. Please use :method:queries/get instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param query_id: str  :returns: :class:`LegacyQuery`,queries_legacy,get,select,
sql.json,/api/2.0/preview/sql/queries/{query_id},queries_legacy_update,post,LegacyQuery,"sql, queries_legacy","query_id, data_source_id, description, name, options, query, run_as_role, tags",Modify this query definition.,"Modify this query definition.  **Note**: You cannot undo this operation.  **Warning**: This API is deprecated. Please use :method:queries/update instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param query_id: str :param data_source_id: str (optional)   Data source ID maps to the ID of the data source used by the resource and is distinct from the   warehouse ID. [Learn more]    [Learn more]: https://docs.databricks.com/api/workspace/datasources/list :param description: str (optional)   General description that conveys additional information about this query such as usage notes. :param name: str (optional)   The title of this query that appears in list views, widget headings, and on the query page. :param options: Any (optional)   Exclusively used for storing a list parameter definitions. A parameter is an object with `title`,   `name`, `type`, and `value` properties. The `value` field here is the default value. It can be   overridden at runtime. :param query: str (optional)   The text of the query to be run. :param run_as_role: :class:`RunAsRole` (optional)   Sets the **Run as** role for the object. Must be set to one of `""viewer""` (signifying ""run as   viewer"" behavior) or `""owner""` (signifying ""run as owner"" behavior) :param tags: List[str] (optional)  :returns: :class:`LegacyQuery`",queries_legacy,replace,replace,
sql.json,/api/2.0/preview/sql/queries/trash/{query_id},queries_legacy_restore,post,,"sql, queries_legacy",query_id,Restore a query that has been moved to the trash. A restored query appears in list views and searches.,Restore a query that has been moved to the trash. A restored query appears in list views and searches. You can use restored queries for alerts.  **Warning**: This API is deprecated. Please see the latest version. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param query_id: str,queries_legacy,restore,exec,
sql.json,/api/2.0/sql/history/queries,query_history_list,get,ListQueriesResponse,"sql, query_history","filter_by, include_metrics, max_results, page_token","List the history of queries through SQL warehouses, and serverless compute.","List the history of queries through SQL warehouses, and serverless compute.  You can filter by user ID, warehouse ID, status, and time range. Most recently started queries are returned first (up to max_results in request). The pagination token returned in response can be used to list subsequent query statuses.  :param filter_by: :class:`QueryFilter` (optional)   An optional filter object to limit query history results. Accepts parameters such as user IDs,   endpoint IDs, and statuses to narrow the returned data. In a URL, the parameters of this filter are   specified with dot notation. For example: `filter_by.statement_ids`. :param include_metrics: bool (optional)   Whether to include the query metrics with each query. Only use this for a small subset of queries   (max_results). Defaults to false. :param max_results: int (optional)   Limit the number of results returned in one page. Must be less than 1000 and the default is 100. :param page_token: str (optional)   A token that can be used to get the next page of results. The token can contains characters that   need to be encoded before using it in a URL. For example, the character '+' needs to be replaced by   %2B. This field is optional.  :returns: :class:`ListQueriesResponse`",query_history,list,select,
sql.json,/api/2.0/sql/queries/{id}/visualizations,queries_list_visualizations,get,ListVisualizationsForQueryResponse,"sql, queries","id, page_size, page_token",Gets a list of visualizations on a query.,Gets a list of visualizations on a query.  :param id: str :param page_size: int (optional) :param page_token: str (optional)  :returns: Iterator over :class:`Visualization`,query_visualizations,list,select,$.results
sql.json,/api/2.0/sql/visualizations,query_visualizations_create,post,Visualization,"sql, query_visualizations",visualization,Adds a visualization to a query.,Adds a visualization to a query.  :param visualization: :class:`CreateVisualizationRequestVisualization` (optional)  :returns: :class:`Visualization`,query_visualizations,create,insert,
sql.json,/api/2.0/sql/visualizations/{id},query_visualizations_delete,delete,,"sql, query_visualizations",id,Removes a visualization.,Removes a visualization.  :param id: str,query_visualizations,delete,delete,
sql.json,/api/2.0/sql/visualizations/{id},query_visualizations_update,patch,Visualization,"sql, query_visualizations","id, update_mask, visualization",Updates a visualization.,"Updates a visualization.  :param id: str :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future. :param visualization: :class:`UpdateVisualizationRequestVisualization` (optional)  :returns: :class:`Visualization`",query_visualizations,update,update,
sql.json,/api/2.0/preview/sql/visualizations,query_visualizations_legacy_create,post,LegacyVisualization,"sql, query_visualizations_legacy","options, query_id, type, description, name",Creates visualization in the query.,"Creates visualization in the query.  **Warning**: This API is deprecated. Please use :method:queryvisualizations/create instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param options: Any   The options object varies widely from one visualization type to the next and is unsupported.   Databricks does not recommend modifying visualization settings in JSON. :param query_id: str   The identifier returned by :method:queries/create :param type: str   The type of visualization: chart, table, pivot table, and so on. :param description: str (optional)   A short description of this visualization. This is not displayed in the UI. :param name: str (optional)   The name of the visualization that appears on dashboards and the query screen.  :returns: :class:`LegacyVisualization`",query_visualizations_legacy,create,insert,
sql.json,/api/2.0/preview/sql/visualizations/{id},query_visualizations_legacy_delete,delete,,"sql, query_visualizations_legacy",id,Removes a visualization from the query.,Removes a visualization from the query.  **Warning**: This API is deprecated. Please use :method:queryvisualizations/delete instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param id: str   Widget ID returned by :method:queryvisualizations/create,query_visualizations_legacy,delete,delete,
sql.json,/api/2.0/preview/sql/visualizations/{id},query_visualizations_legacy_update,post,LegacyVisualization,"sql, query_visualizations_legacy","id, created_at, description, name, options, query, type, updated_at",Updates visualization in the query.,"Updates visualization in the query.  **Warning**: This API is deprecated. Please use :method:queryvisualizations/update instead. [Learn more]  [Learn more]: https://docs.databricks.com/en/sql/dbsql-api-latest.html  :param created_at: str (optional) :param description: str (optional)   A short description of this visualization. This is not displayed in the UI. :param id: str (optional)   The UUID for this visualization. :param name: str (optional)   The name of the visualization that appears on dashboards and the query screen. :param options: Any (optional)   The options object varies widely from one visualization type to the next and is unsupported.   Databricks does not recommend modifying visualization settings in JSON. :param query: :class:`LegacyQuery` (optional) :param type: str (optional)   The type of visualization: chart, table, pivot table, and so on. :param updated_at: str (optional)  :returns: :class:`LegacyVisualization`",query_visualizations_legacy,update,insert,
sql.json,/api/2.0/redash-v2/config,redash_config_get_config,get,ClientConfig,"sql, redash_config",,Read workspace configuration for Redash-v2.,Read workspace configuration for Redash-v2.   :returns: :class:`ClientConfig`,redash_config,get,select,
sql.json,/api/2.0/sql/statements/{statement_id}/cancel,statement_execution_cancel_execution,post,,"sql, statement_execution",statement_id,Requests that an executing statement be canceled. Callers must poll for status to see the terminal,"Requests that an executing statement be canceled. Callers must poll for status to see the terminal state. Cancel response is empty; receiving response indicates successful receipt.  :param statement_id: str   The statement ID is returned upon successfully submitting a SQL statement, and is a required   reference for all subsequent calls.",statement_execution,cancel,insert,
sql.json,/api/2.0/sql/statements,statement_execution_execute_statement,post,StatementResponse,"sql, statement_execution","statement, warehouse_id, byte_limit, catalog, disposition, format, on_wait_timeout, parameters, query_tags, row_limit, schema, wait_timeout",Execute a SQL statement and optionally await its results for a specified time.,"Execute a SQL statement and optionally await its results for a specified time.  **Use case: small result sets with INLINE + JSON_ARRAY**  For flows that generate small and predictable result sets (<= 25 MiB), `INLINE` responses of `JSON_ARRAY` result data are typically the simplest way to execute and fetch result data.  **Use case: large result sets with EXTERNAL_LINKS**  Using `EXTERNAL_LINKS` to fetch result data allows you to fetch large result sets efficiently. The main differences from using `INLINE` disposition are that the result data is accessed with URLs, and that there are 3 supported formats: `JSON_ARRAY`, `ARROW_STREAM` and `CSV` compared to only `JSON_ARRAY` with `INLINE`.  ** URLs**  External links point to data stored within your workspace's internal storage, in the form of a URL. The URLs are valid for only a short period, <= 15 minutes. Alongside each `external_link` is an expiration field indicating the time at which the URL is no longer valid. In `EXTERNAL_LINKS` mode, chunks can be resolved and fetched multiple times and in parallel.  ----  ### **Warning: Databricks strongly recommends that you protect the URLs that are returned by the `EXTERNAL_LINKS` disposition.**  When you use the `EXTERNAL_LINKS` disposition, a short-lived, URL is generated, which can be used to download the results directly from . As a short-lived is embedded in this URL, you should protect the URL.  Because URLs are already generated with embedded temporary s, you must not set an `Authorization` header in the download requests.  The `EXTERNAL_LINKS` disposition can be disabled upon request by creating a support case.  See also [Security best practices].  ----  StatementResponse contains `statement_id` and `status`; other fields might be absent or present depending on context. If the SQL warehouse fails to execute the provided statement, a 200 response is returned with `status.state` set to `FAILED` (in contrast to a failure when accepting the request, which results in a non-200 response). Details of the error can be found at `status.error` in case of execution failures.  [Security best practices]: https://docs.databricks.com/sql/admin/sql-execution-tutorial.html#security-best-practices  :param statement: str   The SQL statement to execute. The statement can optionally be parameterized, see `parameters`. The   maximum query text size is 16 MiB. :param warehouse_id: str   Warehouse upon which to execute a statement. See also [What are SQL warehouses?]    [What are SQL warehouses?]: https://docs.databricks.com/sql/admin/warehouse-type.html :param byte_limit: int (optional)   Applies the given byte limit to the statement's result size. Byte counts are based on internal data   representations and might not match the final size in the requested `format`. If the result was   truncated due to the byte limit, then `truncated` in the response is set to `true`. When using   `EXTERNAL_LINKS` disposition, a default `byte_limit` of 100 GiB is applied if `byte_limit` is not   explicitly set. :param catalog: str (optional)   Sets default catalog for statement execution, similar to [`USE CATALOG`] in SQL.    [`USE CATALOG`]: https://docs.databricks.com/sql/language-manual/sql-ref-syntax-ddl-use-catalog.html :param disposition: :class:`Disposition` (optional)   The fetch disposition provides two modes of fetching results: `INLINE` and `EXTERNAL_LINKS`.    Statements executed with `INLINE` disposition will return result data inline, in `JSON_ARRAY`   format, in a series of chunks. If a given statement produces a result set with a size larger than 25   MiB, that statement execution is aborted, and no result set will be available.    **NOTE** Byte limits are computed based upon internal representations of the result set data, and   might not match the sizes visible in JSON responses.    Statements executed with `EXTERNAL_LINKS` disposition will return result data as external links:   URLs that point to cloud storage internal to the workspace. Using `EXTERNAL_LINKS` disposition   allows statements to generate arbitrarily sized result sets for fetching up to 100 GiB. The   resulting links have two important properties:    1. They point to resources _external_ to the Databricks compute; therefore any associated   authentication information (typically a personal access token, OAuth token, or similar) _must be   removed_ when fetching from these links.    2. These are URLs with a specific expiration, indicated in the response. The behavior when   attempting to use an expired link is cloud specific. :param format: :class:`Format` (optional)   Statement execution supports three result formats: `JSON_ARRAY` (default), `ARROW_STREAM`, and   `CSV`.    Important: The formats `ARROW_STREAM` and `CSV` are supported only with `EXTERNAL_LINKS`   disposition. `JSON_ARRAY` is supported in `INLINE` and `EXTERNAL_LINKS` disposition.    When specifying `format=JSON_ARRAY`, result data will be formatted as an array of arrays of values,   where each value is either the *string representation* of a value, or `null`. For example, the   output of `SELECT concat('id-', id) AS strCol, id AS intCol, null AS nullCol FROM range(3)` would   look like this:    ``` [ [ ""id-1"", ""1"", null ], [ ""id-2"", ""2"", null ], [ ""id-3"", ""3"", null ], ] ```    When specifying `format=JSON_ARRAY` and `disposition=EXTERNAL_LINKS`, each chunk in the result   contains compact JSON with no indentation or extra whitespace.    When specifying `format=ARROW_STREAM` and `disposition=EXTERNAL_LINKS`, each chunk in the result   will be formatted as Apache Arrow Stream. See the [Apache Arrow streaming format].    When specifying `format=CSV` and `disposition=EXTERNAL_LINKS`, each chunk in the result will be a   CSV according to [RFC 4180] standard. All the columns values will have *string representation*   similar to the `JSON_ARRAY` format, and `null` values will be encoded as “null”. Only the first   chunk in the result would contain a header row with column names. For example, the output of `SELECT   concat('id-', id) AS strCol, id AS intCol, null as nullCol FROM range(3)` would look like this:    ``` strCol,intCol,nullCol id-1,1,null id-2,2,null id-3,3,null ```    [Apache Arrow streaming format]: https://arrow.apache.org/docs/format/Columnar.html#ipc-streaming-format   [RFC 4180]: https://www.rfc-editor.org/rfc/rfc4180 :param on_wait_timeout: :class:`ExecuteStatementRequestOnWaitTimeout` (optional)   When `wait_timeout > 0s`, the call will block up to the specified time. If the statement execution   doesn't finish within this time, `on_wait_timeout` determines whether the execution should continue   or be canceled. When set to `CONTINUE`, the statement execution continues asynchronously and the   call returns a statement ID which can be used for polling with   :method:statementexecution/getStatement. When set to `CANCEL`, the statement execution is canceled   and the call returns with a `CANCELED` state. :param parameters: List[:class:`StatementParameterListItem`] (optional)   A list of parameters to pass into a SQL statement containing parameter markers. A parameter consists   of a name, a value, and optionally a type. To represent a NULL value, the `value` field may be   omitted or set to `null` explicitly. If the `type` field is omitted, the value is interpreted as a   string.    If the type is given, parameters will be checked for type correctness according to the given type. A   value is correct if the provided string can be converted to the requested type using the `cast`   function. The exact semantics are described in the section [`cast` function] of the SQL language   reference.    For example, the following statement contains two parameters, `my_name` and `my_date`:    ``` SELECT * FROM my_table WHERE name = :my_name AND date = :my_date ```    The parameters can be passed in the request body as follows:    ` { ..., ""statement"": ""SELECT * FROM my_table WHERE name = :my_name AND date = :my_date"",   ""parameters"": [ { ""name"": ""my_name"", ""value"": ""the name"" }, { ""name"": ""my_date"", ""value"":   ""2020-01-01"", ""type"": ""DATE"" } ] } `    Currently, positional parameters denoted by a `?` marker are not supported by the Databricks SQL   Statement Execution API.    Also see the section [Parameter markers] of the SQL language reference.    [Parameter markers]: https://docs.databricks.com/sql/language-manual/sql-ref-parameter-marker.html   [`cast` function]: https://docs.databricks.com/sql/language-manual/functions/cast.html :param query_tags: List[:class:`QueryTag`] (optional)   An array of query tags to annotate a SQL statement. A query tag consists of a non-empty key and,   optionally, a value. To represent a NULL value, either omit the `value` field or manually set it to   `null` or white space. Refer to the SQL language reference for the format specification of query   tags. There's no significance to the order of tags. Only one value per key will be recorded. A   sequence in excess of 20 query tags will be coerced to 20. Example:    { ..., ""query_tags"": [ { ""key"": ""team"", ""value"": ""eng"" }, { ""key"": ""some key only tag"" } ] } :param row_limit: int (optional)   Applies the given row limit to the statement's result set, but unlike the `LIMIT` clause in SQL, it   also sets the `truncated` field in the response to indicate whether the result was trimmed due to   the limit or not. :param schema: str (optional)   Sets default schema for statement execution, similar to [`USE SCHEMA`] in SQL.    [`USE SCHEMA`]: https://docs.databricks.com/sql/language-manual/sql-ref-syntax-ddl-use-schema.html :param wait_timeout: str (optional)   The time in seconds the call will wait for the statement's result set as `Ns`, where `N` can be set   to 0 or to a value between 5 and 50.    When set to `0s`, the statement will execute in asynchronous mode and the call will not wait for the   execution to finish. In this case, the call returns directly with `PENDING` state and a statement ID   which can be used for polling with :method:statementexecution/getStatement.    When set between 5 and 50 seconds, the call will behave synchronously up to this timeout and wait   for the statement execution to finish. If the execution finishes within this time, the call returns   immediately with a manifest and result data (or a `FAILED` state in case of an execution error). If   the statement takes longer to execute, `on_wait_timeout` determines what should happen after the   timeout is reached.  :returns: :class:`StatementResponse`",statement_execution,execute,insert,
sql.json,/api/2.0/sql/statements/{statement_id},statement_execution_get_statement,get,StatementResponse,"sql, statement_execution",statement_id,This request can be used to poll for the statement's status. StatementResponse contains `statement_id`,"This request can be used to poll for the statement's status. StatementResponse contains `statement_id` and `status`; other fields might be absent or present depending on context. When the `status.state` field is `SUCCEEDED` it will also return the result manifest and the first chunk of the result data. When the statement is in the terminal states `CANCELED`, `CLOSED` or `FAILED`, it returns HTTP 200 with the state set. After at least 12 hours in terminal state, the statement is removed from the warehouse and further calls will receive an HTTP 404 response.  **NOTE** This call currently might take up to 5 seconds to get the latest status and result.  :param statement_id: str   The statement ID is returned upon successfully submitting a SQL statement, and is a required   reference for all subsequent calls.  :returns: :class:`StatementResponse`",statement_execution,get,select,
sql.json,/api/2.0/sql/statements/{statement_id}/result/chunks/{chunk_index},statement_execution_get_statement_result_chunk_n,get,ResultData,"sql, statement_execution","statement_id, chunk_index","After the statement execution has `SUCCEEDED`, this request can be used to fetch any chunk by index.","After the statement execution has `SUCCEEDED`, this request can be used to fetch any chunk by index. Whereas the first chunk with `chunk_index=0` is typically fetched with :method:statementexecution/executeStatement or :method:statementexecution/getStatement, this request can be used to fetch subsequent chunks. The response structure is identical to the nested `result` element described in the :method:statementexecution/getStatement request, and similarly includes the `next_chunk_index` and `next_chunk_internal_link` fields for simple iteration through the result set. Depending on `disposition`, the response returns chunks of data either inline, or as links.  :param statement_id: str   The statement ID is returned upon successfully submitting a SQL statement, and is a required   reference for all subsequent calls. :param chunk_index: int  :returns: :class:`ResultData`",statement_execution,get_result_chunk,select,
sql.json,/api/2.0/permissions/warehouses/{warehouse_id}/permissionLevels,warehouses_get_permission_levels,get,GetWarehousePermissionLevelsResponse,"sql, warehouses",warehouse_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param warehouse_id: str   The SQL warehouse for which to get or manage permissions.  :returns: :class:`GetWarehousePermissionLevelsResponse`,warehouse_permission_levels,get,select,
sql.json,/api/2.0/permissions/warehouses/{warehouse_id},warehouses_get_permissions,get,WarehousePermissions,"sql, warehouses",warehouse_id,Gets the permissions of a SQL warehouse. SQL warehouses can inherit permissions from their root,Gets the permissions of a SQL warehouse. SQL warehouses can inherit permissions from their root object.  :param warehouse_id: str   The SQL warehouse for which to get or manage permissions.  :returns: :class:`WarehousePermissions`,warehouse_permissions,get,select,
sql.json,/api/2.0/permissions/warehouses/{warehouse_id},warehouses_set_permissions,put,WarehousePermissions,"sql, warehouses","warehouse_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param warehouse_id: str   The SQL warehouse for which to get or manage permissions. :param access_control_list: List[:class:`WarehouseAccessControlRequest`] (optional)  :returns: :class:`WarehousePermissions`",warehouse_permissions,set,replace,
sql.json,/api/2.0/permissions/warehouses/{warehouse_id},warehouses_update_permissions,patch,WarehousePermissions,"sql, warehouses","warehouse_id, access_control_list",Updates the permissions on a SQL warehouse. SQL warehouses can inherit permissions from their root,Updates the permissions on a SQL warehouse. SQL warehouses can inherit permissions from their root object.  :param warehouse_id: str   The SQL warehouse for which to get or manage permissions. :param access_control_list: List[:class:`WarehouseAccessControlRequest`] (optional)  :returns: :class:`WarehousePermissions`,warehouse_permissions,update,update,
sql.json,/api/2.0/sql/warehouses,warehouses_create,post,GetWarehouseResponse,"sql, warehouses","auto_stop_mins, channel, cluster_size, creator_name, enable_photon, enable_serverless_compute, instance_profile_arn, max_num_clusters, min_num_clusters, name, spot_instance_policy, tags, warehouse_type",Creates a new SQL warehouse.,"Creates a new SQL warehouse.  :param auto_stop_mins: int (optional)   The amount of time in minutes that a SQL warehouse must be idle (i.e., no RUNNING queries) before it   is automatically stopped.    Supported values: - Must be == 0 or >= 10 mins - 0 indicates no autostop.    Defaults to 120 mins :param channel: :class:`Channel` (optional)   Channel Details :param cluster_size: str (optional)   Size of the clusters allocated for this warehouse. Increasing the size of a spark cluster allows you   to run larger queries on it. If you want to increase the number of concurrent queries, please tune   max_num_clusters.    Supported values: - 2X-Small - X-Small - Small - Medium - Large - X-Large - 2X-Large - 3X-Large -   4X-Large :param creator_name: str (optional)   warehouse creator name :param enable_photon: bool (optional)   Configures whether the warehouse should use Photon optimized clusters.    Defaults to false. :param enable_serverless_compute: bool (optional)   Configures whether the warehouse should use serverless compute :param instance_profile_arn: str (optional)   Deprecated. Instance profile used to pass IAM role to the cluster :param max_num_clusters: int (optional)   Maximum number of clusters that the autoscaler will create to handle concurrent queries.    Supported values: - Must be >= min_num_clusters - Must be <= 40.    Defaults to min_clusters if unset. :param min_num_clusters: int (optional)   Minimum number of available clusters that will be maintained for this SQL warehouse. Increasing this   will ensure that a larger number of clusters are always running and therefore may reduce the cold   start time for new queries. This is similar to reserved vs. revocable cores in a resource manager.    Supported values: - Must be > 0 - Must be <= min(max_num_clusters, 30)    Defaults to 1 :param name: str (optional)   Logical name for the cluster.    Supported values: - Must be unique within an org. - Must be less than 100 characters. :param spot_instance_policy: :class:`SpotInstancePolicy` (optional)   Configurations whether the endpoint should use spot instances. :param tags: :class:`EndpointTags` (optional)   A set of key-value pairs that will be tagged on all resources (e.g., AWS instances and EBS volumes)   associated with this SQL warehouse.    Supported values: - Number of tags < 45. :param warehouse_type: :class:`CreateWarehouseRequestWarehouseType` (optional)   Warehouse type: `PRO` or `CLASSIC`. If you want to use serverless compute, you must set to `PRO` and   also set the field `enable_serverless_compute` to `true`.  :returns:   Long-running operation waiter for :class:`GetWarehouseResponse`.   See :method:wait_get_warehouse_running for more details.",warehouses,create,insert,
sql.json,/api/2.0/sql/warehouses,warehouses_list,get,ListWarehousesResponse,"sql, warehouses","page_size, page_token, run_as_user_id",Lists all SQL warehouses that a user has access to.,"Lists all SQL warehouses that a user has access to.  :param page_size: int (optional)   The max number of warehouses to return. :param page_token: str (optional)   A page token, received from a previous `ListWarehouses` call. Provide this to retrieve the   subsequent page; otherwise the first will be retrieved.    When paginating, all other parameters provided to `ListWarehouses` must match the call that provided   the page token. :param run_as_user_id: int (optional)   Service Principal which will be used to fetch the list of endpoints. If not specified, SQL Gateway   will use the user from the session header.  :returns: Iterator over :class:`EndpointInfo`",warehouses,list,select,$.warehouses
sql.json,/api/2.0/sql/warehouses/{id},warehouses_delete,delete,,"sql, warehouses",id,Deletes a SQL warehouse.,Deletes a SQL warehouse.  :param id: str   Required. Id of the SQL warehouse.,warehouses,delete,delete,
sql.json,/api/2.0/sql/warehouses/{id},warehouses_get,get,GetWarehouseResponse,"sql, warehouses",id,Gets the information for a single SQL warehouse.,Gets the information for a single SQL warehouse.  :param id: str   Required. Id of the SQL warehouse.  :returns: :class:`GetWarehouseResponse`,warehouses,get,select,
sql.json,/api/2.0/sql/warehouses/{id}/edit,warehouses_edit,post,GetWarehouseResponse,"sql, warehouses","id, auto_stop_mins, channel, cluster_size, creator_name, enable_photon, enable_serverless_compute, instance_profile_arn, max_num_clusters, min_num_clusters, name, spot_instance_policy, tags, warehouse_type",Updates the configuration for a SQL warehouse.,"Updates the configuration for a SQL warehouse.  :param id: str   Required. Id of the warehouse to configure. :param auto_stop_mins: int (optional)   The amount of time in minutes that a SQL warehouse must be idle (i.e., no RUNNING queries) before it   is automatically stopped.    Supported values: - Must be == 0 or >= 10 mins - 0 indicates no autostop.    Defaults to 120 mins :param channel: :class:`Channel` (optional)   Channel Details :param cluster_size: str (optional)   Size of the clusters allocated for this warehouse. Increasing the size of a spark cluster allows you   to run larger queries on it. If you want to increase the number of concurrent queries, please tune   max_num_clusters.    Supported values: - 2X-Small - X-Small - Small - Medium - Large - X-Large - 2X-Large - 3X-Large -   4X-Large :param creator_name: str (optional)   warehouse creator name :param enable_photon: bool (optional)   Configures whether the warehouse should use Photon optimized clusters.    Defaults to false. :param enable_serverless_compute: bool (optional)   Configures whether the warehouse should use serverless compute :param instance_profile_arn: str (optional)   Deprecated. Instance profile used to pass IAM role to the cluster :param max_num_clusters: int (optional)   Maximum number of clusters that the autoscaler will create to handle concurrent queries.    Supported values: - Must be >= min_num_clusters - Must be <= 40.    Defaults to min_clusters if unset. :param min_num_clusters: int (optional)   Minimum number of available clusters that will be maintained for this SQL warehouse. Increasing this   will ensure that a larger number of clusters are always running and therefore may reduce the cold   start time for new queries. This is similar to reserved vs. revocable cores in a resource manager.    Supported values: - Must be > 0 - Must be <= min(max_num_clusters, 30)    Defaults to 1 :param name: str (optional)   Logical name for the cluster.    Supported values: - Must be unique within an org. - Must be less than 100 characters. :param spot_instance_policy: :class:`SpotInstancePolicy` (optional)   Configurations whether the endpoint should use spot instances. :param tags: :class:`EndpointTags` (optional)   A set of key-value pairs that will be tagged on all resources (e.g., AWS instances and EBS volumes)   associated with this SQL warehouse.    Supported values: - Number of tags < 45. :param warehouse_type: :class:`EditWarehouseRequestWarehouseType` (optional)   Warehouse type: `PRO` or `CLASSIC`. If you want to use serverless compute, you must set to `PRO` and   also set the field `enable_serverless_compute` to `true`.  :returns:   Long-running operation waiter for :class:`GetWarehouseResponse`.   See :method:wait_get_warehouse_running for more details.",warehouses,edit,replace,
sql.json,/api/2.0/sql/warehouses/{id}/start,warehouses_start,post,GetWarehouseResponse,"sql, warehouses",id,Starts a SQL warehouse.,Starts a SQL warehouse.  :param id: str   Required. Id of the SQL warehouse.  :returns:   Long-running operation waiter for :class:`GetWarehouseResponse`.   See :method:wait_get_warehouse_running for more details.,warehouses,start,exec,
sql.json,/api/2.0/sql/warehouses/{id}/stop,warehouses_stop,post,GetWarehouseResponse,"sql, warehouses",id,Stops a SQL warehouse.,Stops a SQL warehouse.  :param id: str   Required. Id of the SQL warehouse.  :returns:   Long-running operation waiter for :class:`GetWarehouseResponse`.   See :method:wait_get_warehouse_stopped for more details.,warehouses,stop,exec,
sql.json,/api/2.0/sql/config/warehouses,warehouses_get_workspace_warehouse_config,get,GetWorkspaceWarehouseConfigResponse,"sql, warehouses",,Gets the workspace level configuration that is shared by all SQL warehouses in a workspace.,Gets the workspace level configuration that is shared by all SQL warehouses in a workspace.   :returns: :class:`GetWorkspaceWarehouseConfigResponse`,workspace_warehouse_config,get,select,
sql.json,/api/2.0/sql/config/warehouses,warehouses_set_workspace_warehouse_config,put,,"sql, warehouses","channel, config_param, data_access_config, enable_serverless_compute, enabled_warehouse_types, global_param, google_service_account, instance_profile_arn, security_policy, sql_configuration_parameters",Sets the workspace level configuration that is shared by all SQL warehouses in a workspace.,"Sets the workspace level configuration that is shared by all SQL warehouses in a workspace.  :param channel: :class:`Channel` (optional)   Optional: Channel selection details :param config_param: :class:`RepeatedEndpointConfPairs` (optional)   Deprecated: Use sql_configuration_parameters :param data_access_config: List[:class:`EndpointConfPair`] (optional)   Spark confs for external hive metastore configuration JSON serialized size must be less than <= 512K :param enable_serverless_compute: bool (optional)   Enable Serverless compute for SQL warehouses :param enabled_warehouse_types: List[:class:`WarehouseTypePair`] (optional)   List of Warehouse Types allowed in this workspace (limits allowed value of the type field in   CreateWarehouse and EditWarehouse). Note: Some types cannot be disabled, they don't need to be   specified in SetWorkspaceWarehouseConfig. Note: Disabling a type may cause existing warehouses to be   converted to another type. Used by frontend to save specific type availability in the warehouse   create and edit form UI. :param global_param: :class:`RepeatedEndpointConfPairs` (optional)   Deprecated: Use sql_configuration_parameters :param google_service_account: str (optional)   GCP only: Google Service Account used to pass to cluster to access Google Cloud Storage :param instance_profile_arn: str (optional)   AWS Only: The instance profile used to pass an IAM role to the SQL warehouses. This configuration is   also applied to the workspace's serverless compute for notebooks and jobs. :param security_policy: :class:`SetWorkspaceWarehouseConfigRequestSecurityPolicy` (optional)   Security policy for warehouses :param sql_configuration_parameters: :class:`RepeatedEndpointConfPairs` (optional)   SQL configuration parameters",workspace_warehouse_config,set,replace,
tags.json,/api/2.1/tag-policies,tag_policies_create_tag_policy,post,TagPolicy,"tags, tag_policies",tag_policy,"Creates a new tag policy, making the associated tag key governed. For Terraform usage, see the [Tag","Creates a new tag policy, making the associated tag key governed. For Terraform usage, see the [Tag Policy Terraform documentation]. To manage permissions for tag policies, use the [Account Access Control Proxy API].  [Account Access Control Proxy API]: https://docs.databricks.com/api/workspace/accountaccesscontrolproxy [Tag Policy Terraform documentation]: https://registry.terraform.io/providers/databricks/databricks/latest/docs/resources/tag_policy  :param tag_policy: :class:`TagPolicy`  :returns: :class:`TagPolicy`",tag_policies,create,insert,
tags.json,/api/2.1/tag-policies,tag_policies_list_tag_policies,get,ListTagPoliciesResponse,"tags, tag_policies","page_size, page_token","Lists the tag policies for all governed tags in the account. For Terraform usage, see the [Tag Policy","Lists the tag policies for all governed tags in the account. For Terraform usage, see the [Tag Policy Terraform documentation]. To list granted permissions for tag policies, use the [Account Access Control Proxy API].  [Account Access Control Proxy API]: https://docs.databricks.com/api/workspace/accountaccesscontrolproxy [Tag Policy Terraform documentation]: https://registry.terraform.io/providers/databricks/databricks/latest/docs/data-sources/tag_policies  :param page_size: int (optional)   The maximum number of results to return in this request. Fewer results may be returned than   requested. If unspecified or set to 0, this defaults to 1000. The maximum value is 1000; values   above 1000 will be coerced down to 1000. :param page_token: str (optional)   An optional page token received from a previous list tag policies call.  :returns: Iterator over :class:`TagPolicy`",tag_policies,list,select,$.tag_policies
tags.json,/api/2.1/tag-policies/{tag_key},tag_policies_delete_tag_policy,delete,,"tags, tag_policies",tag_key,"Deletes a tag policy by its associated governed tag's key, leaving that tag key ungoverned. For","Deletes a tag policy by its associated governed tag's key, leaving that tag key ungoverned. For Terraform usage, see the [Tag Policy Terraform documentation].  [Tag Policy Terraform documentation]: https://registry.terraform.io/providers/databricks/databricks/latest/docs/resources/tag_policy  :param tag_key: str",tag_policies,delete,delete,
tags.json,/api/2.1/tag-policies/{tag_key},tag_policies_get_tag_policy,get,TagPolicy,"tags, tag_policies",tag_key,"Gets a single tag policy by its associated governed tag's key. For Terraform usage, see the [Tag","Gets a single tag policy by its associated governed tag's key. For Terraform usage, see the [Tag Policy Terraform documentation]. To list granted permissions for tag policies, use the [Account Access Control Proxy API].  [Account Access Control Proxy API]: https://docs.databricks.com/api/workspace/accountaccesscontrolproxy [Tag Policy Terraform documentation]: https://registry.terraform.io/providers/databricks/databricks/latest/docs/data-sources/tag_policy  :param tag_key: str  :returns: :class:`TagPolicy`",tag_policies,get,select,
tags.json,/api/2.1/tag-policies/{tag_key},tag_policies_update_tag_policy,patch,TagPolicy,"tags, tag_policies","tag_key, update_mask, tag_policy","Updates an existing tag policy for a single governed tag. For Terraform usage, see the [Tag Policy","Updates an existing tag policy for a single governed tag. For Terraform usage, see the [Tag Policy Terraform documentation]. To manage permissions for tag policies, use the [Account Access Control Proxy API].  [Account Access Control Proxy API]: https://docs.databricks.com/api/workspace/accountaccesscontrolproxy [Tag Policy Terraform documentation]: https://registry.terraform.io/providers/databricks/databricks/latest/docs/resources/tag_policy  :param tag_key: str :param tag_policy: :class:`TagPolicy` :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`TagPolicy`",tag_policies,update,update,
tags.json,/api/2.0/entity-tag-assignments,workspace_entity_tag_assignments_create_tag_assignment,post,TagAssignment,"tags, workspace_entity_tag_assignments",tag_assignment,Create a tag assignment,Create a tag assignment  :param tag_assignment: :class:`TagAssignment`  :returns: :class:`TagAssignment`,workspace_entity_tag_assignments,create,insert,
tags.json,/api/2.0/entity-tag-assignments/{entity_type}/{entity_id}/tags/{tag_key},workspace_entity_tag_assignments_delete_tag_assignment,delete,,"tags, workspace_entity_tag_assignments","entity_type, entity_id, tag_key",Delete a tag assignment,"Delete a tag assignment  :param entity_type: str   The type of entity to which the tag is assigned. Allowed values are apps, dashboards, geniespaces :param entity_id: str   The identifier of the entity to which the tag is assigned :param tag_key: str   The key of the tag. The characters , . : / - = and leading/trailing spaces are not allowed",workspace_entity_tag_assignments,delete,delete,
tags.json,/api/2.0/entity-tag-assignments/{entity_type}/{entity_id}/tags/{tag_key},workspace_entity_tag_assignments_get_tag_assignment,get,TagAssignment,"tags, workspace_entity_tag_assignments","entity_type, entity_id, tag_key",Get a tag assignment,"Get a tag assignment  :param entity_type: str   The type of entity to which the tag is assigned. Allowed values are apps, dashboards, geniespaces :param entity_id: str   The identifier of the entity to which the tag is assigned :param tag_key: str   The key of the tag. The characters , . : / - = and leading/trailing spaces are not allowed  :returns: :class:`TagAssignment`",workspace_entity_tag_assignments,get,select,
tags.json,/api/2.0/entity-tag-assignments/{entity_type}/{entity_id}/tags/{tag_key},workspace_entity_tag_assignments_update_tag_assignment,patch,TagAssignment,"tags, workspace_entity_tag_assignments","entity_type, entity_id, tag_key, update_mask, tag_assignment",Update a tag assignment,"Update a tag assignment  :param entity_type: str   The type of entity to which the tag is assigned. Allowed values are apps, dashboards, geniespaces :param entity_id: str   The identifier of the entity to which the tag is assigned :param tag_key: str   The key of the tag. The characters , . : / - = and leading/trailing spaces are not allowed :param tag_assignment: :class:`TagAssignment` :param update_mask: str   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. It’s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns: :class:`TagAssignment`",workspace_entity_tag_assignments,update,update,
tags.json,/api/2.0/entity-tag-assignments/{entity_type}/{entity_id}/tags,workspace_entity_tag_assignments_list_tag_assignments,get,ListTagAssignmentsResponse,"tags, workspace_entity_tag_assignments","entity_type, entity_id, page_size, page_token",List the tag assignments for an entity,"List the tag assignments for an entity  :param entity_type: str   The type of entity to which the tag is assigned. Allowed values are apps, dashboards, geniespaces :param entity_id: str   The identifier of the entity to which the tag is assigned :param page_size: int (optional)   Optional. Maximum number of tag assignments to return in a single page :param page_token: str (optional)   Pagination token to go to the next page of tag assignments. Requests first page if absent.  :returns: Iterator over :class:`TagAssignment`",workspace_entity_tag_assignments,list,select,$.tag_assignments
vectorsearch.json,/api/2.0/vector-search/endpoints,vector_search_endpoints_create_endpoint,post,EndpointInfo,"vectorsearch, vector_search_endpoints","name, endpoint_type, budget_policy_id",Create a new endpoint.,Create a new endpoint.  :param name: str   Name of the vector search endpoint :param endpoint_type: :class:`EndpointType`   Type of endpoint :param budget_policy_id: str (optional)   The budget policy id to be applied  :returns:   Long-running operation waiter for :class:`EndpointInfo`.   See :method:wait_get_endpoint_vector_search_endpoint_online for more details.,endpoints,create,insert,
vectorsearch.json,/api/2.0/vector-search/endpoints,vector_search_endpoints_list_endpoints,get,ListEndpointResponse,"vectorsearch, vector_search_endpoints",page_token,List all vector search endpoints in the workspace.,List all vector search endpoints in the workspace.  :param page_token: str (optional)   Token for pagination  :returns: Iterator over :class:`EndpointInfo`,endpoints,list,select,$.endpoints
vectorsearch.json,/api/2.0/vector-search/endpoints/{endpoint_name},vector_search_endpoints_delete_endpoint,delete,,"vectorsearch, vector_search_endpoints",endpoint_name,Delete a vector search endpoint.,Delete a vector search endpoint.  :param endpoint_name: str   Name of the vector search endpoint,endpoints,delete,delete,
vectorsearch.json,/api/2.0/vector-search/endpoints/{endpoint_name},vector_search_endpoints_get_endpoint,get,EndpointInfo,"vectorsearch, vector_search_endpoints",endpoint_name,Get details for a single vector search endpoint.,Get details for a single vector search endpoint.  :param endpoint_name: str   Name of the endpoint  :returns: :class:`EndpointInfo`,endpoints,get,select,
vectorsearch.json,/api/2.0/vector-search/endpoints/{name}/metrics,vector_search_endpoints_retrieve_user_visible_metrics,post,RetrieveUserVisibleMetricsResponse,"vectorsearch, vector_search_endpoints","name, end_time, granularity_in_seconds, metrics, page_token, start_time",Retrieve user-visible metrics for an endpoint,Retrieve user-visible metrics for an endpoint  :param name: str   Vector search endpoint name :param end_time: str (optional)   End time for metrics query :param granularity_in_seconds: int (optional)   Granularity in seconds :param metrics: List[:class:`Metric`] (optional)   List of metrics to retrieve :param page_token: str (optional)   Token for pagination :param start_time: str (optional)   Start time for metrics query  :returns: :class:`RetrieveUserVisibleMetricsResponse`,endpoints,retrieve_user_visible_metrics,exec,
vectorsearch.json,/api/2.0/vector-search/endpoints/{endpoint_name}/budget-policy,vector_search_endpoints_update_endpoint_budget_policy,patch,PatchEndpointBudgetPolicyResponse,"vectorsearch, vector_search_endpoints","endpoint_name, budget_policy_id",Update the budget policy of an endpoint,Update the budget policy of an endpoint  :param endpoint_name: str   Name of the vector search endpoint :param budget_policy_id: str   The budget policy id to be applied  :returns: :class:`PatchEndpointBudgetPolicyResponse`,endpoints,update_endpoint_budget_policy,exec,
vectorsearch.json,/api/2.0/vector-search/endpoints/{endpoint_name}/tags,vector_search_endpoints_update_endpoint_custom_tags,patch,UpdateEndpointCustomTagsResponse,"vectorsearch, vector_search_endpoints","endpoint_name, custom_tags",Update the custom tags of an endpoint.,Update the custom tags of an endpoint.  :param endpoint_name: str   Name of the vector search endpoint :param custom_tags: List[:class:`CustomTag`]   The new custom tags for the vector search endpoint  :returns: :class:`UpdateEndpointCustomTagsResponse`,endpoints,update_endpoint_custom_tags,exec,
vectorsearch.json,/api/2.0/vector-search/indexes,vector_search_indexes_create_index,post,VectorIndex,"vectorsearch, vector_search_indexes","name, endpoint_name, primary_key, index_type, delta_sync_index_spec, direct_access_index_spec",Create a new index.,Create a new index.  :param name: str   Name of the index :param endpoint_name: str   Name of the endpoint to be used for serving the index :param primary_key: str   Primary key of the index :param index_type: :class:`VectorIndexType` :param delta_sync_index_spec: :class:`DeltaSyncVectorIndexSpecRequest` (optional)   Specification for Delta Sync Index. Required if `index_type` is `DELTA_SYNC`. :param direct_access_index_spec: :class:`DirectAccessVectorIndexSpec` (optional)   Specification for Direct Vector Access Index. Required if `index_type` is `DIRECT_ACCESS`.  :returns: :class:`VectorIndex`,indexes,create,insert,
vectorsearch.json,/api/2.0/vector-search/indexes,vector_search_indexes_list_indexes,get,ListVectorIndexesResponse,"vectorsearch, vector_search_indexes","endpoint_name, page_token",List all indexes in the given endpoint.,List all indexes in the given endpoint.  :param endpoint_name: str   Name of the endpoint :param page_token: str (optional)   Token for pagination  :returns: Iterator over :class:`MiniVectorIndex`,indexes,list,select,$.vector_indexes
vectorsearch.json,/api/2.0/vector-search/indexes/{index_name}/delete-data,vector_search_indexes_delete_data_vector_index,delete,DeleteDataVectorIndexResponse,"vectorsearch, vector_search_indexes","index_name, primary_keys",Handles the deletion of data from a specified vector index.,Handles the deletion of data from a specified vector index.  :param index_name: str   Name of the vector index where data is to be deleted. Must be a Direct Vector Access Index. :param primary_keys: List[str]   List of primary keys for the data to be deleted.  :returns: :class:`DeleteDataVectorIndexResponse`,indexes,delete_data_vector_index,exec,
vectorsearch.json,/api/2.0/vector-search/indexes/{index_name},vector_search_indexes_delete_index,delete,,"vectorsearch, vector_search_indexes",index_name,Delete an index.,Delete an index.  :param index_name: str   Name of the index,indexes,delete,delete,
vectorsearch.json,/api/2.0/vector-search/indexes/{index_name},vector_search_indexes_get_index,get,VectorIndex,"vectorsearch, vector_search_indexes","index_name, ensure_reranker_compatible",Get an index.,"Get an index.  :param index_name: str   Name of the index :param ensure_reranker_compatible: bool (optional)   If true, the URL returned for the index is guaranteed to be compatible with the reranker. Currently   this means we return the CP URL regardless of how the index is being accessed. If not set or set to   false, the URL may still be compatible with the reranker depending on what URL we return.  :returns: :class:`VectorIndex`",indexes,get,select,
vectorsearch.json,/api/2.0/vector-search/indexes/{index_name}/query,vector_search_indexes_query_index,post,QueryVectorIndexResponse,"vectorsearch, vector_search_indexes","index_name, columns, columns_to_rerank, filters_json, num_results, query_text, query_type, query_vector, reranker, score_threshold",Query the specified vector index.,"Query the specified vector index.  :param index_name: str   Name of the vector index to query. :param columns: List[str]   List of column names to include in the response. :param columns_to_rerank: List[str] (optional)   Column names used to retrieve data to send to the reranker. :param filters_json: str (optional)   JSON string representing query filters.    Example filters:    - `{""id <"": 5}`: Filter for id less than 5. - `{""id >"": 5}`: Filter for id greater than 5. - `{""id   <="": 5}`: Filter for id less than equal to 5. - `{""id >="": 5}`: Filter for id greater than equal to   5. - `{""id"": 5}`: Filter for id equal to 5. :param num_results: int (optional)   Number of results to return. Defaults to 10. :param query_text: str (optional)   Query text. Required for Delta Sync Index using model endpoint. :param query_type: str (optional)   The query type to use. Choices are `ANN` and `HYBRID` and `FULL_TEXT`. Defaults to `ANN`. :param query_vector: List[float] (optional)   Query vector. Required for Direct Vector Access Index and Delta Sync Index using self-managed   vectors. :param reranker: :class:`RerankerConfig` (optional)   If set, the top 50 results are reranked with the Databricks Reranker model before returning the   `num_results` results to the user. The setting `columns_to_rerank` selects which columns are used   for reranking. For each datapoint, the columns selected are concatenated before being sent to the   reranking model. See https://docs.databricks.com/aws/en/vector-search/query-vector-search#rerank for   more information. :param score_threshold: float (optional)   Threshold for the approximate nearest neighbor search. Defaults to 0.0.  :returns: :class:`QueryVectorIndexResponse`",indexes,query_index,exec,
vectorsearch.json,/api/2.0/vector-search/indexes/{index_name}/query-next-page,vector_search_indexes_query_next_page,post,QueryVectorIndexResponse,"vectorsearch, vector_search_indexes","index_name, endpoint_name, page_token",Use `next_page_token` returned from previous `QueryVectorIndex` or `QueryVectorIndexNextPage` request,Use `next_page_token` returned from previous `QueryVectorIndex` or `QueryVectorIndexNextPage` request to fetch next page of results.  :param index_name: str   Name of the vector index to query. :param endpoint_name: str (optional)   Name of the endpoint. :param page_token: str (optional)   Page token returned from previous `QueryVectorIndex` or `QueryVectorIndexNextPage` API.  :returns: :class:`QueryVectorIndexResponse`,indexes,query_next_page,exec,
vectorsearch.json,/api/2.0/vector-search/indexes/{index_name}/scan,vector_search_indexes_scan_index,post,ScanVectorIndexResponse,"vectorsearch, vector_search_indexes","index_name, last_primary_key, num_results",Scan the specified vector index and return the first `num_results` entries after the exclusive,Scan the specified vector index and return the first `num_results` entries after the exclusive `primary_key`.  :param index_name: str   Name of the vector index to scan. :param last_primary_key: str (optional)   Primary key of the last entry returned in the previous scan. :param num_results: int (optional)   Number of results to return. Defaults to 10.  :returns: :class:`ScanVectorIndexResponse`,indexes,scan_index,exec,
vectorsearch.json,/api/2.0/vector-search/indexes/{index_name}/sync,vector_search_indexes_sync_index,post,,"vectorsearch, vector_search_indexes",index_name,Triggers a synchronization process for a specified vector index.,Triggers a synchronization process for a specified vector index.  :param index_name: str   Name of the vector index to synchronize. Must be a Delta Sync Index.,indexes,sync_index,exec,
vectorsearch.json,/api/2.0/vector-search/indexes/{index_name}/upsert-data,vector_search_indexes_upsert_data_vector_index,post,UpsertDataVectorIndexResponse,"vectorsearch, vector_search_indexes","index_name, inputs_json",Handles the upserting of data into a specified vector index.,Handles the upserting of data into a specified vector index.  :param index_name: str   Name of the vector index where data is to be upserted. Must be a Direct Vector Access Index. :param inputs_json: str   JSON string representing the data to be upserted.  :returns: :class:`UpsertDataVectorIndexResponse`,indexes,upsert_data_vector_index,exec,
workspace.json,/api/2.0/git-credentials,git_credentials_create,post,CreateCredentialsResponse,"workspace, git_credentials","git_provider, git_email, git_username, is_default_for_provider, name, personal_access_token, principal_id","Creates a Git credential entry for the user. Only one Git credential per user is supported, so any","Creates a Git credential entry for the user. Only one Git credential per user is supported, so any attempts to create credentials if an entry already exists will fail. Use the PATCH endpoint to update existing credentials, or the DELETE endpoint to delete existing credentials.  :param git_provider: str   Git provider. This field is case-insensitive. The available Git providers are `gitHub`,   `bitbucketCloud`, `gitLab`, `azureDevOpsServices`, `gitHubEnterprise`, `bitbucketServer`,   `gitLabEnterpriseEdition` and `awsCodeCommit`. :param git_email: str (optional)   The authenticating email associated with your Git provider user account. Used for authentication   with the remote repository and also sets the author & committer identity for commits. Required for   most Git providers except AWS CodeCommit. Learn more at   https://docs.databricks.com/aws/en/repos/get-access-tokens-from-git-provider :param git_username: str (optional)   The username provided with your Git provider account and associated with the credential. For most   Git providers it is only used to set the Git committer & author names for commits, however it may be   required for authentication depending on your Git provider / token requirements. Required for AWS   CodeCommit. :param is_default_for_provider: bool (optional)   if the credential is the default for the given provider :param name: str (optional)   the name of the git credential, used for identification and ease of lookup :param personal_access_token: str (optional)   The personal access token used to authenticate to the corresponding Git provider. For certain   providers, support may exist for other types of scoped access tokens. [Learn more].    [Learn more]: https://docs.databricks.com/repos/get-access-tokens-from-git-provider.html :param principal_id: int (optional)   The ID of the service principal whose credentials will be modified. Only service principal managers   can perform this action.  :returns: :class:`CreateCredentialsResponse`",git_credentials,create,insert,
workspace.json,/api/2.0/git-credentials,git_credentials_list,get,ListCredentialsResponse,"workspace, git_credentials",principal_id,Lists the calling user's Git credentials.,Lists the calling user's Git credentials.  :param principal_id: int (optional)   The ID of the service principal whose credentials will be listed. Only service principal managers   can perform this action.  :returns: Iterator over :class:`CredentialInfo`,git_credentials,list,select,$.credentials
workspace.json,/api/2.0/git-credentials/{credential_id},git_credentials_delete,delete,,"workspace, git_credentials","credential_id, principal_id",Deletes the specified Git credential.,Deletes the specified Git credential.  :param credential_id: int   The ID for the corresponding credential to access. :param principal_id: int (optional)   The ID of the service principal whose credentials will be modified. Only service principal managers   can perform this action.,git_credentials,delete,delete,
workspace.json,/api/2.0/git-credentials/{credential_id},git_credentials_get,get,GetCredentialsResponse,"workspace, git_credentials","credential_id, principal_id",Gets the Git credential with the specified credential ID.,Gets the Git credential with the specified credential ID.  :param credential_id: int   The ID for the corresponding credential to access. :param principal_id: int (optional)   The ID of the service principal whose credentials will be modified. Only service principal managers   can perform this action.  :returns: :class:`GetCredentialsResponse`,git_credentials,get,select,
workspace.json,/api/2.0/git-credentials/{credential_id},git_credentials_update,patch,,"workspace, git_credentials","credential_id, git_provider, git_email, git_username, is_default_for_provider, name, personal_access_token, principal_id",Updates the specified Git credential.,"Updates the specified Git credential.  :param credential_id: int   The ID for the corresponding credential to access. :param git_provider: str   Git provider. This field is case-insensitive. The available Git providers are `gitHub`,   `bitbucketCloud`, `gitLab`, `azureDevOpsServices`, `gitHubEnterprise`, `bitbucketServer`,   `gitLabEnterpriseEdition` and `awsCodeCommit`. :param git_email: str (optional)   The authenticating email associated with your Git provider user account. Used for authentication   with the remote repository and also sets the author & committer identity for commits. Required for   most Git providers except AWS CodeCommit. Learn more at   https://docs.databricks.com/aws/en/repos/get-access-tokens-from-git-provider :param git_username: str (optional)   The username provided with your Git provider account and associated with the credential. For most   Git providers it is only used to set the Git committer & author names for commits, however it may be   required for authentication depending on your Git provider / token requirements. Required for AWS   CodeCommit. :param is_default_for_provider: bool (optional)   if the credential is the default for the given provider :param name: str (optional)   the name of the git credential, used for identification and ease of lookup :param personal_access_token: str (optional)   The personal access token used to authenticate to the corresponding Git provider. For certain   providers, support may exist for other types of scoped access tokens. [Learn more].    [Learn more]: https://docs.databricks.com/repos/get-access-tokens-from-git-provider.html :param principal_id: int (optional)   The ID of the service principal whose credentials will be modified. Only service principal managers   can perform this action.",git_credentials,update,update,
workspace.json,/api/2.0/repos,repos_create,post,CreateRepoResponse,"workspace, repos","url, provider, path, sparse_checkout",Creates a repo in the workspace and links it to the remote Git repo specified. Note that repos created,"Creates a repo in the workspace and links it to the remote Git repo specified. Note that repos created programmatically must be linked to a remote Git repo, unlike repos created in the browser.  :param url: str   URL of the Git repository to be linked. :param provider: str   Git provider. This field is case-insensitive. The available Git providers are `gitHub`,   `bitbucketCloud`, `gitLab`, `azureDevOpsServices`, `gitHubEnterprise`, `bitbucketServer`,   `gitLabEnterpriseEdition` and `awsCodeCommit`. :param path: str (optional)   Desired path for the repo in the workspace. Almost any path in the workspace can be chosen. If repo   is created in `/Repos`, path must be in the format `/Repos/{folder}/{repo-name}`. :param sparse_checkout: :class:`SparseCheckout` (optional)   If specified, the repo will be created with sparse checkout enabled. You cannot enable/disable   sparse checkout after the repo is created.  :returns: :class:`CreateRepoResponse`",repos,create,insert,
workspace.json,/api/2.0/repos,repos_list,get,ListReposResponse,"workspace, repos","next_page_token, path_prefix",Returns repos that the calling user has Manage permissions on. Use `next_page_token` to iterate,"Returns repos that the calling user has Manage permissions on. Use `next_page_token` to iterate through additional pages.  :param next_page_token: str (optional)   Token used to get the next page of results. If not specified, returns the first page of results as   well as a next page token if there are more results. :param path_prefix: str (optional)   Filters repos that have paths starting with the given path prefix. If not provided or when provided   an effectively empty prefix (`/` or `/Workspace`) Git folders (repos) from `/Workspace/Repos` will   be served.  :returns: Iterator over :class:`RepoInfo`",repos,list,select,$.repos
workspace.json,/api/2.0/repos/{repo_id},repos_delete,delete,,"workspace, repos",repo_id,Deletes the specified repo.,Deletes the specified repo.  :param repo_id: int   The ID for the corresponding repo to delete.,repos,delete,delete,
workspace.json,/api/2.0/repos/{repo_id},repos_get,get,GetRepoResponse,"workspace, repos",repo_id,Returns the repo with the given repo ID.,Returns the repo with the given repo ID.  :param repo_id: int   ID of the Git folder (repo) object in the workspace.  :returns: :class:`GetRepoResponse`,repos,get,select,
workspace.json,/api/2.0/repos/{repo_id},repos_update,patch,,"workspace, repos","repo_id, branch, sparse_checkout, tag","Updates the repo to a different branch or tag, or updates the repo to the latest commit on the same","Updates the repo to a different branch or tag, or updates the repo to the latest commit on the same branch.  :param repo_id: int   ID of the Git folder (repo) object in the workspace. :param branch: str (optional)   Branch that the local version of the repo is checked out to. :param sparse_checkout: :class:`SparseCheckoutUpdate` (optional)   If specified, update the sparse checkout settings. The update will fail if sparse checkout is not   enabled for the repo. :param tag: str (optional)   Tag that the local version of the repo is checked out to. Updating the repo to a tag puts the repo   in a detached HEAD state. Before committing new changes, you must update the repo to a branch   instead of the detached HEAD.",repos,update,update,
workspace.json,/api/2.0/permissions/repos/{repo_id}/permissionLevels,repos_get_permission_levels,get,GetRepoPermissionLevelsResponse,"workspace, repos",repo_id,Gets the permission levels that a user can have on an object.,Gets the permission levels that a user can have on an object.  :param repo_id: str   The repo for which to get or manage permissions.  :returns: :class:`GetRepoPermissionLevelsResponse`,repo_permission_levels,get,select,
workspace.json,/api/2.0/permissions/repos/{repo_id},repos_get_permissions,get,RepoPermissions,"workspace, repos",repo_id,Gets the permissions of a repo. Repos can inherit permissions from their root object.,Gets the permissions of a repo. Repos can inherit permissions from their root object.  :param repo_id: str   The repo for which to get or manage permissions.  :returns: :class:`RepoPermissions`,repo_permissions,get,select,
workspace.json,/api/2.0/permissions/repos/{repo_id},repos_set_permissions,put,RepoPermissions,"workspace, repos","repo_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their root object.  :param repo_id: str   The repo for which to get or manage permissions. :param access_control_list: List[:class:`RepoAccessControlRequest`] (optional)  :returns: :class:`RepoPermissions`",repo_permissions,set,replace,
workspace.json,/api/2.0/permissions/repos/{repo_id},repos_update_permissions,patch,RepoPermissions,"workspace, repos","repo_id, access_control_list",Updates the permissions on a repo. Repos can inherit permissions from their root object.,Updates the permissions on a repo. Repos can inherit permissions from their root object.  :param repo_id: str   The repo for which to get or manage permissions. :param access_control_list: List[:class:`RepoAccessControlRequest`] (optional)  :returns: :class:`RepoPermissions`,repo_permissions,update,update,
workspace.json,/api/2.0/secrets/scopes/create,secrets_create_scope,post,,"workspace, secrets","scope, backend_azure_keyvault, initial_manage_principal, scope_backend_type",Creates a new secret scope.,"Creates a new secret scope.  The scope name must consist of alphanumeric characters, dashes, underscores, and periods, and may not exceed 128 characters.  Example request:  .. code::  { ""scope"": ""my-simple-databricks-scope"", ""initial_manage_principal"": ""users"" ""scope_backend_type"": ""databricks|azure_keyvault"", # below is only required if scope type is azure_keyvault ""backend_azure_keyvault"": { ""resource_id"": ""/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/xxxx/providers/Microsoft.KeyVault/vaults/xxxx"", ""tenant_id"": ""xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"", ""dns_name"": ""https://xxxx.vault.azure.net/"", } }  If ``initial_manage_principal`` is specified, the initial ACL applied to the scope is applied to the supplied principal (user or group) with ``MANAGE`` permissions. The only supported principal for this option is the group ``users``, which contains all users in the workspace. If ``initial_manage_principal`` is not specified, the initial ACL with ``MANAGE`` permission applied to the scope is assigned to the API request issuer's user identity.  If ``scope_backend_type`` is ``azure_keyvault``, a secret scope is created with secrets from a given Azure KeyVault. The caller must provide the keyvault_resource_id and the tenant_id for the key vault. If ``scope_backend_type`` is ``databricks`` or is unspecified, an empty secret scope is created and stored in Databricks's own storage.  Throws ``RESOURCE_ALREADY_EXISTS`` if a scope with the given name already exists. Throws ``RESOURCE_LIMIT_EXCEEDED`` if maximum number of scopes in the workspace is exceeded. Throws ``INVALID_PARAMETER_VALUE`` if the scope name is invalid. Throws ``BAD_REQUEST`` if request violated constraints. Throws ``CUSTOMER_UNAUTHORIZED`` if normal user attempts to create a scope with name reserved for databricks internal usage. Throws ``UNAUTHENTICATED`` if unable to verify user access permission on Azure KeyVault  :param scope: str   Scope name requested by the user. Scope names are unique. :param backend_azure_keyvault: :class:`AzureKeyVaultSecretScopeMetadata` (optional)   The metadata for the secret scope if the type is ``AZURE_KEYVAULT`` :param initial_manage_principal: str (optional)   The principal that is initially granted ``MANAGE`` permission to the created scope. :param scope_backend_type: :class:`ScopeBackendType` (optional)   The backend type the scope will be created with. If not specified, will default to ``DATABRICKS``",secret_scopes,create,insert,
workspace.json,/api/2.0/secrets/acls/delete,secrets_delete_acl,post,,"workspace, secrets","scope, principal",Deletes the given ACL on the given scope.,"Deletes the given ACL on the given scope.  Users must have the ``MANAGE`` permission to invoke this API.  Example request:  .. code::  { ""scope"": ""my-secret-scope"", ""principal"": ""data-scientists"" }  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret scope, principal, or ACL exists. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call. Throws ``INVALID_PARAMETER_VALUE`` if the permission or principal is invalid.  :param scope: str   The name of the scope to remove permissions from. :param principal: str   The principal to remove an existing ACL from.",secret_acls,delete,exec,
workspace.json,/api/2.0/secrets/scopes/delete,secrets_delete_scope,post,,"workspace, secrets",scope,Deletes a secret scope.,"Deletes a secret scope.  Example request:  .. code::  { ""scope"": ""my-secret-scope"" }  Throws ``RESOURCE_DOES_NOT_EXIST`` if the scope does not exist. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call. Throws ``BAD_REQUEST`` if system user attempts to delete internal secret scope.  :param scope: str   Name of the scope to delete.",secret_scopes,delete,exec,
workspace.json,/api/2.0/secrets/delete,secrets_delete_secret,post,,"workspace, secrets","scope, key",Deletes the secret stored in this secret scope. You must have ``WRITE`` or ``MANAGE`` permission on,"Deletes the secret stored in this secret scope. You must have ``WRITE`` or ``MANAGE`` permission on the Secret Scope.  Example request:  .. code::  { ""scope"": ""my-secret-scope"", ""key"": ""my-secret-key"" }  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret scope or secret exists. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call. Throws ``BAD_REQUEST`` if system user attempts to delete an internal secret, or request is made against Azure KeyVault backed scope.  :param scope: str   The name of the scope that contains the secret to delete. :param key: str   Name of the secret to delete.",secrets,delete,exec,
workspace.json,/api/2.0/secrets/acls/get,secrets_get_acl,get,AclItem,"workspace, secrets","scope, principal","Describes the details about the given ACL, such as the group and permission.","Describes the details about the given ACL, such as the group and permission.  Users must have the ``MANAGE`` permission to invoke this API.  Example response:  .. code::  { ""principal"": ""data-scientists"", ""permission"": ""READ"" }  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret scope exists. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call. Throws ``INVALID_PARAMETER_VALUE`` if the permission or principal is invalid.  :param scope: str   The name of the scope to fetch ACL information from. :param principal: str   The principal to fetch ACL information for.  :returns: :class:`AclItem`",secret_acls,get,select,
workspace.json,/api/2.0/secrets/get,secrets_get_secret,get,GetSecretResponse,"workspace, secrets","scope, key",Gets a secret for a given key and scope. This API can only be called from the DBUtils interface. Users,"Gets a secret for a given key and scope. This API can only be called from the DBUtils interface. Users need the READ permission to make this call.  Example response:  .. code::  { ""key"": ""my-string-key"", ""value"": <bytes of the secret value> }  Note that the secret value returned is in bytes. The interpretation of the bytes is determined by the caller in DBUtils and the type the data is decoded into.  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret or secret scope exists. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call.  Note: This is explicitly an undocumented API. It also doesn't need to be supported for the /preview prefix, because it's not a customer-facing API (i.e. only used for DBUtils SecretUtils to fetch secrets).  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret scope or secret exists. Throws ``BAD_REQUEST`` if normal user calls get secret outside of a notebook. AKV specific errors: Throws ``INVALID_PARAMETER_VALUE`` if secret name is not alphanumeric or too long. Throws ``PERMISSION_DENIED`` if secret manager cannot access AKV with 403 error Throws ``MALFORMED_REQUEST`` if secret manager cannot access AKV with any other 4xx error  :param scope: str   The name of the scope that contains the secret. :param key: str   Name of the secret to fetch value information.  :returns: :class:`GetSecretResponse`",secrets,get,select,
workspace.json,/api/2.0/secrets/acls/list,secrets_list_acls,get,ListAclsResponse,"workspace, secrets",scope,Lists the ACLs set on the given scope.,"Lists the ACLs set on the given scope.  Users must have the ``MANAGE`` permission to invoke this API.  Example response:  .. code::  { ""acls"": [{ ""principal"": ""admins"", ""permission"": ""MANAGE"" },{ ""principal"": ""data-scientists"", ""permission"": ""READ"" }] }  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret scope exists. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call.  :param scope: str   The name of the scope to fetch ACL information from.  :returns: Iterator over :class:`AclItem`",secret_acls,list,select,$.items
workspace.json,/api/2.0/secrets/scopes/list,secrets_list_scopes,get,ListScopesResponse,"workspace, secrets",,Lists all secret scopes available in the workspace.,"Lists all secret scopes available in the workspace.  Example response:  .. code::  { ""scopes"": [{ ""name"": ""my-databricks-scope"", ""backend_type"": ""DATABRICKS"" },{ ""name"": ""mount-points"", ""backend_type"": ""DATABRICKS"" }] }  Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call.   :returns: Iterator over :class:`SecretScope`",secret_scopes,list,select,$.scopes
workspace.json,/api/2.0/secrets/list,secrets_list_secrets,get,ListSecretsResponse,"workspace, secrets",scope,Lists the secret keys that are stored at this scope. This is a metadata-only operation; secret data,"Lists the secret keys that are stored at this scope. This is a metadata-only operation; secret data cannot be retrieved using this API. Users need the READ permission to make this call.  Example response:  .. code::  { ""secrets"": [ { ""key"": ""my-string-key"""", ""last_updated_timestamp"": ""1520467595000"" }, { ""key"": ""my-byte-key"", ""last_updated_timestamp"": ""1520467595000"" }, ] }  The lastUpdatedTimestamp returned is in milliseconds since epoch.  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret scope exists. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call.  :param scope: str   The name of the scope to list secrets within.  :returns: Iterator over :class:`SecretMetadata`",secrets,list,select,$.secrets
workspace.json,/api/2.0/secrets/acls/put,secrets_put_acl,post,,"workspace, secrets","scope, principal, permission",Creates or overwrites the ACL associated with the given principal (user or group) on the specified,"Creates or overwrites the ACL associated with the given principal (user or group) on the specified scope point. In general, a user or group will use the most powerful permission available to them, and permissions are ordered as follows:  * ``MANAGE`` - Allowed to change ACLs, and read and write to this secret scope. * ``WRITE`` - Allowed to read and write to this secret scope. * ``READ`` - Allowed to read this secret scope and list what secrets are available.  Note that in general, secret values can only be read from within a command on a cluster (for example, through a notebook). There is no API to read the actual secret value material outside of a cluster. However, the user's permission will be applied based on who is executing the command, and they must have at least READ permission.  Users must have the ``MANAGE`` permission to invoke this API.  Example request:  .. code::  { ""scope"": ""my-secret-scope"", ""principal"": ""data-scientists"", ""permission"": ""READ"" }  The principal is a user or group name corresponding to an existing Databricks principal to be granted or revoked access.  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret scope exists. Throws ``RESOURCE_ALREADY_EXISTS`` if a permission for the principal already exists. Throws ``INVALID_PARAMETER_VALUE`` if the permission or principal is invalid. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call.  :param scope: str   The name of the scope to apply permissions to. :param principal: str   The principal in which the permission is applied. :param permission: :class:`AclPermission`   The permission level applied to the principal.",secret_acls,put,insert,
workspace.json,/api/2.0/secrets/put,secrets_put_secret,post,,"workspace, secrets","scope, key, bytes_value, string_value",Inserts a secret under the provided scope with the given name. If a secret already exists with the,"Inserts a secret under the provided scope with the given name. If a secret already exists with the same name, this command overwrites the existing secret's value. The server encrypts the secret using the secret scope's encryption settings before storing it. You must have ``WRITE`` or ``MANAGE`` permission on the secret scope.  The secret key must consist of alphanumeric characters, dashes, underscores, and periods, and cannot exceed 128 characters. The maximum allowed secret value size is 128 KB. The maximum number of secrets in a given scope is 1000.  Example request:  .. code::  { ""scope"": ""my-databricks-scope"", ""key"": ""my-string-key"", ""string_value"": ""foobar"" }  The input fields ""string_value"" or ""bytes_value"" specify the type of the secret, which will determine the value returned when the secret value is requested. Exactly one must be specified.  Throws ``RESOURCE_DOES_NOT_EXIST`` if no such secret scope exists. Throws ``RESOURCE_LIMIT_EXCEEDED`` if maximum number of secrets in scope is exceeded. Throws ``INVALID_PARAMETER_VALUE`` if the request parameters are invalid. Throws ``PERMISSION_DENIED`` if the user does not have permission to make this API call. Throws ``MALFORMED_REQUEST`` if request is incorrectly formatted or conflicting. Throws ``BAD_REQUEST`` if request is made against Azure KeyVault backed scope.  :param scope: str   The name of the scope to which the secret will be associated with. :param key: str   A unique name to identify the secret. :param bytes_value: str (optional)   If specified, value will be stored as bytes. :param string_value: str (optional)   If specified, note that the value will be stored in UTF-8 (MB4) form.",secrets,put,insert,
workspace.json,/api/2.0/workspace/delete,workspace_delete,post,,workspace,"path, recursive",Deletes an object or a directory (and optionally recursively deletes all objects in the directory). *,"Deletes an object or a directory (and optionally recursively deletes all objects in the directory). * If `path` does not exist, this call returns an error `RESOURCE_DOES_NOT_EXIST`. * If `path` is a non-empty directory and `recursive` is set to `false`, this call returns an error `DIRECTORY_NOT_EMPTY`.  Object deletion cannot be undone and deleting a directory recursively is not atomic.  :param path: str   The absolute path of the notebook or directory. :param recursive: bool (optional)   The flag that specifies whether to delete the object recursively. It is `false` by default. Please   note this deleting directory is not atomic. If it fails in the middle, some of objects under this   directory may be deleted and cannot be undone.",workspace,delete,exec,
workspace.json,/api/2.0/workspace/export,workspace_export,get,ExportResponse,workspace,"path, format",Exports an object or the contents of an entire directory.,"Exports an object or the contents of an entire directory.  If `path` does not exist, this call returns an error `RESOURCE_DOES_NOT_EXIST`.  If the exported data would exceed size limit, this call returns `MAX_NOTEBOOK_SIZE_EXCEEDED`. Currently, this API does not support exporting a library.  :param path: str   The absolute path of the object or directory. Exporting a directory is only supported for the `DBC`,   `SOURCE`, and `AUTO` format. :param format: :class:`ExportFormat` (optional)   This specifies the format of the exported file. By default, this is `SOURCE`.    The value is case sensitive.    - `SOURCE`: The notebook is exported as source code. Directory exports will not include non-notebook   entries. - `HTML`: The notebook is exported as an HTML file. - `JUPYTER`: The notebook is exported   as a Jupyter/IPython Notebook file. - `DBC`: The notebook is exported in Databricks archive format.   Directory exports will not include non-notebook entries. - `R_MARKDOWN`: The notebook is exported to   R Markdown format. - `AUTO`: The object or directory is exported depending on the objects type.   Directory exports will include notebooks and workspace files.  :returns: :class:`ExportResponse`",workspace,export,exec,
workspace.json,/api/2.0/permissions/{workspace_object_type}/{workspace_object_id}/permissionLevels,workspace_get_permission_levels,get,GetWorkspaceObjectPermissionLevelsResponse,workspace,"workspace_object_type, workspace_object_id",Gets the permission levels that a user can have on an object.,"Gets the permission levels that a user can have on an object.  :param workspace_object_type: str   The workspace object type for which to get or manage permissions. Could be one of the following:   alerts, alertsv2, dashboards, dbsql-dashboards, directories, experiments, files, genie, notebooks,   queries :param workspace_object_id: str   The workspace object for which to get or manage permissions.  :returns: :class:`GetWorkspaceObjectPermissionLevelsResponse`",object_permission_levels,get,select,
workspace.json,/api/2.0/permissions/{workspace_object_type}/{workspace_object_id},workspace_get_permissions,get,WorkspaceObjectPermissions,workspace,"workspace_object_type, workspace_object_id",Gets the permissions of a workspace object. Workspace objects can inherit permissions from their,"Gets the permissions of a workspace object. Workspace objects can inherit permissions from their parent objects or root object.  :param workspace_object_type: str   The workspace object type for which to get or manage permissions. Could be one of the following:   alerts, alertsv2, dashboards, dbsql-dashboards, directories, experiments, files, genie, notebooks,   queries :param workspace_object_id: str   The workspace object for which to get or manage permissions.  :returns: :class:`WorkspaceObjectPermissions`",object_permissions,get,select,
workspace.json,/api/2.0/permissions/{workspace_object_type}/{workspace_object_id},workspace_set_permissions,put,WorkspaceObjectPermissions,workspace,"workspace_object_type, workspace_object_id, access_control_list","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct","Sets permissions on an object, replacing existing permissions if they exist. Deletes all direct permissions if none are specified. Objects can inherit permissions from their parent objects or root object.  :param workspace_object_type: str   The workspace object type for which to get or manage permissions. Could be one of the following:   alerts, alertsv2, dashboards, dbsql-dashboards, directories, experiments, files, genie, notebooks,   queries :param workspace_object_id: str   The workspace object for which to get or manage permissions. :param access_control_list: List[:class:`WorkspaceObjectAccessControlRequest`] (optional)  :returns: :class:`WorkspaceObjectPermissions`",object_permissions,set,replace,
workspace.json,/api/2.0/permissions/{workspace_object_type}/{workspace_object_id},workspace_update_permissions,patch,WorkspaceObjectPermissions,workspace,"workspace_object_type, workspace_object_id, access_control_list",Updates the permissions on a workspace object. Workspace objects can inherit permissions from their,"Updates the permissions on a workspace object. Workspace objects can inherit permissions from their parent objects or root object.  :param workspace_object_type: str   The workspace object type for which to get or manage permissions. Could be one of the following:   alerts, alertsv2, dashboards, dbsql-dashboards, directories, experiments, files, genie, notebooks,   queries :param workspace_object_id: str   The workspace object for which to get or manage permissions. :param access_control_list: List[:class:`WorkspaceObjectAccessControlRequest`] (optional)  :returns: :class:`WorkspaceObjectPermissions`",object_permissions,update,update,
workspace.json,/api/2.0/workspace/get-status,workspace_get_status,get,ObjectInfo,workspace,path,"Gets the status of an object or a directory. If `path` does not exist, this call returns an error","Gets the status of an object or a directory. If `path` does not exist, this call returns an error `RESOURCE_DOES_NOT_EXIST`.  :param path: str   The absolute path of the notebook or directory.  :returns: :class:`ObjectInfo`",workspace_status,get,select,
workspace.json,/api/2.0/workspace/import,workspace_import_,post,,workspace,"path, content, format, language, overwrite","Imports a workspace object (for example, a notebook or file) or the contents of an entire directory.","Imports a workspace object (for example, a notebook or file) or the contents of an entire directory. If `path` already exists and `overwrite` is set to `false`, this call returns an error `RESOURCE_ALREADY_EXISTS`. To import a directory, you can use either the `DBC` format or the `SOURCE` format with the `language` field unset. To import a single file as `SOURCE`, you must set the `language` field. Zip files within directories are not supported.  :param path: str   The absolute path of the object or directory. Importing a directory is only supported for the `DBC`   and `SOURCE` formats. :param content: str (optional)   The base64-encoded content. This has a limit of 10 MB.    If the limit (10MB) is exceeded, exception with error code **MAX_NOTEBOOK_SIZE_EXCEEDED** is thrown.   This parameter might be absent, and instead a posted file is used. :param format: :class:`ImportFormat` (optional)   This specifies the format of the file to be imported.    The value is case sensitive.    - `AUTO`: The item is imported depending on an analysis of the item's extension and the header   content provided in the request. If the item is imported as a notebook, then the item's extension is   automatically removed. - `SOURCE`: The notebook or directory is imported as source code. - `HTML`:   The notebook is imported as an HTML file. - `JUPYTER`: The notebook is imported as a Jupyter/IPython   Notebook file. - `DBC`: The notebook is imported in Databricks archive format. Required for   directories. - `R_MARKDOWN`: The notebook is imported from R Markdown format. :param language: :class:`Language` (optional)   The language of the object. This value is set only if the object type is `NOTEBOOK`. :param overwrite: bool (optional)   The flag that specifies whether to overwrite existing object. It is `false` by default. For `DBC`   format, `overwrite` is not supported since it may contain a directory.",workspace,import,exec,
workspace.json,/api/2.0/workspace/list,workspace_list,get,ListResponse,workspace,"path, notebooks_modified_after","Lists the contents of a directory, or the object if it is not a directory. If the input path does not","Lists the contents of a directory, or the object if it is not a directory. If the input path does not exist, this call returns an error `RESOURCE_DOES_NOT_EXIST`.  :param path: str   The absolute path of the notebook or directory. :param notebooks_modified_after: int (optional)   UTC timestamp in milliseconds  :returns: Iterator over :class:`ObjectInfo`",workspace,list,select,$.objects
workspace.json,/api/2.0/workspace/mkdirs,workspace_mkdirs,post,,workspace,path,Creates the specified directory (and necessary parent directories if they do not exist). If there is,"Creates the specified directory (and necessary parent directories if they do not exist). If there is an object (not a directory) at any prefix of the input path, this call returns an error `RESOURCE_ALREADY_EXISTS`.  Note that if this operation fails it may have succeeded in creating some of the necessary parent directories.  :param path: str   The absolute path of the directory. If the parent directories do not exist, it will also create   them. If the directory already exists, this command will do nothing and succeed.",workspace,mkdirs,exec,
