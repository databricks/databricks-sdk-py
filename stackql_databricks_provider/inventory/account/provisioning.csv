service,operation_id,http_path,http_verb,tags,params,success_response_object,summary,description,stackql_resource_name,stackql_method_name,stackql_verb
provisioning,credentials_create,/api/2.0/accounts/{account_id}/credentials,post,"provisioning, credentials","credentials_name, aws_credentials",Credential,Creates a Databricks credential configuration that represents cloud cross-account credentials for a,"Creates a Databricks credential configuration that represents cloud cross-account credentials for a specified account. Databricks uses this to set up network infrastructure properly to host Databricks clusters. For your AWS IAM role, you need to trust the External ID (the Databricks Account API account ID) in the returned credential object, and configure the required access policy.  Save the response's `credentials_id` field, which is the ID for your new credential configuration object.  For information about how to create a new workspace with this API, see [Create a new workspace using the Account API]  [Create a new workspace using the Account API]: http://docs.databricks.com/administration-guide/account-api/new-workspace.html  :param credentials_name: str   The human-readable name of the credential configuration object. :param aws_credentials: :class:`CreateCredentialAwsCredentials`  :returns: :class:`Credential`",credentials,credentials_create,INSERT
provisioning,credentials_list,/api/2.0/accounts/{account_id}/credentials,get,"provisioning, credentials",,Iterator[Credential],"List Databricks credential configuration objects for an account, specified by ID.","List Databricks credential configuration objects for an account, specified by ID.   :returns: Iterator over :class:`Credential`",credentials,credentials_list,SELECT
provisioning,credentials_delete,/api/2.0/accounts/{account_id}/credentials/{credentials_id},delete,"provisioning, credentials",credentials_id,Credential,"Deletes a Databricks credential configuration object for an account, both specified by ID. You cannot","Deletes a Databricks credential configuration object for an account, both specified by ID. You cannot delete a credential that is associated with any workspace.  :param credentials_id: str   Databricks Account API credential configuration ID  :returns: :class:`Credential`",credentials,credentials_delete,DELETE
provisioning,credentials_get,/api/2.0/accounts/{account_id}/credentials/{credentials_id},get,"provisioning, credentials",credentials_id,Credential,"Gets a Databricks credential configuration object for an account, both specified by ID.","Gets a Databricks credential configuration object for an account, both specified by ID.  :param credentials_id: str   Credential configuration ID  :returns: :class:`Credential`",credentials,credentials_get,SELECT
provisioning,encryption_keys_create,/api/2.0/accounts/{account_id}/customer-managed-keys,post,"provisioning, encryption_keys","use_cases, aws_key_info, gcp_key_info",CustomerManagedKey,"Creates a customer-managed key configuration object for an account, specified by ID. This operation","Creates a customer-managed key configuration object for an account, specified by ID. This operation uploads a reference to a customer-managed key to Databricks. If the key is assigned as a workspace's customer-managed key for managed services, Databricks uses the key to encrypt the workspaces notebooks and secrets in the control plane, in addition to Databricks SQL queries and query history. If it is specified as a workspace's customer-managed key for workspace storage, the key encrypts the workspace's root S3 bucket (which contains the workspace's root DBFS and system data) and, optionally, cluster EBS volume data.  **Important**: Customer-managed keys are supported only for some deployment types, subscription types, and AWS regions that currently support creation of Databricks workspaces.  This operation is available only if your account is on the E2 version of the platform or on a select custom plan that allows multiple workspaces per account.  :param use_cases: List[:class:`KeyUseCase`]   The cases that the key can be used for. :param aws_key_info: :class:`CreateAwsKeyInfo` (optional) :param gcp_key_info: :class:`CreateGcpKeyInfo` (optional)  :returns: :class:`CustomerManagedKey`",encryption_keys,encryption_keys_create,INSERT
provisioning,encryption_keys_list,/api/2.0/accounts/{account_id}/customer-managed-keys,get,"provisioning, encryption_keys",,Iterator[CustomerManagedKey],Lists Databricks customer-managed key configurations for an account.,Lists Databricks customer-managed key configurations for an account.   :returns: Iterator over :class:`CustomerManagedKey`,encryption_keys,encryption_keys_list,SELECT
provisioning,encryption_keys_delete,/api/2.0/accounts/{account_id}/customer-managed-keys/{customer_managed_key_id},delete,"provisioning, encryption_keys",customer_managed_key_id,CustomerManagedKey,Deletes a customer-managed key configuration object for an account. You cannot delete a configuration,Deletes a customer-managed key configuration object for an account. You cannot delete a configuration that is associated with a running workspace.  :param customer_managed_key_id: str   Databricks encryption key configuration ID.  :returns: :class:`CustomerManagedKey`,encryption_keys,encryption_keys_delete,DELETE
provisioning,encryption_keys_get,/api/2.0/accounts/{account_id}/customer-managed-keys/{customer_managed_key_id},get,"provisioning, encryption_keys",customer_managed_key_id,CustomerManagedKey,"Gets a customer-managed key configuration object for an account, specified by ID. This operation","Gets a customer-managed key configuration object for an account, specified by ID. This operation uploads a reference to a customer-managed key to Databricks. If assigned as a workspace's customer-managed key for managed services, Databricks uses the key to encrypt the workspaces notebooks and secrets in the control plane, in addition to Databricks SQL queries and query history. If it is specified as a workspace's customer-managed key for storage, the key encrypts the workspace's root S3 bucket (which contains the workspace's root DBFS and system data) and, optionally, cluster EBS volume data.  **Important**: Customer-managed keys are supported only for some deployment types, subscription types, and AWS regions.  This operation is available only if your account is on the E2 version of the platform."",  :param customer_managed_key_id: str   Databricks encryption key configuration ID.  :returns: :class:`CustomerManagedKey`",encryption_keys,encryption_keys_get,SELECT
provisioning,networks_create,/api/2.0/accounts/{account_id}/networks,post,"provisioning, networks","gcp_network_info, network_name, security_group_ids, subnet_ids, vpc_endpoints, vpc_id",Network,Creates a Databricks network configuration that represents an VPC and its resources. The VPC will be,Creates a Databricks network configuration that represents an VPC and its resources. The VPC will be used for new Databricks clusters. This requires a pre-existing VPC and subnets.  :param gcp_network_info: :class:`GcpNetworkInfo` (optional) :param network_name: str (optional)   The human-readable name of the network configuration. :param security_group_ids: List[str] (optional)   IDs of one to five security groups associated with this network. Security group IDs **cannot** be   used in multiple network configurations. :param subnet_ids: List[str] (optional)   IDs of at least two subnets associated with this network. Subnet IDs **cannot** be used in multiple   network configurations. :param vpc_endpoints: :class:`NetworkVpcEndpoints` (optional) :param vpc_id: str (optional)   The ID of the VPC associated with this network configuration. VPC IDs can be used in multiple   networks.  :returns: :class:`Network`,networks,networks_create,INSERT
provisioning,networks_list,/api/2.0/accounts/{account_id}/networks,get,"provisioning, networks",,Iterator[Network],Lists Databricks network configurations for an account.,Lists Databricks network configurations for an account.   :returns: Iterator over :class:`Network`,networks,networks_list,SELECT
provisioning,networks_delete,/api/2.0/accounts/{account_id}/networks/{network_id},delete,"provisioning, networks",network_id,Network,"Deletes a Databricks network configuration, which represents a cloud VPC and its resources. You cannot","Deletes a Databricks network configuration, which represents a cloud VPC and its resources. You cannot delete a network that is associated with a workspace.  This operation is available only if your account is on the E2 version of the platform.  :param network_id: str   Databricks Account API network configuration ID.  :returns: :class:`Network`",networks,networks_delete,DELETE
provisioning,networks_get,/api/2.0/accounts/{account_id}/networks/{network_id},get,"provisioning, networks",network_id,Network,"Gets a Databricks network configuration, which represents a cloud VPC and its resources.","Gets a Databricks network configuration, which represents a cloud VPC and its resources.  :param network_id: str   Databricks Account API network configuration ID.  :returns: :class:`Network`",networks,networks_get,SELECT
provisioning,private_access_create,/api/2.0/accounts/{account_id}/private-access-settings,post,"provisioning, private_access","allowed_vpc_endpoint_ids, private_access_level, private_access_settings_name, public_access_enabled, region",PrivateAccessSettings,"Creates a private access settings configuration, which represents network access restrictions for","Creates a private access settings configuration, which represents network access restrictions for workspace resources. Private access settings configure whether workspaces can be accessed from the public internet or only from private endpoints.  :param allowed_vpc_endpoint_ids: List[str] (optional)   An array of Databricks VPC endpoint IDs. This is the Databricks ID returned when registering the VPC   endpoint configuration in your Databricks account. This is not the ID of the VPC endpoint in AWS.   Only used when private_access_level is set to ENDPOINT. This is an allow list of VPC endpoints   registered in your Databricks account that can connect to your workspace over AWS PrivateLink. Note:   If hybrid access to your workspace is enabled by setting public_access_enabled to true, this control   only works for PrivateLink connections. To control how your workspace is accessed via public   internet, see IP access lists. :param private_access_level: :class:`PrivateAccessLevel` (optional)   The private access level controls which VPC endpoints can connect to the UI or API of any workspace   that attaches this private access settings object. `ACCOUNT` level access (the default) allows only   VPC endpoints that are registered in your Databricks account connect to your workspace. `ENDPOINT`   level access allows only specified VPC endpoints connect to your workspace. For details, see   allowed_vpc_endpoint_ids. :param private_access_settings_name: str (optional)   The human-readable name of the private access settings object. :param public_access_enabled: bool (optional)   Determines if the workspace can be accessed over public internet. For fully private workspaces, you   can optionally specify false, but only if you implement both the front-end and the back-end   PrivateLink connections. Otherwise, specify true, which means that public access is enabled. :param region: str (optional)   The AWS region for workspaces attached to this private access settings object.  :returns: :class:`PrivateAccessSettings`",private_access,private_access_create,INSERT
provisioning,private_access_list,/api/2.0/accounts/{account_id}/private-access-settings,get,"provisioning, private_access",,Iterator[PrivateAccessSettings],Lists Databricks private access settings for an account.,Lists Databricks private access settings for an account.   :returns: Iterator over :class:`PrivateAccessSettings`,private_access,private_access_list,SELECT
provisioning,private_access_delete,/api/2.0/accounts/{account_id}/private-access-settings/{private_access_settings_id},delete,"provisioning, private_access",private_access_settings_id,PrivateAccessSettings,"Deletes a Databricks private access settings configuration, both specified by ID.","Deletes a Databricks private access settings configuration, both specified by ID.  :param private_access_settings_id: str  :returns: :class:`PrivateAccessSettings`",private_access,private_access_delete,DELETE
provisioning,private_access_get,/api/2.0/accounts/{account_id}/private-access-settings/{private_access_settings_id},get,"provisioning, private_access",private_access_settings_id,PrivateAccessSettings,"Gets a Databricks private access settings configuration, both specified by ID.","Gets a Databricks private access settings configuration, both specified by ID.  :param private_access_settings_id: str  :returns: :class:`PrivateAccessSettings`",private_access,private_access_get,SELECT
provisioning,private_access_replace,/api/2.0/accounts/{account_id}/private-access-settings/{private_access_settings_id},put,"provisioning, private_access","private_access_settings_id, customer_facing_private_access_settings",PrivateAccessSettings,"Updates an existing private access settings object, which specifies how your workspace is accessed","Updates an existing private access settings object, which specifies how your workspace is accessed over AWS PrivateLink. To use AWS PrivateLink, a workspace must have a private access settings object referenced by ID in the workspace's private_access_settings_id property. This operation completely overwrites your existing private access settings object attached to your workspaces. All workspaces attached to the private access settings are affected by any change. If public_access_enabled, private_access_level, or allowed_vpc_endpoint_ids are updated, effects of these changes might take several minutes to propagate to the workspace API. You can share one private access settings object with multiple workspaces in a single account. However, private access settings are specific to AWS regions, so only workspaces in the same AWS region can use a given private access settings object. Before configuring PrivateLink, read the Databricks article about PrivateLink.  :param private_access_settings_id: str   Databricks private access settings ID. :param customer_facing_private_access_settings: :class:`PrivateAccessSettings`   Properties of the new private access settings object.  :returns: :class:`PrivateAccessSettings`",private_access,private_access_replace,REPLACE
provisioning,storage_create,/api/2.0/accounts/{account_id}/storage-configurations,post,"provisioning, storage","storage_configuration_name, root_bucket_info, role_arn",StorageConfiguration,Creates a Databricks storage configuration for an account.,"Creates a Databricks storage configuration for an account.  :param storage_configuration_name: str   The human-readable name of the storage configuration. :param root_bucket_info: :class:`RootBucketInfo`   Root S3 bucket information. :param role_arn: str (optional)   Optional IAM role that is used to access the workspace catalog which is created during workspace   creation for UC by Default. If a storage configuration with this field populated is used to create a   workspace, then a workspace catalog is created together with the workspace. The workspace catalog   shares the root bucket with internal workspace storage (including DBFS root) but uses a dedicated   bucket path prefix.  :returns: :class:`StorageConfiguration`",storage,storage_create,INSERT
provisioning,storage_list,/api/2.0/accounts/{account_id}/storage-configurations,get,"provisioning, storage",,Iterator[StorageConfiguration],"Lists Databricks storage configurations for an account, specified by ID.","Lists Databricks storage configurations for an account, specified by ID.   :returns: Iterator over :class:`StorageConfiguration`",storage,storage_list,SELECT
provisioning,storage_delete,/api/2.0/accounts/{account_id}/storage-configurations/{storage_configuration_id},delete,"provisioning, storage",storage_configuration_id,StorageConfiguration,Deletes a Databricks storage configuration. You cannot delete a storage configuration that is,Deletes a Databricks storage configuration. You cannot delete a storage configuration that is associated with any workspace.  :param storage_configuration_id: str  :returns: :class:`StorageConfiguration`,storage,storage_delete,DELETE
provisioning,storage_get,/api/2.0/accounts/{account_id}/storage-configurations/{storage_configuration_id},get,"provisioning, storage",storage_configuration_id,StorageConfiguration,"Gets a Databricks storage configuration for an account, both specified by ID.","Gets a Databricks storage configuration for an account, both specified by ID.  :param storage_configuration_id: str  :returns: :class:`StorageConfiguration`",storage,storage_get,SELECT
provisioning,vpc_endpoints_create,/api/2.0/accounts/{account_id}/vpc-endpoints,post,"provisioning, vpc_endpoints","aws_vpc_endpoint_id, gcp_vpc_endpoint_info, region, vpc_endpoint_name",VpcEndpoint,"Creates a VPC endpoint configuration, which represents a [VPC endpoint] object in AWS used to","Creates a VPC endpoint configuration, which represents a [VPC endpoint] object in AWS used to communicate privately with Databricks over [AWS PrivateLink].  After you create the VPC endpoint configuration, the Databricks [endpoint service] automatically accepts the VPC endpoint.  Before configuring PrivateLink, read the [Databricks article about PrivateLink].  [AWS PrivateLink]: https://aws.amazon.com/privatelink [Databricks article about PrivateLink]: https://docs.databricks.com/administration-guide/cloud-configurations/aws/privatelink.html [VPC endpoint]: https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints.html [endpoint service]: https://docs.aws.amazon.com/vpc/latest/privatelink/privatelink-share-your-services.html  :param aws_vpc_endpoint_id: str (optional)   The ID of the VPC endpoint object in AWS. :param gcp_vpc_endpoint_info: :class:`GcpVpcEndpointInfo` (optional)   The cloud info of this vpc endpoint. :param region: str (optional)   The region in which this VPC endpoint object exists. :param vpc_endpoint_name: str (optional)   The human-readable name of the storage configuration.  :returns: :class:`VpcEndpoint`",vpc_endpoints,vpc_endpoints_create,INSERT
provisioning,vpc_endpoints_list,/api/2.0/accounts/{account_id}/vpc-endpoints,get,"provisioning, vpc_endpoints",,Iterator[VpcEndpoint],Lists Databricks VPC endpoint configurations for an account.,Lists Databricks VPC endpoint configurations for an account.   :returns: Iterator over :class:`VpcEndpoint`,vpc_endpoints,vpc_endpoints_list,SELECT
provisioning,vpc_endpoints_delete,/api/2.0/accounts/{account_id}/vpc-endpoints/{vpc_endpoint_id},delete,"provisioning, vpc_endpoints",vpc_endpoint_id,VpcEndpoint,Deletes a Databricks VPC endpoint configuration. You cannot delete a VPC endpoint configuration that,Deletes a Databricks VPC endpoint configuration. You cannot delete a VPC endpoint configuration that is associated with any workspace.  :param vpc_endpoint_id: str  :returns: :class:`VpcEndpoint`,vpc_endpoints,vpc_endpoints_delete,DELETE
provisioning,vpc_endpoints_get,/api/2.0/accounts/{account_id}/vpc-endpoints/{vpc_endpoint_id},get,"provisioning, vpc_endpoints",vpc_endpoint_id,VpcEndpoint,"Gets a VPC endpoint configuration, which represents a [VPC endpoint] object in AWS used to communicate","Gets a VPC endpoint configuration, which represents a [VPC endpoint] object in AWS used to communicate privately with Databricks over [AWS PrivateLink].  [AWS PrivateLink]: https://aws.amazon.com/privatelink [VPC endpoint]: https://docs.aws.amazon.com/vpc/latest/privatelink/concepts.html  :param vpc_endpoint_id: str   Databricks VPC endpoint ID.  :returns: :class:`VpcEndpoint`",vpc_endpoints,vpc_endpoints_get,SELECT
provisioning,workspaces_create,/api/2.0/accounts/{account_id}/workspaces,post,"provisioning, workspaces","aws_region, cloud, cloud_resource_container, compute_mode, credentials_id, custom_tags, deployment_name, gcp_managed_network_config, gke_config, location, managed_services_customer_managed_key_id, network_connectivity_config_id, network_id, pricing_tier, private_access_settings_id, storage_configuration_id, storage_customer_managed_key_id, workspace_name",Wait[Workspace],"Creates a new workspace using a credential configuration and a storage configuration, an optional","Creates a new workspace using a credential configuration and a storage configuration, an optional network configuration (if using a customer-managed VPC), an optional managed services key configuration (if using customer-managed keys for managed services), and an optional storage key configuration (if using customer-managed keys for storage). The key configurations used for managed services and storage encryption can be the same or different.  Important: This operation is asynchronous. A response with HTTP status code 200 means the request has been accepted and is in progress, but does not mean that the workspace deployed successfully and is running. The initial workspace status is typically PROVISIONING. Use the workspace ID (workspace_id) field in the response to identify the new workspace and make repeated GET requests with the workspace ID and check its status. The workspace becomes available when the status changes to RUNNING.  You can share one customer-managed VPC with multiple workspaces in a single account. It is not required to create a new VPC for each workspace. However, you cannot reuse subnets or Security Groups between workspaces. If you plan to share one VPC with multiple workspaces, make sure you size your VPC and subnets accordingly. Because a Databricks Account API network configuration encapsulates this information, you cannot reuse a Databricks Account API network configuration across workspaces.  For information about how to create a new workspace with this API including error handling, see [Create a new workspace using the Account API].  Important: Customer-managed VPCs, PrivateLink, and customer-managed keys are supported on a limited set of deployment and subscription types. If you have questions about availability, contact your Databricks representative.  This operation is available only if your account is on the E2 version of the platform or on a select custom plan that allows multiple workspaces per account.  [Create a new workspace using the Account API]: http://docs.databricks.com/administration-guide/account-api/new-workspace.html  :param aws_region: str (optional) :param cloud: str (optional)   The cloud name. This field always has the value `gcp`. :param cloud_resource_container: :class:`CloudResourceContainer` (optional) :param compute_mode: :class:`CustomerFacingComputeMode` (optional)   If the compute mode is `SERVERLESS`, a serverless workspace is created that comes pre-configured   with serverless compute and default storage, providing a fully-managed, enterprise-ready SaaS   experience. This means you don't need to provide any resources managed by you, such as credentials,   storage, or network. If the compute mode is `HYBRID` (which is the default option), a classic   workspace is created that uses customer-managed resources. :param credentials_id: str (optional)   ID of the workspace's credential configuration object. :param custom_tags: Dict[str,str] (optional)   The custom tags key-value pairing that is attached to this workspace. The key-value pair is a string   of utf-8 characters. The value can be an empty string, with maximum length of 255 characters. The   key can be of maximum length of 127 characters, and cannot be empty. :param deployment_name: str (optional)   The deployment name defines part of the subdomain for the workspace. The workspace URL for the web   application and REST APIs is <workspace-deployment-name>.cloud.databricks.com. For example, if the   deployment name is abcsales, your workspace URL will be https://abcsales.cloud.databricks.com.   Hyphens are allowed. This property supports only the set of characters that are allowed in a   subdomain. To set this value, you must have a deployment name prefix. Contact your Databricks   account team to add an account deployment name prefix to your account. Workspace deployment names   follow the account prefix and a hyphen. For example, if your account's deployment prefix is acme and   the workspace deployment name is workspace-1, the JSON response for the deployment_name field   becomes acme-workspace-1. The workspace URL would be acme-workspace-1.cloud.databricks.com. You can   also set the deployment_name to the reserved keyword EMPTY if you want the deployment name to only   include the deployment prefix. For example, if your account's deployment prefix is acme and the   workspace deployment name is EMPTY, the deployment_name becomes acme only and the workspace URL is   acme.cloud.databricks.com. This value must be unique across all non-deleted deployments across all   AWS regions. If a new workspace omits this property, the server generates a unique deployment name   for you with the pattern dbc-xxxxxxxx-xxxx. :param gcp_managed_network_config: :class:`GcpManagedNetworkConfig` (optional) :param gke_config: :class:`GkeConfig` (optional) :param location: str (optional)   The Google Cloud region of the workspace data plane in your Google account (for example,   `us-east4`). :param managed_services_customer_managed_key_id: str (optional)   The ID of the workspace's managed services encryption key configuration object. This is used to help   protect and control access to the workspace's notebooks, secrets, Databricks SQL queries, and query   history. The provided key configuration object property use_cases must contain MANAGED_SERVICES. :param network_connectivity_config_id: str (optional)   The object ID of network connectivity config. Once assigned, the workspace serverless compute   resources use the same set of stable IP CIDR blocks and optional private link to access your   resources. :param network_id: str (optional)   The ID of the workspace's network configuration object. To use AWS PrivateLink, this field is   required. :param pricing_tier: :class:`PricingTier` (optional) :param private_access_settings_id: str (optional)   ID of the workspace's private access settings object. Only used for PrivateLink. You must specify   this ID if you are using [AWS PrivateLink] for either front-end (user-to-workspace connection),   back-end (data plane to control plane connection), or both connection types. Before configuring   PrivateLink, read the [Databricks article about PrivateLink]."",    [AWS PrivateLink]: https://aws.amazon.com/privatelink/   [Databricks article about PrivateLink]: https://docs.databricks.com/administration-guide/cloud-configurations/aws/privatelink.html :param storage_configuration_id: str (optional)   ID of the workspace's storage configuration object. :param storage_customer_managed_key_id: str (optional)   The ID of the workspace's storage encryption key configuration object. This is used to encrypt the   workspace's root S3 bucket (root DBFS and system data) and, optionally, cluster EBS volumes. The   provided key configuration object property use_cases must contain STORAGE. :param workspace_name: str (optional)   The human-readable name of the workspace.  :returns:   Long-running operation waiter for :class:`Workspace`.   See :method:wait_get_workspace_running for more details.",workspaces,workspaces_create,INSERT
provisioning,workspaces_list,/api/2.0/accounts/{account_id}/workspaces,get,"provisioning, workspaces",,Iterator[Workspace],Lists Databricks workspaces for an account.,Lists Databricks workspaces for an account.   :returns: Iterator over :class:`Workspace`,workspaces,workspaces_list,SELECT
provisioning,workspaces_delete,/api/2.0/accounts/{account_id}/workspaces/{workspace_id},delete,"provisioning, workspaces",workspace_id,Workspace,"Deletes a Databricks workspace, both specified by ID.","Deletes a Databricks workspace, both specified by ID.  :param workspace_id: int  :returns: :class:`Workspace`",workspaces,workspaces_delete,DELETE
provisioning,workspaces_get,/api/2.0/accounts/{account_id}/workspaces/{workspace_id},get,"provisioning, workspaces",workspace_id,Workspace,"Gets information including status for a Databricks workspace, specified by ID. In the response, the","Gets information including status for a Databricks workspace, specified by ID. In the response, the `workspace_status` field indicates the current status. After initial workspace creation (which is asynchronous), make repeated `GET` requests with the workspace ID and check its status. The workspace becomes available when the status changes to `RUNNING`. For information about how to create a new workspace with this API **including error handling**, see [Create a new workspace using the Account API].  [Create a new workspace using the Account API]: http://docs.databricks.com/administration-guide/account-api/new-workspace.html  :param workspace_id: int  :returns: :class:`Workspace`",workspaces,workspaces_get,SELECT
provisioning,workspaces_update,/api/2.0/accounts/{account_id}/workspaces/{workspace_id},patch,"provisioning, workspaces","workspace_id, update_mask, customer_facing_workspace",Wait[Workspace],Updates a workspace.,"Updates a workspace.  :param workspace_id: int   A unique integer ID for the workspace :param customer_facing_workspace: :class:`Workspace` :param update_mask: str (optional)   The field mask must be a single string, with multiple fields separated by commas (no spaces). The   field path is relative to the resource object, using a dot (`.`) to navigate sub-fields (e.g.,   `author.given_name`). Specification of elements in sequence or map fields is not allowed, as only   the entire collection field can be specified. Field names must exactly match the resource field   names.    A field mask of `*` indicates full replacement. Itâ€™s recommended to always explicitly list the   fields being updated and avoid using `*` wildcards, as it can lead to unintended results if the API   changes in the future.  :returns:   Long-running operation waiter for :class:`Workspace`.   See :method:wait_get_workspace_running for more details.",workspaces,workspaces_update,UPDATE
