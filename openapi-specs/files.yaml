openapi: 3.0.0
info:
  title: Databricks Files API
  description: API for Databricks files service
  version: 1.0.0
  contact:
    name: Databricks
    url: https://databricks.com
servers:
- url: https://{deployment_name}.cloud.databricks.com
  description: Databricks Workspace API
  variables:
    deployment_name:
      default: your-deployment
      description: Databricks workspace deployment name
paths:
  /api/2.0/dbfs/add-block:
    post:
      operationId: add_block
      summary: 'Appends a block of data to the stream specified by the input handle.
        If the handle does not exist,

        this call will throw an exception with ``RESOURCE_DOES_NOT_EXIST``.'
      description: "Appends a block of data to the stream specified by the input handle.\
        \ If the handle does not exist,\nthis call will throw an exception with ``RESOURCE_DOES_NOT_EXIST``.\n\
        \nIf the block of data exceeds 1 MB, this call will throw an exception with\
        \ ``MAX_BLOCK_SIZE_EXCEEDED``.\n\n:param handle: int\n  The handle on an open\
        \ stream.\n:param data: str\n  The base64-encoded data to append to the stream.\
        \ This has a limit of 1 MB."
      tags:
      - files
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                handle:
                  type: integer
                  description: int The handle on an open stream.
                data:
                  type: string
                  description: str The base64-encoded data to append to the stream.
                    This has a limit of 1 MB.
      responses:
        '200':
          description: Success
  /api/2.0/dbfs/close:
    post:
      operationId: close
      summary: 'Closes the stream specified by the input handle. If the handle does
        not exist, this call throws an

        exception with ``RESOURCE_DOES_NOT_EXIST``.'
      description: "Closes the stream specified by the input handle. If the handle\
        \ does not exist, this call throws an\nexception with ``RESOURCE_DOES_NOT_EXIST``.\n\
        \n:param handle: int\n  The handle on an open stream."
      tags:
      - files
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                handle:
                  type: integer
                  description: int The handle on an open stream.
      responses:
        '200':
          description: Success
  /api/2.0/dbfs/create:
    post:
      operationId: create
      summary: 'Opens a stream to write to a file and returns a handle to this stream.
        There is a 10 minute idle

        timeout on this handle. If a file or directory already exists on the given
        path and __overwrite__ is

        set to false, this call will throw an exception with ``RESOURCE_ALREADY_EXISTS``.'
      description: "Opens a stream to write to a file and returns a handle to this\
        \ stream. There is a 10 minute idle\ntimeout on this handle. If a file or\
        \ directory already exists on the given path and __overwrite__ is\nset to\
        \ false, this call will throw an exception with ``RESOURCE_ALREADY_EXISTS``.\n\
        \nA typical workflow for file upload would be:\n\n1. Issue a ``create`` call\
        \ and get a handle. 2. Issue one or more ``add-block`` calls with the handle\n\
        you have. 3. Issue a ``close`` call with the handle you have.\n\n:param path:\
        \ str\n  The path of the new file. The path should be the absolute DBFS path.\n\
        :param overwrite: bool (optional)\n  The flag that specifies whether to overwrite\
        \ existing file/files.\n\n:returns: :class:`CreateResponse`"
      tags:
      - files
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                path:
                  type: string
                  description: str The path of the new file. The path should be the
                    absolute DBFS path.
                overwrite:
                  type: boolean
                  description: bool (optional) The flag that specifies whether to
                    overwrite existing file/files.
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '404':
          description: Not found
        '500':
          description: Internal server error
  /api/2.0/dbfs/delete:
    post:
      operationId: delete
      summary: 'Delete the file or directory (optionally recursively delete all files
        in the directory). This call

        throws an exception with `IO_ERROR` if the path is a non-empty directory and
        `recursive` is set to

        `false` or on other similar errors.'
      description: "Delete the file or directory (optionally recursively delete all\
        \ files in the directory). This call\nthrows an exception with `IO_ERROR`\
        \ if the path is a non-empty directory and `recursive` is set to\n`false`\
        \ or on other similar errors.\n\nWhen you delete a large number of files,\
        \ the delete operation is done in increments. The call returns\na response\
        \ after approximately 45 seconds with an error message (503 Service Unavailable)\
        \ asking you\nto re-invoke the delete operation until the directory structure\
        \ is fully deleted.\n\nFor operations that delete more than 10K files, we\
        \ discourage using the DBFS REST API, but advise you\nto perform such operations\
        \ in the context of a cluster, using the [File system utility\n(dbutils.fs)](/dev-tools/databricks-utils.html#dbutils-fs).\
        \ `dbutils.fs` covers the functional scope\nof the DBFS REST API, but from\
        \ notebooks. Running such operations using notebooks provides better\ncontrol\
        \ and manageability, such as selective deletes, and the possibility to automate\
        \ periodic delete\njobs.\n\n:param path: str\n  The path of the file or directory\
        \ to delete. The path should be the absolute DBFS path.\n:param recursive:\
        \ bool (optional)\n  Whether or not to recursively delete the directory's\
        \ contents. Deleting empty directories can be\n  done without providing the\
        \ recursive flag."
      tags:
      - files
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                path:
                  type: string
                  description: str The path of the file or directory to delete. The
                    path should be the absolute DBFS path.
                recursive:
                  type: boolean
                  description: bool (optional) Whether or not to recursively delete
                    the directory's contents. Deleting empty directories can be done
                    without providing the recursive flag.
      responses:
        '200':
          description: Success
  /api/2.0/dbfs/get-status:
    get:
      operationId: get_status
      summary: 'Gets the file information for a file or directory. If the file or
        directory does not exist, this call

        throws an exception with `RESOURCE_DOES_NOT_EXIST`.'
      description: "Gets the file information for a file or directory. If the file\
        \ or directory does not exist, this call\nthrows an exception with `RESOURCE_DOES_NOT_EXIST`.\n\
        \n:param path: str\n  The path of the file or directory. The path should be\
        \ the absolute DBFS path.\n\n:returns: :class:`FileInfo`"
      tags:
      - files
      parameters:
      - name: path
        description: str The path of the file or directory. The path should be the
          absolute DBFS path.
        required: true
        schema:
          type: string
        in: query
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileInfo'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '404':
          description: Not found
        '500':
          description: Internal server error
  /api/2.0/dbfs/list:
    get:
      operationId: list
      summary: 'List the contents of a directory, or details of the file. If the file
        or directory does not exist,

        this call throws an exception with `RESOURCE_DOES_NOT_EXIST`.'
      description: "List the contents of a directory, or details of the file. If the\
        \ file or directory does not exist,\nthis call throws an exception with `RESOURCE_DOES_NOT_EXIST`.\n\
        \nWhen calling list on a large directory, the list operation will time out\
        \ after approximately 60\nseconds. We strongly recommend using list only on\
        \ directories containing less than 10K files and\ndiscourage using the DBFS\
        \ REST API for operations that list more than 10K files. Instead, we recommend\n\
        that you perform such operations in the context of a cluster, using the [File\
        \ system utility\n(dbutils.fs)](/dev-tools/databricks-utils.html#dbutils-fs),\
        \ which provides the same functionality\nwithout timing out.\n\n:param path:\
        \ str\n  The path of the file or directory. The path should be the absolute\
        \ DBFS path.\n\n:returns: Iterator over :class:`FileInfo`"
      tags:
      - files
      parameters:
      - name: path
        description: str The path of the file or directory. The path should be the
          absolute DBFS path.
        required: true
        schema:
          type: string
        in: query
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileInfo'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '404':
          description: Not found
        '500':
          description: Internal server error
  /api/2.0/dbfs/mkdirs:
    post:
      operationId: mkdirs
      summary: 'Creates the given directory and necessary parent directories if they
        do not exist. If a file (not a

        directory) exists at any prefix of the input path, this call throws an exception
        with

        `RESOURCE_ALREADY_EXISTS`. **Note**: If this operation fails, it might have
        succeeded in creating some

        of the necessary parent directories.'
      description: "Creates the given directory and necessary parent directories if\
        \ they do not exist. If a file (not a\ndirectory) exists at any prefix of\
        \ the input path, this call throws an exception with\n`RESOURCE_ALREADY_EXISTS`.\
        \ **Note**: If this operation fails, it might have succeeded in creating some\n\
        of the necessary parent directories.\n\n:param path: str\n  The path of the\
        \ new directory. The path should be the absolute DBFS path."
      tags:
      - files
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                path:
                  type: string
                  description: str The path of the new directory. The path should
                    be the absolute DBFS path.
      responses:
        '200':
          description: Success
  /api/2.0/dbfs/move:
    post:
      operationId: move
      summary: 'Moves a file from one location to another location within DBFS. If
        the source file does not exist,

        this call throws an exception with `RESOURCE_DOES_NOT_EXIST`. If a file already
        exists in the

        destination path, this call throws an exception with `RESOURCE_ALREADY_EXISTS`.
        If the given source

        path is a directory, this call always recursively moves all files.'
      description: "Moves a file from one location to another location within DBFS.\
        \ If the source file does not exist,\nthis call throws an exception with `RESOURCE_DOES_NOT_EXIST`.\
        \ If a file already exists in the\ndestination path, this call throws an exception\
        \ with `RESOURCE_ALREADY_EXISTS`. If the given source\npath is a directory,\
        \ this call always recursively moves all files.\n\n:param source_path: str\n\
        \  The source path of the file or directory. The path should be the absolute\
        \ DBFS path.\n:param destination_path: str\n  The destination path of the\
        \ file or directory. The path should be the absolute DBFS path."
      tags:
      - files
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                source_path:
                  type: string
                  description: str The source path of the file or directory. The path
                    should be the absolute DBFS path.
                destination_path:
                  type: string
                  description: str The destination path of the file or directory.
                    The path should be the absolute DBFS path.
      responses:
        '200':
          description: Success
  /api/2.0/dbfs/put:
    post:
      operationId: put
      summary: 'Uploads a file through the use of multipart form post. It is mainly
        used for streaming uploads, but

        can also be used as a convenient single call for data upload.'
      description: "Uploads a file through the use of multipart form post. It is mainly\
        \ used for streaming uploads, but\ncan also be used as a convenient single\
        \ call for data upload.\n\nAlternatively you can pass contents as base64 string.\n\
        \nThe amount of data that can be passed (when not streaming) using the __contents__\
        \ parameter is limited\nto 1 MB. `MAX_BLOCK_SIZE_EXCEEDED` will be thrown\
        \ if this limit is exceeded.\n\nIf you want to upload large files, use the\
        \ streaming upload. For details, see :method:dbfs/create,\n:method:dbfs/addBlock,\
        \ :method:dbfs/close.\n\n:param path: str\n  The path of the new file. The\
        \ path should be the absolute DBFS path.\n:param contents: str (optional)\n\
        \  This parameter might be absent, and instead a posted file will be used.\n\
        :param overwrite: bool (optional)\n  The flag that specifies whether to overwrite\
        \ existing file/files."
      tags:
      - files
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                path:
                  type: string
                  description: str The path of the new file. The path should be the
                    absolute DBFS path.
                contents:
                  type: string
                  description: str (optional) This parameter might be absent, and
                    instead a posted file will be used.
                overwrite:
                  type: boolean
                  description: bool (optional) The flag that specifies whether to
                    overwrite existing file/files.
      responses:
        '200':
          description: Success
  /api/2.0/dbfs/read:
    get:
      operationId: read
      summary: 'Returns the contents of a file. If the file does not exist, this call
        throws an exception with

        `RESOURCE_DOES_NOT_EXIST`. If the path is a directory, the read length is
        negative, or if the offset

        is negative, this call throws an exception with `INVALID_PARAMETER_VALUE`.
        If the read length exceeds

        1 MB, this call throws an exception with `MAX_READ_SIZE_EXCEEDED`.'
      description: "Returns the contents of a file. If the file does not exist, this\
        \ call throws an exception with\n`RESOURCE_DOES_NOT_EXIST`. If the path is\
        \ a directory, the read length is negative, or if the offset\nis negative,\
        \ this call throws an exception with `INVALID_PARAMETER_VALUE`. If the read\
        \ length exceeds\n1 MB, this call throws an exception with `MAX_READ_SIZE_EXCEEDED`.\n\
        \nIf `offset + length` exceeds the number of bytes in a file, it reads the\
        \ contents until the end of\nfile.\n\n:param path: str\n  The path of the\
        \ file to read. The path should be the absolute DBFS path.\n:param length:\
        \ int (optional)\n  The number of bytes to read starting from the offset.\
        \ This has a limit of 1 MB, and a default value\n  of 0.5 MB.\n:param offset:\
        \ int (optional)\n  The offset to read from in bytes.\n\n:returns: :class:`ReadResponse`"
      tags:
      - files
      parameters:
      - name: path
        description: str The path of the file to read. The path should be the absolute
          DBFS path.
        required: true
        schema:
          type: string
        in: query
      - name: length
        description: int (optional) The number of bytes to read starting from the
          offset. This has a limit of 1 MB, and a default value of 0.5 MB.
        required: false
        schema:
          type: integer
        in: query
      - name: offset
        description: int (optional) The offset to read from in bytes.
        required: false
        schema:
          type: integer
        in: query
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ReadResponse'
        '400':
          description: Bad request
        '401':
          description: Unauthorized
        '404':
          description: Not found
        '500':
          description: Internal server error
  /api/2.0/fs/files{file_path}:
    delete:
      operationId: delete
      summary: Deletes a file. If the request is successful, there is no response
        body.
      description: "Deletes a file. If the request is successful, there is no response\
        \ body.\n\n:param file_path: str\n  The absolute path of the file."
      tags:
      - files
      parameters:
      - name: file_path
        description: str The absolute path of the file.
        required: true
        schema:
          type: string
        in: path
      responses:
        '200':
          description: Success
components:
  schemas:
    AddBlockResponse:
      type: object
      description: AddBlockResponse()
      properties: {}
    CloseResponse:
      type: object
      description: CloseResponse()
      properties: {}
    CreateDirectoryResponse:
      type: object
      description: CreateDirectoryResponse()
      properties: {}
    CreateResponse:
      type: object
      description: 'CreateResponse(handle: ''Optional[int]'' = None)'
      properties:
        handle:
          type: string
          description: Handle which should subsequently be passed into the AddBlock
            and Close calls when writing to a file through a stream.
    DeleteDirectoryResponse:
      type: object
      description: DeleteDirectoryResponse()
      properties: {}
    DeleteResponse:
      type: object
      description: DeleteResponse()
      properties: {}
    DirectoryEntry:
      type: object
      description: 'DirectoryEntry(file_size: ''Optional[int]'' = None, is_directory:
        ''Optional[bool]'' = None, last_modified: ''Optional[int]'' = None, name:
        ''Optional[str]'' = None, path: ''Optional[str]'' = None)'
      properties:
        file_size:
          type: string
          description: 'The length of the file in bytes. This field is omitted for
            directories.  is_directory: Optional[bool] = None True if the path is
            a directory.'
        is_directory:
          type: string
          description: 'True if the path is a directory.  last_modified: Optional[int]
            = None Last modification time of given file in milliseconds since unix
            epoch.'
        last_modified:
          type: string
          description: 'Last modification time of given file in milliseconds since
            unix epoch.  name: Optional[str] = None The name of the file or directory.
            This is the last component of the path.'
        name:
          type: string
          description: 'The name of the file or directory. This is the last component
            of the path.  path: Optional[str] = None The absolute path of the file
            or directory.'
        path:
          type: string
          description: 'The absolute path of the file or directory.  def as_dict(self)
            -> dict: Serializes the DirectoryEntry into a dictionary suitable for
            use as a JSON request body.'
    DownloadResponse:
      type: object
      description: 'DownloadResponse(content_length: ''Optional[int]'' = None, content_type:
        ''Optional[str]'' = None, contents: ''Optional[BinaryIO]'' = None, last_modified:
        ''Optional[str]'' = None)'
      properties:
        content_length:
          type: string
          description: 'The length of the HTTP response body in bytes.  content_type:
            Optional[str] = None  contents: Optional[BinaryIO] = None  last_modified:
            Optional[str] = None The last modified time of the file in HTTP-date (RFC
            7231) format.'
        content_type:
          type: string
          description: ''
        contents:
          type: string
          description: ''
        last_modified:
          type: string
          description: 'The last modified time of the file in HTTP-date (RFC 7231)
            format.  def as_dict(self) -> dict: Serializes the DownloadResponse into
            a dictionary suitable for use as a JSON request body.'
    FileInfo:
      type: object
      description: 'FileInfo(file_size: ''Optional[int]'' = None, is_dir: ''Optional[bool]''
        = None, modification_time: ''Optional[int]'' = None, path: ''Optional[str]''
        = None)'
      properties:
        file_size:
          type: string
          description: 'The length of the file in bytes. This field is omitted for
            directories.  is_dir: Optional[bool] = None True if the path is a directory.'
        is_dir:
          type: string
          description: 'True if the path is a directory.  modification_time: Optional[int]
            = None Last modification time of given file in milliseconds since epoch.'
        modification_time:
          type: string
          description: 'Last modification time of given file in milliseconds since
            epoch.  path: Optional[str] = None The absolute path of the file or directory.'
        path:
          type: string
          description: 'The absolute path of the file or directory.  def as_dict(self)
            -> dict: Serializes the FileInfo into a dictionary suitable for use as
            a JSON request body.'
    GetDirectoryMetadataResponse:
      type: object
      description: GetDirectoryMetadataResponse()
      properties: {}
    GetMetadataResponse:
      type: object
      description: 'GetMetadataResponse(content_length: ''Optional[int]'' = None,
        content_type: ''Optional[str]'' = None, last_modified: ''Optional[str]'' =
        None)'
      properties:
        content_length:
          type: string
          description: 'The length of the HTTP response body in bytes.  content_type:
            Optional[str] = None  last_modified: Optional[str] = None The last modified
            time of the file in HTTP-date (RFC 7231) format.'
        content_type:
          type: string
          description: ''
        last_modified:
          type: string
          description: 'The last modified time of the file in HTTP-date (RFC 7231)
            format.  def as_dict(self) -> dict: Serializes the GetMetadataResponse
            into a dictionary suitable for use as a JSON request body.'
    ListDirectoryResponse:
      type: object
      description: 'ListDirectoryResponse(contents: ''Optional[List[DirectoryEntry]]''
        = None, next_page_token: ''Optional[str]'' = None)'
      properties:
        contents:
          type: string
          description: 'Array of DirectoryEntry.  next_page_token: Optional[str] =
            None A token, which can be sent as `page_token` to retrieve the next page.'
        next_page_token:
          type: string
          description: 'A token, which can be sent as `page_token` to retrieve the
            next page.  def as_dict(self) -> dict: Serializes the ListDirectoryResponse
            into a dictionary suitable for use as a JSON request body.'
    ListStatusResponse:
      type: object
      description: 'ListStatusResponse(files: ''Optional[List[FileInfo]]'' = None)'
      properties:
        files:
          type: string
          description: 'A list of FileInfo''s that describe contents of directory
            or file. See example above.  def as_dict(self) -> dict: Serializes the
            ListStatusResponse into a dictionary suitable for use as a JSON request
            body.'
    MkDirsResponse:
      type: object
      description: MkDirsResponse()
      properties: {}
    MoveResponse:
      type: object
      description: MoveResponse()
      properties: {}
    PutResponse:
      type: object
      description: PutResponse()
      properties: {}
    ReadResponse:
      type: object
      description: 'ReadResponse(bytes_read: ''Optional[int]'' = None, data: ''Optional[str]''
        = None)'
      properties:
        bytes_read:
          type: string
          description: The number of bytes read (could be less than ``length`` if
            we hit end of file). This refers to number of bytes read in unencoded
            version (response data is base64-encoded).
        data:
          type: string
          description: 'The base64-encoded contents of the file read.  def as_dict(self)
            -> dict: Serializes the ReadResponse into a dictionary suitable for use
            as a JSON request body.'
    UploadResponse:
      type: object
      description: UploadResponse()
      properties: {}
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
      description: Databricks personal access token
security:
- bearerAuth: []
